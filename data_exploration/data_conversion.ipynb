{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    " # Table of Contents\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\" id=\"toc-level0\"><li><span><a href=\"http://localhost:8887/notebooks/data_exploration/data_conversion.ipynb#Append-mean-and-std-for-LAT-variable\" data-toc-modified-id=\"Append-mean-and-std-for-LAT-variable-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Append mean and std for LAT variable</a></span><ul class=\"toc-item\"><li><span><a href=\"http://localhost:8887/notebooks/data_exploration/data_conversion.ipynb#For-sample\" data-toc-modified-id=\"For-sample-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>For sample</a></span></li><li><span><a href=\"http://localhost:8887/notebooks/data_exploration/data_conversion.ipynb#For-full-dataset\" data-toc-modified-id=\"For-full-dataset-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>For full dataset</a></span></li></ul></li><li><span><a href=\"http://localhost:8887/notebooks/data_exploration/data_conversion.ipynb#Split-into-train-and-validation-set\" data-toc-modified-id=\"Split-into-train-and-validation-set-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Split into train and validation set</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data conversion\n",
    "\n",
    "In this notebook, I am creating subsets of the original input data. In particular, I want a reproducible training and validation set and a subset of these in a sample directory. \n",
    "\n",
    "NOTE: The sample set creation is not currently in the notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make train/valid split reproducible\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AndKua_aqua_SPCAM3.0.cam2.h1.0000-01-01-00000.nc\r\n",
      "conda-cheatsheet.pdf\r\n",
      "crm.F\r\n",
      "read_aquaplanet.m\r\n",
      "read_write_max.m\r\n",
      "read_write_normalization.m\r\n",
      "sample\r\n",
      "SPCAM_max.nc\r\n",
      "SPCAM_mean.nc\r\n",
      "SPCAM_mean_no_lat.nc\r\n",
      "SPCAM_outputs.nc\r\n",
      "SPCAM_std.nc\r\n",
      "SPCAM_std_no_lat.nc\r\n",
      "tphysbc_internallythreaded.F90\r\n",
      "variables2predict.F\r\n"
     ]
    }
   ],
   "source": [
    "# data_dir = '/Volumes/STICK/data/SPCAM/'   # Mac\n",
    "data_dir = '/project/meteo/w2w/A6/S.Rasp/SP-CAM/'   # LMU\n",
    "sample_dir = data_dir + '/sample/'\n",
    "!ls $data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Append mean and std for LAT variable\n",
    "\n",
    "This was missing in the original dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### For sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPCAM_mean.nc         SPCAM_outputs.nc  SPCAM_std_no_lat.nc\r\n",
      "SPCAM_mean_no_lat.nc  SPCAM_std.nc\r\n"
     ]
    }
   ],
   "source": [
    "sample_dir = data_dir + '/sample/'\n",
    "%ls $sample_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "! cp $sample_dir/SPCAM_mean.nc $sample_dir/SPCAM_mean_no_lat.nc\n",
    "! cp $sample_dir/SPCAM_std.nc $sample_dir/SPCAM_std_no_lat.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'netCDF4._netCDF4.Dataset'>\n",
       "root group (NETCDF4 data model, file format HDF5):\n",
       "    dimensions(sizes): t(100000), z(21)\n",
       "    variables(dimensions): float64 \u001b[4mLAT\u001b[0m(t), float64 \u001b[4mPS\u001b[0m(t), float64 \u001b[4mSHFLX\u001b[0m(t), float64 \u001b[4mLHFLX\u001b[0m(t), float64 \u001b[4mOMEGA\u001b[0m(z,t), float64 \u001b[4mQAP\u001b[0m(z,t), float64 \u001b[4mTAP\u001b[0m(z,t), float64 \u001b[4mQRL\u001b[0m(z,t), float64 \u001b[4mQRS\u001b[0m(z,t), float64 \u001b[4mUBSP\u001b[0m(z,t), float64 \u001b[4mVBSP\u001b[0m(z,t), float64 \u001b[4mSPQC\u001b[0m(z,t), float64 \u001b[4mSPQG\u001b[0m(z,t), float64 \u001b[4mSPQI\u001b[0m(z,t), float64 \u001b[4mSPQR\u001b[0m(z,t), float64 \u001b[4mSPMC\u001b[0m(z,t), float64 \u001b[4mSPMCDN\u001b[0m(z,t), float64 \u001b[4mSPMCUDN\u001b[0m(z,t), float64 \u001b[4mSPMCUP\u001b[0m(z,t), float64 \u001b[4mSPMCUUP\u001b[0m(z,t), float64 \u001b[4mTPHYSTND\u001b[0m(z,t), float64 \u001b[4mPHQ\u001b[0m(z,t), float64 \u001b[4mSPDT\u001b[0m(z,t), float64 \u001b[4mSPDQ\u001b[0m(z,t), float64 \u001b[4mSPDQC\u001b[0m(z,t), float64 \u001b[4mSPDQI\u001b[0m(z,t), float64 \u001b[4mdTdt_adiabatic\u001b[0m(z,t), float64 \u001b[4mdQdt_adiabatic\u001b[0m(z,t), float64 \u001b[4mGRAD_UQ_H\u001b[0m(z,t)\n",
       "    groups: "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_sample = Dataset(sample_dir + 'SPCAM_outputs.nc')\n",
    "out_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'netCDF4._netCDF4.Dataset'>\n",
       "root group (NETCDF4 data model, file format HDF5):\n",
       "    dimensions(sizes): z(21)\n",
       "    variables(dimensions): float64 \u001b[4mPS\u001b[0m(), float64 \u001b[4mSHFLX\u001b[0m(), float64 \u001b[4mLHFLX\u001b[0m(), float64 \u001b[4mOMEGA\u001b[0m(z), float64 \u001b[4mQAP\u001b[0m(z), float64 \u001b[4mTAP\u001b[0m(z), float64 \u001b[4mQRL\u001b[0m(z), float64 \u001b[4mQRS\u001b[0m(z), float64 \u001b[4mUBSP\u001b[0m(z), float64 \u001b[4mVBSP\u001b[0m(z), float64 \u001b[4mdTdt_adiabatic\u001b[0m(z), float64 \u001b[4mdQdt_adiabatic\u001b[0m(z), float64 \u001b[4mGRAD_UQ_H\u001b[0m(z), float64 \u001b[4mSPQC\u001b[0m(z), float64 \u001b[4mSPQG\u001b[0m(z), float64 \u001b[4mSPQI\u001b[0m(z), float64 \u001b[4mSPQR\u001b[0m(z), float64 \u001b[4mSPMC\u001b[0m(z), float64 \u001b[4mSPMCDN\u001b[0m(z), float64 \u001b[4mSPMCUDN\u001b[0m(z), float64 \u001b[4mSPMCUP\u001b[0m(z), float64 \u001b[4mSPMCUUP\u001b[0m(z), float64 \u001b[4mTPHYSTND\u001b[0m(z), float64 \u001b[4mPHQ\u001b[0m(z), float64 \u001b[4mSPDT\u001b[0m(z), float64 \u001b[4mSPDQ\u001b[0m(z), float64 \u001b[4mSPDQC\u001b[0m(z), float64 \u001b[4mSPDQI\u001b[0m(z)\n",
       "    groups: "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_sample = Dataset(sample_dir + 'SPCAM_mean.nc', 'a')\n",
    "mean_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'netCDF4._netCDF4.Variable'>\n",
       "float64 LAT()\n",
       "unlimited dimensions: \n",
       "current shape = ()\n",
       "filling on, default _FillValue of 9.969209968386869e+36 used"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_sample.createVariable('LAT', 'float64', ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mean_sample.variables['LAT'][:] = np.mean(out_sample.variables['LAT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'netCDF4._netCDF4.Dataset'>\n",
       "root group (NETCDF4 data model, file format HDF5):\n",
       "    dimensions(sizes): z(21)\n",
       "    variables(dimensions): float64 \u001b[4mPS\u001b[0m(), float64 \u001b[4mSHFLX\u001b[0m(), float64 \u001b[4mLHFLX\u001b[0m(), float64 \u001b[4mOMEGA\u001b[0m(z), float64 \u001b[4mQAP\u001b[0m(z), float64 \u001b[4mTAP\u001b[0m(z), float64 \u001b[4mQRL\u001b[0m(z), float64 \u001b[4mQRS\u001b[0m(z), float64 \u001b[4mUBSP\u001b[0m(z), float64 \u001b[4mVBSP\u001b[0m(z), float64 \u001b[4mdTdt_adiabatic\u001b[0m(z), float64 \u001b[4mdQdt_adiabatic\u001b[0m(z), float64 \u001b[4mGRAD_UQ_H\u001b[0m(z), float64 \u001b[4mSPQC\u001b[0m(z), float64 \u001b[4mSPQG\u001b[0m(z), float64 \u001b[4mSPQI\u001b[0m(z), float64 \u001b[4mSPQR\u001b[0m(z), float64 \u001b[4mSPMC\u001b[0m(z), float64 \u001b[4mSPMCDN\u001b[0m(z), float64 \u001b[4mSPMCUDN\u001b[0m(z), float64 \u001b[4mSPMCUP\u001b[0m(z), float64 \u001b[4mSPMCUUP\u001b[0m(z), float64 \u001b[4mTPHYSTND\u001b[0m(z), float64 \u001b[4mPHQ\u001b[0m(z), float64 \u001b[4mSPDT\u001b[0m(z), float64 \u001b[4mSPDQ\u001b[0m(z), float64 \u001b[4mSPDQC\u001b[0m(z), float64 \u001b[4mSPDQI\u001b[0m(z), float64 \u001b[4mLAT\u001b[0m()\n",
       "    groups: "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mean_sample.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'netCDF4._netCDF4.Dataset'>\n",
       "root group (NETCDF4 data model, file format HDF5):\n",
       "    dimensions(sizes): z(21)\n",
       "    variables(dimensions): float64 \u001b[4mPS\u001b[0m(), float64 \u001b[4mSHFLX\u001b[0m(), float64 \u001b[4mLHFLX\u001b[0m(), float64 \u001b[4mOMEGA\u001b[0m(z), float64 \u001b[4mQAP\u001b[0m(z), float64 \u001b[4mTAP\u001b[0m(z), float64 \u001b[4mQRL\u001b[0m(z), float64 \u001b[4mQRS\u001b[0m(z), float64 \u001b[4mUBSP\u001b[0m(z), float64 \u001b[4mVBSP\u001b[0m(z), float64 \u001b[4mdTdt_adiabatic\u001b[0m(z), float64 \u001b[4mdQdt_adiabatic\u001b[0m(z), float64 \u001b[4mGRAD_UQ_H\u001b[0m(z), float64 \u001b[4mSPQC\u001b[0m(z), float64 \u001b[4mSPQG\u001b[0m(z), float64 \u001b[4mSPQI\u001b[0m(z), float64 \u001b[4mSPQR\u001b[0m(z), float64 \u001b[4mSPMC\u001b[0m(z), float64 \u001b[4mSPMCDN\u001b[0m(z), float64 \u001b[4mSPMCUDN\u001b[0m(z), float64 \u001b[4mSPMCUP\u001b[0m(z), float64 \u001b[4mSPMCUUP\u001b[0m(z), float64 \u001b[4mTPHYSTND\u001b[0m(z), float64 \u001b[4mPHQ\u001b[0m(z), float64 \u001b[4mSPDT\u001b[0m(z), float64 \u001b[4mSPDQ\u001b[0m(z), float64 \u001b[4mSPDQC\u001b[0m(z), float64 \u001b[4mSPDQI\u001b[0m(z), float64 \u001b[4mLAT\u001b[0m()\n",
       "    groups: "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_sample = Dataset(sample_dir + 'SPCAM_std.nc', 'a')\n",
    "std_sample.createVariable('LAT', 'float64', ())\n",
    "std_sample.variables['LAT'][:] = np.std(out_sample.variables['LAT'], ddof=1)\n",
    "std_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(51.9367842914506)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_sample.variables['LAT'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "std_sample.close()\n",
    "out_sample.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### For full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "! cp $data_dir/SPCAM_mean.nc $data_dir/SPCAM_mean_no_lat.nc\n",
    "! cp $data_dir/SPCAM_std.nc $data_dir/SPCAM_std_no_lat.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mean = Dataset(data_dir + 'SPCAM_mean.nc', 'a')\n",
    "std = Dataset(data_dir + 'SPCAM_std.nc', 'a')\n",
    "out = Dataset(data_dir + 'SPCAM_outputs.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mean.createVariable('LAT', 'float64', ())\n",
    "std.createVariable('LAT', 'float64', ())\n",
    "mean.variables['LAT'][:] = np.mean(out.variables['LAT'])\n",
    "std.variables['LAT'][:] = np.std(out.variables['LAT'], ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<class 'netCDF4._netCDF4.Dataset'>\n",
       " root group (NETCDF4_CLASSIC data model, file format HDF5):\n",
       "     dimensions(sizes): z(21)\n",
       "     variables(dimensions): float64 \u001b[4mPS\u001b[0m(), float64 \u001b[4mSHFLX\u001b[0m(), float64 \u001b[4mLHFLX\u001b[0m(), float64 \u001b[4mOMEGA\u001b[0m(z), float64 \u001b[4mQAP\u001b[0m(z), float64 \u001b[4mTAP\u001b[0m(z), float64 \u001b[4mQRL\u001b[0m(z), float64 \u001b[4mQRS\u001b[0m(z), float64 \u001b[4mUBSP\u001b[0m(z), float64 \u001b[4mVBSP\u001b[0m(z), float64 \u001b[4mdTdt_adiabatic\u001b[0m(z), float64 \u001b[4mdQdt_adiabatic\u001b[0m(z), float64 \u001b[4mGRAD_UQ_H\u001b[0m(z), float64 \u001b[4mSPQC\u001b[0m(z), float64 \u001b[4mSPQG\u001b[0m(z), float64 \u001b[4mSPQI\u001b[0m(z), float64 \u001b[4mSPQR\u001b[0m(z), float64 \u001b[4mSPMC\u001b[0m(z), float64 \u001b[4mSPMCDN\u001b[0m(z), float64 \u001b[4mSPMCUDN\u001b[0m(z), float64 \u001b[4mSPMCUP\u001b[0m(z), float64 \u001b[4mSPMCUUP\u001b[0m(z), float64 \u001b[4mTPHYSTND\u001b[0m(z), float64 \u001b[4mPHQ\u001b[0m(z), float64 \u001b[4mSPDT\u001b[0m(z), float64 \u001b[4mSPDQ\u001b[0m(z), float64 \u001b[4mSPDQC\u001b[0m(z), float64 \u001b[4mSPDQI\u001b[0m(z), float64 \u001b[4mLAT\u001b[0m()\n",
       "     groups: , <class 'netCDF4._netCDF4.Dataset'>\n",
       " root group (NETCDF4_CLASSIC data model, file format HDF5):\n",
       "     dimensions(sizes): z(21)\n",
       "     variables(dimensions): float64 \u001b[4mPS\u001b[0m(), float64 \u001b[4mSHFLX\u001b[0m(), float64 \u001b[4mLHFLX\u001b[0m(), float64 \u001b[4mOMEGA\u001b[0m(z), float64 \u001b[4mQAP\u001b[0m(z), float64 \u001b[4mTAP\u001b[0m(z), float64 \u001b[4mQRL\u001b[0m(z), float64 \u001b[4mQRS\u001b[0m(z), float64 \u001b[4mUBSP\u001b[0m(z), float64 \u001b[4mVBSP\u001b[0m(z), float64 \u001b[4mdTdt_adiabatic\u001b[0m(z), float64 \u001b[4mdQdt_adiabatic\u001b[0m(z), float64 \u001b[4mGRAD_UQ_H\u001b[0m(z), float64 \u001b[4mSPQC\u001b[0m(z), float64 \u001b[4mSPQG\u001b[0m(z), float64 \u001b[4mSPQI\u001b[0m(z), float64 \u001b[4mSPQR\u001b[0m(z), float64 \u001b[4mSPMC\u001b[0m(z), float64 \u001b[4mSPMCDN\u001b[0m(z), float64 \u001b[4mSPMCUDN\u001b[0m(z), float64 \u001b[4mSPMCUP\u001b[0m(z), float64 \u001b[4mSPMCUUP\u001b[0m(z), float64 \u001b[4mTPHYSTND\u001b[0m(z), float64 \u001b[4mPHQ\u001b[0m(z), float64 \u001b[4mSPDT\u001b[0m(z), float64 \u001b[4mSPDQ\u001b[0m(z), float64 \u001b[4mSPDQC\u001b[0m(z), float64 \u001b[4mSPDQI\u001b[0m(z), float64 \u001b[4mLAT\u001b[0m()\n",
       "     groups: )"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if it worked\n",
    "mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Close \n",
    "mean.close()\n",
    "std.close()\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Split into train and validation set\n",
    "\n",
    "I would like to split the outputs dataset into a train and a valid file. Having them separated makes it easy to get a reproducible split.\n",
    "\n",
    "NOTE: I will not recompute the means and stds from just the training set. This would be proper, but I think for our dataset the differences would be tiny!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_train_valid(data_dir, train_fraction=0.8):\n",
    "    \"\"\"Reads the SPCAM_outputs.nc file and creates two new files \n",
    "    SPCAM_outputs_train.nc and SPCAM_outputs_valid.nc with random samples.\n",
    "    \"\"\"\n",
    "    # Open full dataset\n",
    "    raw_out = Dataset(data_dir + 'SPCAM_outputs.nc')\n",
    "    n_samples = raw_out.dimensions['t'].size\n",
    "    \n",
    "    # Create indexes for train and valid set\n",
    "    idxs = np.arange(n_samples)\n",
    "    np.random.shuffle(idxs)\n",
    "    split_idx = int(n_samples * train_fraction)\n",
    "    train_idxs = idxs[:split_idx]\n",
    "    valid_idxs = idxs[split_idx:]\n",
    "    \n",
    "    # Create train and valid datasets\n",
    "    train_out = Dataset(data_dir + 'SPCAM_outputs_train.nc', 'w')\n",
    "    valid_out = Dataset(data_dir + 'SPCAM_outputs_valid.nc', 'w')\n",
    "    \n",
    "    # Loop over train and valid and write data\n",
    "    for out, idxs in zip([train_out, valid_out], [train_idxs, valid_idxs]):\n",
    "        # Create dimensions\n",
    "        out.createDimension('z', 21)\n",
    "        out.createDimension('t', idxs.shape[0])\n",
    "        \n",
    "        # Create variables and write split data\n",
    "        for name, raw_var in raw_out.variables.items():\n",
    "            var = out.createVariable(name, 'float64', raw_var.dimensions)\n",
    "            if len(raw_var.dimensions) == 1:\n",
    "                var[:] = raw_var[idxs]\n",
    "            elif len(raw_var.dimensions) == 2:\n",
    "                var[:] = raw_var[:, idxs]\n",
    "            else:\n",
    "                raise ValueError('Wrong dimensions.')\n",
    "        # Close rootgroups\n",
    "        out.close()\n",
    "    raw_out.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_fraction = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split_train_valid(sample_dir, train_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPCAM_mean.nc         SPCAM_outputs_train.nc  SPCAM_std_no_lat.nc\r\n",
      "SPCAM_mean_no_lat.nc  SPCAM_outputs_valid.nc\r\n",
      "SPCAM_outputs.nc      SPCAM_std.nc\r\n"
     ]
    }
   ],
   "source": [
    "%ls $sample_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split_train_valid(data_dir, train_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%ls $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
