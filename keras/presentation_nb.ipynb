{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    " # Table of Contents\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\" id=\"toc-level0\"><li><span><a href=\"http://localhost:8887/notebooks/keras/presentation_nb.ipynb#Setup\" data-toc-modified-id=\"Setup-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Setup</a></span></li><li><span><a href=\"http://localhost:8887/notebooks/keras/presentation_nb.ipynb#Train-a-fully-connected-model\" data-toc-modified-id=\"Train-a-fully-connected-model-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Train a fully connected model</a></span><ul class=\"toc-item\"><li><span><a href=\"http://localhost:8887/notebooks/keras/presentation_nb.ipynb#Load-the-datasets\" data-toc-modified-id=\"Load-the-datasets-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Load the datasets</a></span></li><li><span><a href=\"http://localhost:8887/notebooks/keras/presentation_nb.ipynb#Set-up-the-model\" data-toc-modified-id=\"Set-up-the-model-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Set up the model</a></span></li></ul></li><li><span><a href=\"http://localhost:8887/notebooks/keras/presentation_nb.ipynb#Convolutional-model\" data-toc-modified-id=\"Convolutional-model-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Convolutional model</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CBRAIN experiments with Keras, etc.\n",
    "\n",
    "ToDo:\n",
    "- Load data\n",
    "- Run a simple fully connected net to get close to 0.7 R2\n",
    "- Visualization of output\n",
    "    - some examples\n",
    "    - checkout the biases, etc\n",
    "- low level implementation in python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Basic imports and path definitions. The data loading, keras models and other utility functions are imported from scripts in this directory. I am running this interactively on a 4GB GPU. Note that the CPU RAM might need to be bigger due to the large data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports \n",
    "from importlib import reload\n",
    "import utils; reload(utils); from utils import *\n",
    "import data_generator; reload(data_generator); from data_generator import *\n",
    "import models; reload(models); from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Limit Tensorflow GPU memory usage. \n",
    "# Note that apparently it's not possible to change the allocation or release memory again.\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5   # GPU RAM usage fraction of 4GB\n",
    "keras.backend.tensorflow_backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotting setup\n",
    "%matplotlib inline\n",
    "np.random.seed(42)\n",
    "sns.set_style('dark')\n",
    "sns.set_palette('deep')\n",
    "sns.set_context('talk')\n",
    "plt.rcParams[\"figure.figsize\"] = (10,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPCAM_mean_detailed.nc              SPCAM_outputs_train_by_lon_flat.nc\r\n",
      "SPCAM_outputs_detailed.nc           SPCAM_outputs_train_by_lon.nc\r\n",
      "SPCAM_outputs_flat.nc               SPCAM_outputs_valid_by_lon_flat.nc\r\n",
      "SPCAM_outputs_flat_train_random.nc  SPCAM_outputs_valid_by_lon.nc\r\n",
      "SPCAM_outputs_flat_valid_random.nc  SPCAM_std_detailed.nc\r\n"
     ]
    }
   ],
   "source": [
    "# Define data paths\n",
    "data_dir = '/project/meteo/w2w/A6/S.Rasp/SP-CAM/preprocessed_data/detailed_files/' # Full dataset\n",
    "%ls $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a dictionary containing the feature and target variables\n",
    "# and the number of dimensions\n",
    "feature_vars = OrderedDict({\n",
    "    'TAP': 2,             # Temperature [z, sample]\n",
    "    'QAP': 2,             # Specific humidity [z, sample]\n",
    "    'OMEGA': 2,           # [z, sample]\n",
    "    'dTdt_adiabatic': 2,  # [z, sample]\n",
    "    'dQdt_adiabatic': 2,  # [z, sample]\n",
    "    'QRL': 2,             # Long wave heating rate [z, sample]\n",
    "    'QRS': 2,             # Short wave heating rate [z, sample]\n",
    "    'SHFLX': 1,           # [sample]\n",
    "    'LHFLX': 1,           # [sample]\n",
    "    'LAT': 1,             # Latitude [sample]\n",
    "})\n",
    "target_vars = OrderedDict({\n",
    "    'SPDT': 2,            # SP temperature tendency [z, sample]\n",
    "    'SPDQ': 2,            # SP humidity tendency [z, sample]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a fully connected model\n",
    "\n",
    "Here, we will train a fully connected neural net which we can then use for visualization and as a basis for a low-level implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the datasets\n",
    "\n",
    "I am using the train and validation data I created with the function in `data_processing`. The loading of the data to be used in the NN is done with the `DataSet` function from `data_generator.py`. For now I am using the randomly separated data set since this is what I believe is closest to the data sets you guys are using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = DataSet(data_dir, 'SPCAM_outputs_flat_train_random.nc', 'SPCAM_mean_detailed.nc',\n",
    "                    'SPCAM_std_detailed.nc', feature_vars.keys(), flat_input=True)\n",
    "valid_set = DataSet(data_dir, 'SPCAM_outputs_flat_valid_random.nc', 'SPCAM_mean_detailed.nc',\n",
    "                    'SPCAM_std_detailed.nc', feature_vars.keys(), flat_input=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3696230, 150), (924058, 150))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.features.shape, valid_set.features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the model\n",
    "\n",
    "The actual model setup is in `models.py` and the loss functions are in `losses.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fc_model(train_set.features.shape[1], valid_set.targets.shape[1], \n",
    "                 hidden_layers=[1024, 512], \n",
    "                 lr=0.0001, \n",
    "                 loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 1024)              154624    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 42)                21546     \n",
      "=================================================================\n",
      "Total params: 700,970\n",
      "Trainable params: 700,970\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3696230 samples, validate on 924058 samples\n",
      "Epoch 1/10\n",
      "3696230/3696230 [==============================] - 75s - loss: 0.0201 - rmse: 0.0363 - log_loss: -1.5928 - total_error: 90.5786 - unexplained_error: 57.5901 - rsquared: 0.3640 - total_error_avgAx0: 78.6072 - rsquared_avgAx0: 0.2663 - val_loss: 0.0173 - val_rmse: 0.0321 - val_log_loss: -1.6448 - val_total_error: 90.1702 - val_unexplained_error: 43.5502 - val_rsquared: 0.5164 - val_total_error_avgAx0: 78.2253 - val_rsquared_avgAx0: 0.4420\n",
      "Epoch 2/10\n",
      "3696230/3696230 [==============================] - 73s - loss: 0.0170 - rmse: 0.0315 - log_loss: -1.6549 - total_error: 90.5778 - unexplained_error: 42.1389 - rsquared: 0.5341 - total_error_avgAx0: 78.6054 - rsquared_avgAx0: 0.4626 - val_loss: 0.0168 - val_rmse: 0.0311 - val_log_loss: -1.6590 - val_total_error: 90.1702 - val_unexplained_error: 41.1003 - val_rsquared: 0.5437 - val_total_error_avgAx0: 78.2253 - val_rsquared_avgAx0: 0.4734\n",
      "Epoch 3/10\n",
      "3696230/3696230 [==============================] - 73s - loss: 0.0166 - rmse: 0.0308 - log_loss: -1.6645 - total_error: 90.5784 - unexplained_error: 40.6438 - rsquared: 0.5506 - total_error_avgAx0: 78.6061 - rsquared_avgAx0: 0.4816 - val_loss: 0.0165 - val_rmse: 0.0306 - val_log_loss: -1.6676 - val_total_error: 90.1702 - val_unexplained_error: 40.2215 - val_rsquared: 0.5535 - val_total_error_avgAx0: 78.2253 - val_rsquared_avgAx0: 0.4848\n",
      "Epoch 4/10\n",
      " 600064/3696230 [===>..........................] - ETA: 56s - loss: 0.0165 - rmse: 0.0306 - log_loss: -1.6681 - total_error: 90.3615 - unexplained_error: 39.9884 - rsquared: 0.5570 - total_error_avgAx0: 78.4031 - rsquared_avgAx0: 0.4889"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-2af22f782112>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit(train_set.features, train_set.targets, batch_size=512, epochs=10, \n\u001b[0;32m----> 2\u001b[0;31m           validation_data=(valid_set.features, valid_set.targets))\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/cbrain_gpu/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    868\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/.conda/envs/cbrain_gpu/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1505\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1506\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1507\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/cbrain_gpu/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1145\u001b[0m                         \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m                         \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m                     raise TypeError('TypeError while preparing batch. '\n",
      "\u001b[0;32m~/.conda/envs/cbrain_gpu/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_slice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/cbrain_gpu/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_set.features, train_set.targets, batch_size=512, epochs=10, \n",
    "          validation_data=(valid_set.features, valid_set.targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 1024)              154624    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 42)                21546     \n",
      "=================================================================\n",
      "Total params: 963,626\n",
      "Trainable params: 963,626\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = fc_model(train_set.features.shape[1], valid_set.targets.shape[1], \n",
    "                 hidden_layers=[1024, 512, 512], \n",
    "                 lr=0.0001, \n",
    "                 loss='mae')\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3696230 samples, validate on 924058 samples\n",
      "Epoch 1/5\n",
      "3696230/3696230 [==============================] - 87s - loss: 0.0147 - rmse: 0.0270 - log_loss: -1.7449 - total_error: 90.5777 - unexplained_error: 33.6344 - rsquared: 0.6283 - total_error_avgAx0: 78.6071 - rsquared_avgAx0: 0.5712 - val_loss: 0.0147 - val_rmse: 0.0270 - val_log_loss: -1.7431 - val_total_error: 90.1702 - val_unexplained_error: 33.4928 - val_rsquared: 0.6279 - val_total_error_avgAx0: 78.2253 - val_rsquared_avgAx0: 0.5706\n",
      "Epoch 2/5\n",
      "3696230/3696230 [==============================] - 87s - loss: 0.0146 - rmse: 0.0269 - log_loss: -1.7473 - total_error: 90.5788 - unexplained_error: 33.3408 - rsquared: 0.6313 - total_error_avgAx0: 78.6050 - rsquared_avgAx0: 0.5747 - val_loss: 0.0146 - val_rmse: 0.0269 - val_log_loss: -1.7474 - val_total_error: 90.1702 - val_unexplained_error: 33.6649 - val_rsquared: 0.6264 - val_total_error_avgAx0: 78.2253 - val_rsquared_avgAx0: 0.5689\n",
      "Epoch 3/5\n",
      "3696230/3696230 [==============================] - 87s - loss: 0.0146 - rmse: 0.0268 - log_loss: -1.7492 - total_error: 90.5763 - unexplained_error: 33.0902 - rsquared: 0.6342 - total_error_avgAx0: 78.6045 - rsquared_avgAx0: 0.5780 - val_loss: 0.0146 - val_rmse: 0.0269 - val_log_loss: -1.7480 - val_total_error: 90.1702 - val_unexplained_error: 33.1121 - val_rsquared: 0.6322 - val_total_error_avgAx0: 78.2253 - val_rsquared_avgAx0: 0.5756\n",
      "Epoch 4/5\n",
      "3696230/3696230 [==============================] - 87s - loss: 0.0145 - rmse: 0.0267 - log_loss: -1.7509 - total_error: 90.5787 - unexplained_error: 32.8837 - rsquared: 0.6364 - total_error_avgAx0: 78.6057 - rsquared_avgAx0: 0.5806 - val_loss: 0.0145 - val_rmse: 0.0268 - val_log_loss: -1.7498 - val_total_error: 90.1702 - val_unexplained_error: 33.0766 - val_rsquared: 0.6325 - val_total_error_avgAx0: 78.2253 - val_rsquared_avgAx0: 0.5760\n",
      "Epoch 5/5\n",
      "3696230/3696230 [==============================] - 86s - loss: 0.0145 - rmse: 0.0266 - log_loss: -1.7523 - total_error: 90.5784 - unexplained_error: 32.6903 - rsquared: 0.6386 - total_error_avgAx0: 78.6045 - rsquared_avgAx0: 0.5830 - val_loss: 0.0145 - val_rmse: 0.0267 - val_log_loss: -1.7507 - val_total_error: 90.1702 - val_unexplained_error: 32.8527 - val_rsquared: 0.6351 - val_total_error_avgAx0: 78.2253 - val_rsquared_avgAx0: 0.5789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc754142710>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(train_set.features, train_set.targets, batch_size=512, epochs=5, \n",
    "          validation_data=(valid_set.features, valid_set.targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set_cov = DataSet(data_dir, 'SPCAM_outputs_flat_train_random.nc', 'SPCAM_mean_detailed.nc',\n",
    "                    'SPCAM_std_detailed.nc', feature_vars.keys(), flat_input=True,\n",
    "                       convolution=True)\n",
    "valid_set_cov = DataSet(data_dir, 'SPCAM_outputs_flat_valid_random.nc', 'SPCAM_mean_detailed.nc',\n",
    "                    'SPCAM_std_detailed.nc', feature_vars.keys(), flat_input=True,\n",
    "                       convolution=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3696230, 21, 7)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_cov.features[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_cov = conv_model(train_set_cov.features[0].shape[1:], train_set_cov.features[1].shape[1],\n",
    "                   train_set_cov.targets.shape[1], [32, 32, 32, 32, 32, 32], [], 1e-3, 'mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_3 (InputLayer)             (None, 21, 7)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)                (None, 21, 32)        704         input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)                (None, 21, 32)        3104        conv1d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)                (None, 21, 32)        3104        conv1d_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)               (None, 21, 32)        3104        conv1d_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)               (None, 21, 32)        3104        conv1d_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)               (None, 21, 32)        3104        conv1d_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 672)           0           conv1d_12[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_4 (InputLayer)             (None, 3)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 675)           0           flatten_2[0][0]                  \n",
      "                                                                   input_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 42)            28392       concatenate_2[0][0]              \n",
      "====================================================================================================\n",
      "Total params: 44,616\n",
      "Trainable params: 44,616\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_cov.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
