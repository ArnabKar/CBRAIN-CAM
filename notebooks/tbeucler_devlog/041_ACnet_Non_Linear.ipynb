{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tgb - 3/4/2020 - Cleaning up the code for the non-linear ACnet developed in notebook [https://github.com/tbeucler/CBRAIN-CAM/blob/master/notebooks/tbeucler_devlog/035_RH_layers.ipynb]. Includes:  \n",
    "- Moist thermodynamics libraries in both tensorflow and numpy  \n",
    "- Code to build & train non-linear UCnet and ACnet  \n",
    "- Diagnostics of non-linear UCnet/ACnet's performances & energy/mass conservation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0) Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0305 02:24:04.831166 23068480128832 deprecation_wrapper.py:119] From /home/t/Tom.Beucler/SPCAM/CBRAIN-CAM/notebooks/tbeucler_devlog/cbrain/models.py:16: The name tf.keras.layers.CuDNNGRU is deprecated. Please use tf.compat.v1.keras.layers.CuDNNGRU instead.\n",
      "\n",
      "W0305 02:24:04.831747 23068480128832 deprecation_wrapper.py:119] From /home/t/Tom.Beucler/SPCAM/CBRAIN-CAM/notebooks/tbeucler_devlog/cbrain/models.py:16: The name tf.keras.layers.CuDNNLSTM is deprecated. Please use tf.compat.v1.keras.layers.CuDNNLSTM instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/t/Tom.Beucler/SPCAM/CBRAIN-CAM/notebooks/tbeucler_devlog\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0305 02:24:05.387026 23068480128832 deprecation_wrapper.py:119] From /home/t/Tom.Beucler/SPCAM/CBRAIN-CAM/notebooks/tbeucler_devlog/cbrain/utils.py:145: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0305 02:24:05.387856 23068480128832 deprecation_wrapper.py:119] From /home/t/Tom.Beucler/SPCAM/CBRAIN-CAM/notebooks/tbeucler_devlog/cbrain/utils.py:148: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n",
      "W0305 02:24:05.388351 23068480128832 deprecation_wrapper.py:119] From /home/t/Tom.Beucler/SPCAM/CBRAIN-CAM/notebooks/tbeucler_devlog/cbrain/utils.py:148: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/filer/z-sv-pool12c/t/Tom.Beucler/SPCAM/CBRAIN-CAM\n"
     ]
    }
   ],
   "source": [
    "from cbrain.imports import *\n",
    "from cbrain.data_generator import *\n",
    "from cbrain.cam_constants import *\n",
    "from cbrain.losses import *\n",
    "from cbrain.utils import limit_mem\n",
    "from cbrain.layers import *\n",
    "from cbrain.data_generator import DataGenerator\n",
    "import tensorflow as tf\n",
    "import tensorflow.math as tfm\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from cbrain.model_diagnostics import ModelDiagnostics\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as imag\n",
    "import scipy.integrate as sin\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.ticker as mticker\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import pickle\n",
    "\n",
    "TRAINDIR = '/local/Tom.Beucler/SPCAM_PHYS/'\n",
    "DATADIR = '/project/meteo/w2w/A6/S.Rasp/SP-CAM/fluxbypass_aqua/'\n",
    "PREFIX = '8col009_01_'\n",
    "%cd /filer/z-sv-pool12c/t/Tom.Beucler/SPCAM/CBRAIN-CAM\n",
    "\n",
    "# Otherwise tensorflow will use ALL your GPU RAM for no reason\n",
    "limit_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Tensorflow library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1) Moist thermodynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moist thermodynamics library adapted to tf\n",
    "def eliq(T):\n",
    "    a_liq = np.float32(np.array([-0.976195544e-15,-0.952447341e-13,\\\n",
    "                                 0.640689451e-10,\\\n",
    "                      0.206739458e-7,0.302950461e-5,0.264847430e-3,\\\n",
    "                      0.142986287e-1,0.443987641,6.11239921]));\n",
    "    c_liq = np.float32(-80.0)\n",
    "    T0 = np.float32(273.16)\n",
    "    return np.float32(100.0)*tfm.polyval(a_liq,tfm.maximum(c_liq,T-T0))\n",
    "\n",
    "def eice(T):\n",
    "    a_ice = np.float32(np.array([0.252751365e-14,0.146898966e-11,0.385852041e-9,\\\n",
    "                      0.602588177e-7,0.615021634e-5,0.420895665e-3,\\\n",
    "                      0.188439774e-1,0.503160820,6.11147274]));\n",
    "    c_ice = np.float32(np.array([273.15,185,-100,0.00763685,0.000151069,7.48215e-07]))\n",
    "    T0 = np.float32(273.16)\n",
    "    return tf.where(T>c_ice[0],eliq(T),\\\n",
    "                   tf.where(T<=c_ice[1],np.float32(100.0)*(c_ice[3]+tfm.maximum(c_ice[2],T-T0)*\\\n",
    "                   (c_ice[4]+tfm.maximum(c_ice[2],T-T0)*c_ice[5])),\\\n",
    "                           np.float32(100.0)*tfm.polyval(a_ice,T-T0)))\n",
    "\n",
    "def esat(T):\n",
    "    T0 = np.float32(273.16)\n",
    "    T00 = np.float32(253.16)\n",
    "    omtmp = (T-T00)/(T0-T00)\n",
    "    omega = tfm.maximum(np.float32(0.0),tfm.minimum(np.float32(1.0),omtmp))\n",
    "\n",
    "    return tf.where(T>T0,eliq(T),tf.where(T<T00,eice(T),(omega*eliq(T)+(1-omega)*eice(T))))\n",
    "\n",
    "def qv(T,RH,P0,PS,hyam,hybm):\n",
    "    \n",
    "    R = np.float32(287.0)\n",
    "    Rv = np.float32(461.0)\n",
    "    p = P0 * hyam + PS[:, None] * hybm # Total pressure (Pa)\n",
    "    \n",
    "    T = tf.cast(T,tf.float32)\n",
    "    RH = tf.cast(RH,tf.float32)\n",
    "    p = tf.cast(p,tf.float32)\n",
    "    \n",
    "    return R*esat(T)*RH/(Rv*p)\n",
    "    # DEBUG 1\n",
    "    # return esat(T)\n",
    "    \n",
    "def RH(T,qv,P0,PS,hyam,hybm):\n",
    "    R = np.float32(287.0)\n",
    "    Rv = np.float32(461.0)\n",
    "    p = P0 * hyam + PS[:, None] * hybm # Total pressure (Pa)\n",
    "    \n",
    "    T = tf.cast(T,tf.float32)\n",
    "    qv = tf.cast(qv,tf.float32)\n",
    "    p = tf.cast(p,tf.float32)\n",
    "    \n",
    "    return Rv*p*qv/(R*esat(T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2) Conversion Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1) From relative to specific humidity (inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RH2QV(Layer):\n",
    "    def __init__(self, inp_subQ, inp_divQ, inp_subRH, inp_divRH, hyam, hybm, **kwargs):\n",
    "        \"\"\"\n",
    "        Call using ([input])\n",
    "        Converts specific humidity to relative humidity and renormalizes all inputs\n",
    "        in preparation for ACnet\n",
    "        Assumes\n",
    "        prior: [RHBP, \n",
    "        QCBP, QIBP, TBP, VBP, Qdt_adiabatic, QCdt_adiabatic, QIdt_adiabatic, \n",
    "        Tdt_adiabatic, Vdt_adiabatic, PS, SOLIN, SHFLX, LHFLX]\n",
    "        Returns\n",
    "        post(erior): [QBP, \n",
    "        QCBP, QIBP, TBP, VBP, Qdt_adiabatic, QCdt_adiabatic, QIdt_adiabatic, \n",
    "        Tdt_adiabatic, Vdt_adiabatic, PS, SOLIN, SHFLX, LHFLX]\n",
    "        \"\"\"\n",
    "        self.inp_subQ, self.inp_divQ, self.inp_subRH, self.inp_divRH, self.hyam, self.hybm = \\\n",
    "            np.array(inp_subQ), np.array(inp_divQ), np.array(inp_subRH), np.array(inp_divRH), \\\n",
    "        np.array(hyam), np.array(hybm)\n",
    "        # Define variable indices here\n",
    "        # Input\n",
    "        self.QBP_idx = slice(0,30)\n",
    "        self.TBP_idx = slice(90,120)\n",
    "        self.PS_idx = 300\n",
    "        self.SHFLX_idx = 302\n",
    "        self.LHFLX_idx = 303\n",
    "\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'inp_subQ': list(self.inp_subQ), 'inp_divQ': list(self.inp_divQ),\n",
    "                  'inp_subRH': list(self.inp_subRH), 'inp_divRH': list(self.inp_divRH),\n",
    "                  'hyam': list(self.hyam),'hybm': list(self.hybm)}\n",
    "        base_config = super().get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "    \n",
    "    def call(self, arrs):\n",
    "        prior = arrs\n",
    "        \n",
    "        # Denormalize T,RH,PS to get them in physical units\n",
    "        Tprior = prior[:,self.TBP_idx]*self.inp_divRH[self.TBP_idx]+self.inp_subRH[self.TBP_idx]\n",
    "        RHprior = prior[:,self.QBP_idx]*self.inp_divRH[self.QBP_idx]+self.inp_subRH[self.QBP_idx]\n",
    "        PSprior = prior[:,self.PS_idx]*self.inp_divRH[self.PS_idx]+self.inp_subRH[self.PS_idx]\n",
    "        \n",
    "        # Calculate qv from RH,PS,T using moist thermo library & normalize\n",
    "        qvprior = (qv(Tprior,RHprior,P0,PSprior,self.hyam,self.hybm)-\\\n",
    "                    self.inp_subQ[self.QBP_idx])/self.inp_divQ[self.QBP_idx]\n",
    "        \n",
    "        # Concatenate renormalized inputs to form final input vector\n",
    "        post = tf.concat([tf.cast(qvprior,tf.float32),\n",
    "                          ((prior[:,30:]*self.inp_divRH[30:]+self.inp_subRH[30:])\\\n",
    "                           -self.inp_subQ[30:])/self.inp_divQ[30:]\\\n",
    "                         ], axis=1)\n",
    "        \n",
    "        return post\n",
    "\n",
    "    def compute_output_shape(self,input_shape):\n",
    "        \"\"\"Input shape + 1\"\"\"\n",
    "        return (input_shape[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2) From specific to relative humidity time-tendency (output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dQVdt2dRHdt(Layer):\n",
    "    def __init__(self, inp_subQ, inp_divQ, norm_qQ, norm_TQ, inp_subRH, inp_divRH, norm_qRH, hyam, hybm, **kwargs):\n",
    "        \"\"\"\n",
    "        Call using ([input_qv,output])\n",
    "        Converts specific humidity tendency output to relative humidity tendency output\n",
    "        Assumes\n",
    "        prior: [PHQ, PHCLDLIQ, PHCLDICE, TPHYSTND, QRL, QRS, DTVKE, FSNT, FSNS, FLNT, FLNS, PRECT, PRECTEND, PRECST, PRECSTEN]\n",
    "        Returns\n",
    "        post(erior): [dRHdt, PHCLDLIQ, PHCLDICE, TPHYSTND, QRL, QRS, DTVKE, FSNT, FSNS, FLNT, FLNS, PRECT, PRECTEND, PRECST, PRECSTEN]\n",
    "        \"\"\"\n",
    "        self.inp_subQ, self.inp_divQ, self.norm_qQ, self.norm_TQ, \\\n",
    "        self.inp_subRH, self.inp_divRH, self.norm_qRH, \\\n",
    "        self.hyam, self.hybm = \\\n",
    "            np.array(inp_subQ), np.array(inp_divQ), \\\n",
    "        np.array(norm_qQ), np.array(norm_TQ),\\\n",
    "        np.array(inp_subRH), np.array(inp_divRH), np.array(norm_qRH), \\\n",
    "        np.array(hyam), np.array(hybm)\n",
    "        # Define variable indices here\n",
    "        # Input\n",
    "        self.PHQ_idx = slice(0,30)\n",
    "        self.QBP_idx = slice(0,30)\n",
    "        self.TBP_idx = slice(90,120)\n",
    "        self.PS_idx = 300\n",
    "        self.SHFLX_idx = 302\n",
    "        self.LHFLX_idx = 303\n",
    "\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'inp_subQ': list(self.inp_subQ), 'inp_divQ': list(self.inp_divQ),\n",
    "                  'norm_qQ': list(self.norm_qQ),'norm_TQ':list(self.norm_TQ),\n",
    "                  'inp_subRH': list(self.inp_subRH), 'inp_divRH': list(self.inp_divRH),\n",
    "                  'norm_qRH': list(self.norm_qRH), \n",
    "                  'hyam': list(self.hyam),'hybm': list(self.hybm)}\n",
    "        base_config = super().get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "    \n",
    "    def call(self, arrs):\n",
    "        inp, prior = arrs\n",
    "        \n",
    "        # Denormalize specific humidity, temperature and surface pressure to convert them to physical units\n",
    "        Qprior = inp[:,self.QBP_idx]*self.inp_divQ[self.QBP_idx]+self.inp_subQ[self.QBP_idx]\n",
    "        Tprior = inp[:,self.TBP_idx]*self.inp_divQ[self.TBP_idx]+self.inp_subQ[self.TBP_idx]\n",
    "        PSprior = inp[:,self.PS_idx]*self.inp_divQ[self.PS_idx]+self.inp_subQ[self.PS_idx]\n",
    "        \n",
    "        # Calculate specific humidity after physics using its time-tendency\n",
    "        dqvdtprior = prior[:,self.QBP_idx]/self.norm_qQ\n",
    "        Q2prior = Qprior+DT*dqvdtprior\n",
    "        \n",
    "        # Calculate temperature after physics using its time-tendency\n",
    "        dTdtprior = prior[:,self.TBP_idx]/self.norm_TQ\n",
    "        T2prior = Tprior+DT*dTdtprior\n",
    "        \n",
    "        # Infer the relative humidity tendency from relative humidity before & after physics\n",
    "        RHprior = RH(Tprior,Qprior,P0,PSprior,self.hyam,self.hybm)\n",
    "        RH2prior = RH(T2prior,Q2prior,P0,PSprior,self.hyam,self.hybm)\n",
    "        dRHdtprior = ((RH2prior-RHprior)/DT)*self.norm_qRH\n",
    "        \n",
    "        # Concatenate the relative humidity tendency with the remaining outputs\n",
    "        post = tf.concat([dRHdtprior,prior[:,30:]], axis=1)\n",
    "        \n",
    "        return post\n",
    "\n",
    "    def compute_output_shape(self,input_shape):\n",
    "        \"\"\"Input shape\"\"\"\n",
    "        return (input_shape[0][0],input_shape[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Build UCnet_NL and ACnet_NL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1) Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/filer/z-sv-pool12c/t/Tom.Beucler/SPCAM/CBRAIN-CAM\n"
     ]
    }
   ],
   "source": [
    "%cd /filer/z-sv-pool12c/t/Tom.Beucler/SPCAM/CBRAIN-CAM\n",
    "scale_dict = load_pickle('./nn_config/scale_dicts/009_Wm2_scaling.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_dict['dRHdt'] = 5*L_S/G, # Factor 5 in loss to give std of dRH/dt similar weight as std of dT/dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1) Generator using RH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_vars = ['RH', 'QCBP', 'QIBP', 'TBP', 'VBP', \n",
    "           'Qdt_adiabatic', 'QCdt_adiabatic', 'QIdt_adiabatic', 'Tdt_adiabatic', 'Vdt_adiabatic',\n",
    "           'PS', 'SOLIN', 'SHFLX', 'LHFLX']\n",
    "out_vars = ['dRHdt', 'PHCLDLIQ', 'PHCLDICE', 'TPHYSTND', 'QRL', 'QRS', 'DTVKE', \n",
    "            'FSNT', 'FSNS', 'FLNT', 'FLNS', 'PRECT', 'PRECTEND', 'PRECST', 'PRECSTEN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINFILE = '8col009RH_01_train.nc'\n",
    "NORMFILE = '8col009RH_01_norm.nc'\n",
    "VALIDFILE = '8col009RH_01_valid.nc'\n",
    "TESTFILE = '8col009RH_01_test.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = DataGenerator(\n",
    "    data_fn = TRAINDIR+TRAINFILE,\n",
    "    input_vars = in_vars,\n",
    "    output_vars = out_vars,\n",
    "    norm_fn = TRAINDIR+NORMFILE,\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dict,\n",
    "    batch_size=1024,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_gen = DataGenerator(\n",
    "    data_fn = TRAINDIR+VALIDFILE,\n",
    "    input_vars = in_vars,\n",
    "    output_vars = out_vars,\n",
    "    norm_fn = TRAINDIR+NORMFILE,\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dict,\n",
    "    batch_size=1024,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = DataGenerator(\n",
    "    data_fn = TRAINDIR+TESTFILE,\n",
    "    input_vars = in_vars,\n",
    "    output_vars = out_vars,\n",
    "    norm_fn = TRAINDIR+NORMFILE,\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dict,\n",
    "    batch_size=1024,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2) Generators using qv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINFILEQ = '8col009_01_train.nc'\n",
    "VALIDFILEQ = '8col009_01_valid.nc'\n",
    "NORMFILEQ = '8col009_01_norm.nc'\n",
    "TESTFILEQ = '8col009_01_test.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_dictQ = load_pickle('./nn_config/scale_dicts/009_Wm2_scaling.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_varsQ = ['QBP', 'QCBP', 'QIBP', 'TBP', 'VBP', \n",
    "           'Qdt_adiabatic', 'QCdt_adiabatic', 'QIdt_adiabatic', 'Tdt_adiabatic', 'Vdt_adiabatic',\n",
    "           'PS', 'SOLIN', 'SHFLX', 'LHFLX']\n",
    "out_varsQ = ['PHQ', 'PHCLDLIQ', 'PHCLDICE', 'TPHYSTND', 'QRL', 'QRS', 'DTVKE', \n",
    "            'FSNT', 'FSNS', 'FLNT', 'FLNS', 'PRECT', 'PRECTEND', 'PRECST', 'PRECSTEN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_genQ = DataGenerator(\n",
    "    data_fn = TRAINDIR+TRAINFILEQ,\n",
    "    input_vars = in_varsQ,\n",
    "    output_vars = out_varsQ,\n",
    "    norm_fn = TRAINDIR+NORMFILEQ,\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dictQ,\n",
    "    batch_size=1024,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_genQ = DataGenerator(\n",
    "    data_fn = TRAINDIR+VALIDFILEQ,\n",
    "    input_vars = in_varsQ,\n",
    "    output_vars = out_varsQ,\n",
    "    norm_fn = TRAINDIR+NORMFILEQ,\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dictQ,\n",
    "    batch_size=1024,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_genQ = DataGenerator(\n",
    "    data_fn = TRAINDIR+TESTFILEQ,\n",
    "    input_vars = in_varsQ,\n",
    "    output_vars = out_varsQ,\n",
    "    norm_fn = TRAINDIR+NORMFILEQ,\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dictQ,\n",
    "    batch_size=1024,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2) Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1) UCnet NL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_genQ' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/api/_v1/keras/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m304\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m inpQ = RH2QV(inp_subQ=train_genQ.input_transform.sub, \n\u001b[0m\u001b[1;32m      3\u001b[0m              \u001b[0minp_divQ\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_genQ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_transform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m              \u001b[0minp_subRH\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_transform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m              \u001b[0minp_divRH\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_transform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_genQ' is not defined"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(304,))\n",
    "inpQ = RH2QV(inp_subQ=train_genQ.input_transform.sub, \n",
    "             inp_divQ=train_genQ.input_transform.div, \n",
    "             inp_subRH=train_gen.input_transform.sub, \n",
    "             inp_divRH=train_gen.input_transform.div, \n",
    "             hyam=hyam, hybm=hybm)(inp)\n",
    "densout = Dense(512, activation='linear')(inpQ)\n",
    "densout = LeakyReLU(alpha=0.3)(densout)\n",
    "for i in range (4):\n",
    "    densout = Dense(512, activation='linear')(densout)\n",
    "    densout = LeakyReLU(alpha=0.3)(densout)\n",
    "outQ = Dense(218, activation='linear')(densout)\n",
    "out = dQVdt2dRHdt(inp_subQ=train_genQ.input_transform.sub,\n",
    "                  inp_divQ=train_genQ.input_transform.div,\n",
    "                  norm_qQ=scale_dictQ['PHQ'], \n",
    "                  inp_subRH=train_gen.input_transform.sub, \n",
    "                  inp_divRH=train_gen.input_transform.div, \n",
    "                  norm_qRH=scale_dict['dRHdt'], \n",
    "                  hyam=hyam, hybm=hybm)([inpQ, outQ])\n",
    "UCnet_NL = tf.keras.models.Model(inp, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'UCnetNL_20'\n",
    "path_HDF5 = '/local/Tom.Beucler/SPCAM_PHYS/HDF5_DATA/'\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "mcp_save = ModelCheckpoint(path_HDF5+name+'.hdf5',save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UCnet_NL.compile(tf.keras.optimizers.RMSprop(), loss=mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nep = 10\n",
    "UCnet_NL.fit_generator(train_gen, epochs=Nep, validation_data=valid_gen,\\\n",
    "              callbacks=[earlyStopping, mcp_save])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2) ACnet NL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(304,))\n",
    "inpQ = RH2QV(inp_subQ=train_genQ.input_transform.sub, \n",
    "             inp_divQ=train_genQ.input_transform.div, \n",
    "             inp_subRH=train_gen.input_transform.sub, \n",
    "             inp_divRH=train_gen.input_transform.div, \n",
    "             hyam=hyam, hybm=hybm)(inp)\n",
    "densout = Dense(512, activation='linear')(inpQ)\n",
    "densout = LeakyReLU(alpha=0.3)(densout)\n",
    "for i in range (4):\n",
    "    densout = Dense(512, activation='linear')(densout)\n",
    "    densout = LeakyReLU(alpha=0.3)(densout)\n",
    "densout = Dense(214, activation='linear')(densout)\n",
    "densout = LeakyReLU(alpha=0.3)(densout)\n",
    "surfout = SurRadLayer(\n",
    "    inp_div=train_genQ.input_transform.div,\n",
    "    inp_sub=train_genQ.input_transform.sub,\n",
    "    norm_q=scale_dict['PHQ'],\n",
    "    hyai=hyai, hybi=hybi\n",
    ")([inpQ, densout])\n",
    "massout = MassConsLayer(\n",
    "    inp_div=train_genQ.input_transform.div,\n",
    "    inp_sub=train_genQ.input_transform.sub,\n",
    "    norm_q=scale_dict['PHQ'],\n",
    "    hyai=hyai, hybi=hybi\n",
    ")([inpQ, surfout])\n",
    "enthout = EntConsLayer(\n",
    "    inp_div=train_genQ.input_transform.div,\n",
    "    inp_sub=train_genQ.input_transform.sub,\n",
    "    norm_q=scale_dict['PHQ'],\n",
    "    hyai=hyai, hybi=hybi\n",
    ")([inpQ, massout])\n",
    "out = dQVdt2dRHdt(inp_subQ=train_genQ.input_transform.sub,\n",
    "                  inp_divQ=train_genQ.input_transform.div,\n",
    "                  norm_qQ=scale_dictQ['PHQ'],\n",
    "                  norm_TQ=scale_dictQ['TPHYSTND'],\n",
    "                  inp_subRH=train_gen.input_transform.sub, \n",
    "                  inp_divRH=train_gen.input_transform.div, \n",
    "                  norm_qRH=scale_dict['dRHdt'], \n",
    "                  hyam=hyam, hybm=hybm)([inpQ, enthout])\n",
    "ACnet_NL = tf.keras.models.Model(inp, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'ACnetNL_20'\n",
    "path_HDF5 = '/local/Tom.Beucler/SPCAM_PHYS/HDF5_DATA/'\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "mcp_save = ModelCheckpoint(path_HDF5+name+'.hdf5',save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACnet_NL.compile(tf.keras.optimizers.RMSprop(), loss=mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nep = 10\n",
    "ACnet_NL.fit_generator(train_gen, epochs=Nep, validation_data=valid_gen,\\\n",
    "              callbacks=[earlyStopping, mcp_save])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Numpy library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='np_destination'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1) Moist thermodynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliq(T):\n",
    "    a_liq = np.array([-0.976195544e-15,-0.952447341e-13,0.640689451e-10,0.206739458e-7,0.302950461e-5,0.264847430e-3,0.142986287e-1,0.443987641,6.11239921]);\n",
    "    c_liq = -80\n",
    "    T0 = 273.16\n",
    "    return 100*np.polyval(a_liq,np.maximum(c_liq,T-T0))\n",
    "\n",
    "def deliqdT(T):\n",
    "    a_liq = np.array([-0.599634321e-17,-0.792933209e-14,-0.604119582e-12,0.385208005e-9,0.103167413e-6,0.121167162e-4,0.794747212e-3,0.285976452e-1,0.443956472])\n",
    "    c_liq = -80\n",
    "    T0 = 273.16\n",
    "    return 100*np.polyval(a_liq,np.maximum(c_liq,T-T0))\n",
    "\n",
    "def eice(T):\n",
    "    a_ice = np.array([0.252751365e-14,0.146898966e-11,0.385852041e-9,0.602588177e-7,0.615021634e-5,0.420895665e-3,0.188439774e-1,0.503160820,6.11147274]);\n",
    "    c_ice = np.array([273.15,185,-100,0.00763685,0.000151069,7.48215e-07])\n",
    "    T0 = 273.16\n",
    "    return (T>c_ice[0])*eliq(T)+\\\n",
    "(T<=c_ice[0])*(T>c_ice[1])*100*np.polyval(a_ice,T-T0)+\\\n",
    "(T<=c_ice[1])*100*(c_ice[3]+np.maximum(c_ice[2],T-T0)*(c_ice[4]+np.maximum(c_ice[2],T-T0)*c_ice[5]))\n",
    "\n",
    "def deicedT(T):\n",
    "    a_ice = np.array([0.497275778e-16,0.390204672e-13,0.132073448e-10,0.255653718e-8,0.312668753e-6,0.249065913e-4,0.126710138e-2,0.377174432e-1,0.503223089])\n",
    "    c_ice = np.array([273.15,185,-100,0.0013186,2.60269e-05,1.28676e-07])\n",
    "    T0 = 273.16\n",
    "    return (T>c_ice[0])*deliqdT(T)+\\\n",
    "(T<=c_ice[0])*(T>c_ice[1])*100*np.polyval(a_ice,T-T0)+\\\n",
    "(T<=c_ice[1])*100*(c_ice[3]+np.maximum(c_ice[2],T-T0)*(c_ice[4]+np.maximum(c_ice[2],T-T0)*c_ice[5]))\n",
    "\n",
    "def esat(T):\n",
    "    T0 = 273.16\n",
    "    T00 = 253.16\n",
    "    omega = np.maximum(0,np.minimum(1,(T-T00)/(T0-T00)))\n",
    "    \n",
    "    return (T>T0)*eliq(T)+(T<T00)*eice(T)+(T<=T0)*(T>=T00)*(omega*eliq(T)+(1-omega)*eice(T))\n",
    "\n",
    "def RH(T,qv,P0,PS,hyam,hybm):\n",
    "    R = 287\n",
    "    Rv = 461\n",
    "    p = np.moveaxis((hyam*P0+hybm*PS).values,0,1) # Total pressure (Pa)\n",
    "    return Rv*p*qv/(R*esat(T))\n",
    "\n",
    "def qv(T,RH,P0,PS,hyam,hybm):\n",
    "    R = 287\n",
    "    Rv = 461\n",
    "    Bsize = np.shape(T)[0]\n",
    "    p = np.tile(hyam*P0,(Bsize,1))+np.tile(hybm,(Bsize,1))*np.tile(PS,(30,1)).T\n",
    "    return R*esat(T)*RH/(Rv*p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2) Mass/Energy/Radiation checkers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mass_res_diagno(inp_div,inp_sub,norm_q,inp,pred):\n",
    "    # Input\n",
    "    PS_idx = 300\n",
    "    LHFLX_idx = 303\n",
    "\n",
    "    # Output\n",
    "    PHQ_idx = slice(0, 30)\n",
    "    PHCLDLIQ_idx = slice(30, 60)\n",
    "    PHCLDICE_idx = slice(60, 90)\n",
    "    PRECT_idx = 214\n",
    "    PRECTEND_idx = 215\n",
    "\n",
    "    # 1. Compute dP_tilde\n",
    "    dP_tilde = compute_dP_tilde(inp[:, PS_idx],  inp_div[PS_idx], inp_sub[PS_idx], norm_q, hyai, hybi)\n",
    "\n",
    "    # 2. Compute water integral\n",
    "    WATINT = np.sum(dP_tilde *(pred[:, PHQ_idx] + pred[:, PHCLDLIQ_idx] + pred[:, PHCLDICE_idx]), axis=1)\n",
    "#     print('PHQ',np.mean(np.sum(dP_tilde*pred[:,PHQ_idx],axis=1)))\n",
    "#     print('PHCLQ',np.mean(np.sum(dP_tilde*pred[:,PHCLDLIQ_idx],axis=1)))\n",
    "#     print('PHICE',np.mean(np.sum(dP_tilde*pred[:,PHCLDICE_idx],axis=1)))\n",
    "\n",
    "    # 3. Compute latent heat flux and precipitation forcings\n",
    "    LHFLX = inp[:, LHFLX_idx] * inp_div[LHFLX_idx] + inp_sub[LHFLX_idx]\n",
    "    PREC = pred[:, PRECT_idx] + pred[:, PRECTEND_idx]\n",
    "\n",
    "    # 4. Compute water mass residual\n",
    "#     print('LHFLX',np.mean(LHFLX))\n",
    "#     print('PREC',np.mean(PREC))\n",
    "#     print('WATINT',np.mean(WATINT))\n",
    "    WATRES = LHFLX - PREC - WATINT\n",
    "    #print('WATRES',np.mean(WATRES))\n",
    "\n",
    "    return np.square(WATRES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ent_res_diagno(inp_div,inp_sub,norm_q,inp,pred):\n",
    "\n",
    "    # Input\n",
    "    PS_idx = 300\n",
    "    SHFLX_idx = 302\n",
    "    LHFLX_idx = 303\n",
    "\n",
    "    # Output\n",
    "    PHQ_idx = slice(0, 30)\n",
    "    PHCLDLIQ_idx = slice(30, 60)\n",
    "    PHCLDICE_idx = slice(60, 90)\n",
    "    TPHYSTND_idx = slice(90, 120)\n",
    "    DTVKE_idx = slice(180, 210)\n",
    "    FSNT_idx = 210\n",
    "    FSNS_idx = 211\n",
    "    FLNT_idx = 212\n",
    "    FLNS_idx = 213\n",
    "    PRECT_idx = 214\n",
    "    PRECTEND_idx = 215\n",
    "    PRECST_idx = 216\n",
    "    PRECSTEND_idx = 217\n",
    "\n",
    "    # 1. Compute dP_tilde\n",
    "    dP_tilde = compute_dP_tilde(inp[:, PS_idx],  inp_div[PS_idx], inp_sub[PS_idx], norm_q, hyai, hybi)\n",
    "\n",
    "    # 2. Compute net energy input from phase change and precipitation\n",
    "    PHAS = L_I / L_V * (\n",
    "            (pred[:, PRECST_idx] + pred[:, PRECSTEND_idx]) -\n",
    "            (pred[:, PRECT_idx] + pred[:, PRECTEND_idx])\n",
    "    )\n",
    "\n",
    "    # 3. Compute net energy input from radiation, SHFLX and TKE\n",
    "    RAD = (pred[:, FSNT_idx] - pred[:, FSNS_idx] -\n",
    "           pred[:, FLNT_idx] + pred[:, FLNS_idx])\n",
    "    SHFLX = (inp[:, SHFLX_idx] * inp_div[SHFLX_idx] +\n",
    "             inp_sub[SHFLX_idx])\n",
    "    KEDINT = np.sum(dP_tilde * pred[:, DTVKE_idx], 1)\n",
    "\n",
    "    # 4. Compute tendency of vapor due to phase change\n",
    "    LHFLX = (inp[:, LHFLX_idx] * inp_div[LHFLX_idx] +\n",
    "             inp_sub[LHFLX_idx])\n",
    "    VAPINT = np.sum(dP_tilde * pred[:, PHQ_idx], 1)\n",
    "    SPDQINT = (VAPINT - LHFLX) * L_S / L_V\n",
    "\n",
    "    # 5. Same for cloud liquid water tendency\n",
    "    SPDQCINT = np.sum(dP_tilde * pred[:, PHCLDLIQ_idx], 1) * L_I / L_V\n",
    "\n",
    "    # 6. And the same for T but remember residual is still missing\n",
    "    DTINT = np.sum(dP_tilde * pred[:, TPHYSTND_idx], 1)\n",
    "\n",
    "    # 7. Compute enthalpy residual\n",
    "    ENTRES = SPDQINT + SPDQCINT + DTINT - RAD - SHFLX - PHAS - KEDINT\n",
    "\n",
    "    return np.square(ENTRES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lw_res_diagno(inp_div,inp_sub,norm_q,inp,pred):\n",
    "\n",
    "    # Input\n",
    "    PS_idx = 300\n",
    "\n",
    "    # Output\n",
    "    QRL_idx = slice(120, 150)\n",
    "    FLNS_idx = 213\n",
    "    FLNT_idx = 212\n",
    "\n",
    "    # 1. Compute dP_tilde\n",
    "    dP_tilde = compute_dP_tilde(inp[:, PS_idx],  inp_div[PS_idx], inp_sub[PS_idx], norm_q, hyai, hybi)\n",
    "\n",
    "    # 2. Compute longwave integral\n",
    "    LWINT = np.sum(dP_tilde *pred[:, QRL_idx], axis=1)\n",
    "\n",
    "    # 3. Compute net longwave flux from lw fluxes at top and bottom\n",
    "    LWNET = pred[:, FLNS_idx] - pred[:, FLNT_idx]\n",
    "\n",
    "    # 4. Compute water mass residual\n",
    "    LWRES = LWINT-LWNET\n",
    "\n",
    "    return np.square(LWRES)\n",
    "\n",
    "def sw_res_diagno(inp_div,inp_sub,norm_q,inp,pred):\n",
    "\n",
    "    # Input\n",
    "    PS_idx = 300\n",
    "\n",
    "    # Output\n",
    "    QRS_idx = slice(150, 180)\n",
    "    FSNS_idx = 211\n",
    "    FSNT_idx = 210\n",
    "\n",
    "    # 1. Compute dP_tilde\n",
    "    dP_tilde = compute_dP_tilde(inp[:, PS_idx],  inp_div[PS_idx], inp_sub[PS_idx], norm_q, hyai, hybi)\n",
    "\n",
    "    # 2. Compute longwave integral\n",
    "    SWINT = np.sum(dP_tilde *pred[:, QRS_idx], axis=1)\n",
    "\n",
    "    # 3. Compute net longwave flux from lw fluxes at top and bottom\n",
    "    SWNET = pred[:, FSNT_idx] - pred[:, FSNS_idx]\n",
    "\n",
    "    # 4. Compute water mass residual\n",
    "    SWRES = SWINT-SWNET\n",
    "\n",
    "    return np.square(SWRES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tot_res_diagno(inp_div,inp_sub,norm_q,inp,pred):\n",
    "    return 0.25*(mass_res_diagno(inp_div,inp_sub,norm_q,inp,pred)+\\\n",
    "                ent_res_diagno(inp_div,inp_sub,norm_q,inp,pred)+\\\n",
    "                lw_res_diagno(inp_div,inp_sub,norm_q,inp,pred)+\\\n",
    "                sw_res_diagno(inp_div,inp_sub,norm_q,inp,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Link to diagnostics](#diagnostics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Diagnostics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1) Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_HDF5 = '/local/Tom.Beucler/SPCAM_PHYS/HDF5_DATA/'\n",
    "NNarray = ['035_UCnet.hdf5','UCnetNL_10.hdf5','ACnetNL_10.hdf5']\n",
    "NNname = ['UCnet','UCnet_{NL}','ACnet_{NL}'] # TODO: Add UCnet_NL\n",
    "dict_lay = {'SurRadLayer':SurRadLayer,'MassConsLayer':MassConsLayer,'EntConsLayer':EntConsLayer,\n",
    "            'RH2QV':RH2QV,'dQVdt2dRHdt':dQVdt2dRHdt,\n",
    "           'eliq':eliq,'eice':eice,'esat':esat,'qv':qv,'RH':RH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0305 02:24:11.949509 23068480128832 deprecation.py:506] From /home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0305 02:24:11.951040 23068480128832 deprecation.py:506] From /home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0305 02:24:11.952066 23068480128832 deprecation.py:506] From /home/t/Tom.Beucler/miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch-local/Tom.Beucler/SPCAM_PHYS/HDF5_DATA\n",
      "NN name is  035_UCnet.hdf5\n",
      "NN name is  UCnetNL_10.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0305 02:24:13.286235 23068480128832 deprecation.py:323] From <ipython-input-2-d8b861a31dd8>:20: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN name is  ACnetNL_10.hdf5\n"
     ]
    }
   ],
   "source": [
    "NN = {}; md = {};\n",
    "%cd $TRAINDIR/HDF5_DATA\n",
    "for i,NNs in enumerate(NNarray):\n",
    "    print('NN name is ',NNs)\n",
    "    path = path_HDF5+NNs\n",
    "    NN[NNs] = load_model(path,custom_objects=dict_lay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2) Calculate square error and physical constraints residual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Link to numpy library for diagnostics](#np_destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='diagnostics'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = valid_gen\n",
    "genQ = valid_genQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SE = {}\n",
    "# TRES = {}\n",
    "\n",
    "# for iNNs,NNs in enumerate(['UCnetNL_10.hdf5','ACnetNL_10.hdf5']):\n",
    "#     SE[NNs] = np.zeros((1,218))\n",
    "#     TRES[NNs] = np.zeros((1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "SE = {}\n",
    "TRES = {}\n",
    "MSE = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spl= 539                   \r"
     ]
    }
   ],
   "source": [
    "spl = 0\n",
    "while gen[spl][0].size>0: #spl is sample number\n",
    "    \n",
    "    print('spl=',spl,'                  ',end='\\r')\n",
    "    \n",
    "    inp = gen[spl][0]\n",
    "    truth = gen[spl][1]\n",
    "    \n",
    "    inp_phys = inp*gen.input_transform.div+gen.input_transform.sub\n",
    "    \n",
    "    for iNNs,NNs in enumerate(NNarray):\n",
    "        \n",
    "        pred = NN[NNs].predict_on_batch(inp)\n",
    "\n",
    "        se = (pred-truth)**2\n",
    "\n",
    "        pred_phys = pred/gen.output_transform.scale\n",
    "\n",
    "        QV1 = qv(inp_phys[:,90:120],inp_phys[:,:30],P0,inp_phys[:,300],hyam,hybm)\n",
    "        QV2 = qv(inp_phys[:,90:120]+DT*pred_phys[:,90:120],\n",
    "                 inp_phys[:,:30]+DT*pred_phys[:,:30],P0,inp_phys[:,300],hyam,hybm)\n",
    "        dQVdt = train_genQ.output_transform.scale[:30]*(QV2-QV1)/DT\n",
    "\n",
    "        predQ = np.copy(pred)\n",
    "        predQ[:,:30] = dQVdt\n",
    "\n",
    "        tresid = tot_res_diagno(gen.input_transform.div,gen.input_transform.sub,\n",
    "                                genQ.output_transform.scale[:30],inp,predQ)\n",
    "        \n",
    "        if spl==0: SE[NNs] = se; TRES[NNs] = tresid; MSE[NNs] = np.mean(se,axis=1);\n",
    "        else: \n",
    "            SE[NNs] += se; \n",
    "            TRES[NNs] = np.concatenate((TRES[NNs],tresid),axis=0); \n",
    "            MSE[NNs] = np.concatenate((MSE[NNs],np.mean(se,axis=1)),axis=0);\n",
    "        \n",
    "    spl += 1\n",
    "    \n",
    "for iNNs,NNs in enumerate(NNarray): SE[NNs] /= spl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.mean(SE['ACnetNL_10.hdf5'][:,:30],axis=0))\n",
    "plt.plot(np.mean(SE['UCnetNL_10.hdf5'][:,:30],axis=0))\n",
    "plt.plot(np.mean(SE['035_UCnet.hdf5'][:,:30],axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(TRES['ACnetNL_10.hdf5'],bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(TRES['UCnetNL_10.hdf5'],bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(TRES['035_UCnet.hdf5'],bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(TRES['UCnetNL_10.hdf5'],bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(TRES['ACnetNL_10.hdf5']),np.std(TRES['ACnetNL_10.hdf5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(TRES['UCnetNL_10.hdf5']),np.std(TRES['UCnetNL_10.hdf5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(TRES['035_UCnet.hdf5']),np.std(TRES['035_UCnet.hdf5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3) Save reduced data in PKL format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathPKL = '/home/t/Tom.Beucler/SPCAM/CBRAIN-CAM/notebooks/tbeucler_devlog/PKL_DATA/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = open(pathPKL+'2020_03_04_validgen041.pkl','wb')\n",
    "S = {\"TRES\":TRES,\"MSE\":MSE,\"SE\":SE}\n",
    "pickle.dump(S,hf)\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
