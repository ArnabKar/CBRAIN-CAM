{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tb - 6/25/2022 - Testing the hypothesis that low-complexity models are more descriptive when phrased using climate-invariant inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfspool-0/home/tbeucler/CBRAIN-CAM/notebooks/tbeucler_devlog\n"
     ]
    }
   ],
   "source": [
    "from cbrain.climate_invariant import *\n",
    "from cbrain.climate_invariant_utils import *\n",
    "import pickle\n",
    "#import h5netcdf\n",
    "import time\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cbrain.imports import *\n",
    "from cbrain.utils import *\n",
    "from cbrain.normalization import *\n",
    "\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "tf.config.experimental.set_memory_growth(physical_devices[1], True)\n",
    "tf.config.experimental.set_memory_growth(physical_devices[2], True)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = '/DFS-L/DATA/pritchard/tbeucler/SPCAM/SPCAM_PHYS/'\n",
    "path_array = {}\n",
    "climate_str = ['cold','hot','both']\n",
    "set_str = ['train','valid','test']\n",
    "test_clim_str = ['cold','hot','both','medium']\n",
    "\n",
    "path_array['cold'] = [path_data+'2021_03_18_O3_TRAIN_M4K_shuffle.nc',\n",
    "                      path_data+'2021_03_18_O3_VALID_M4K.nc',\n",
    "                      path_data+'2021_03_18_O3_TEST_M4K.nc']\n",
    "path_array['hot'] = [path_data+'2021_03_18_O3_TRAIN_P4K_shuffle.nc',\n",
    "                     path_data+'2021_03_18_O3_VALID_P4K.nc',\n",
    "                     path_data+'2021_03_18_O3_TEST_P4K.nc']\n",
    "path_array['both'] = [path_data+'2022_04_18_TRAIN_M4K_P4K_shuffle.nc',\n",
    "                      path_data+'2022_04_18_VALID_M4K_P4K.nc',\n",
    "                      path_data+'2022_04_18_TEST_M4K_P4K.nc']\n",
    "path_array['medium'] = [path_data+'2021_01_24_O3_TRAIN_shuffle.nc',\n",
    "                        path_data+'2021_01_24_O3_VALID.nc',\n",
    "                        path_data+'2021_01_24_O3_TEST.nc']\n",
    "\n",
    "path_input_norm = path_data + '2021_01_24_NORM_O3_small.nc'\n",
    "scale_dict = pickle.load(open(path_data+'009_Wm2_scaling.pkl','rb'))\n",
    "path_norm_RH = path_data + '2021_02_01_NORM_O3_RH_small.nc'\n",
    "scale_dict_RH = scale_dict.copy()\n",
    "scale_dict_RH['RH'] = 0.01*L_S/G, # Arbitrary 0.1 factor as specific humidity is generally below 2%\n",
    "path_train_RH = path_data + '2021_01_24_O3_small_shuffle.nc'\n",
    "path_norm_BMSE = path_data + '2021_06_16_NORM_BMSE_small.nc'\n",
    "path_train_BMSE = path_data + '2021_06_16_BMSE_small_shuffle.nc'\n",
    "path_norm_LHF_nsDELQ = path_data + '2021_02_01_NORM_O3_LHF_nsDELQ_small.nc'\n",
    "path_train_LHF_nsDELQ = path_data + '2021_02_01_O3_LHF_nsQ_small_shuffle.nc'\n",
    "\n",
    "in_vars = ['QBP','TBP','PS','SOLIN','SHFLX','LHFLX'] # We take the large-scale climate state as inputs\n",
    "out_vars = ['PHQ','TPHYSTND','QRL','QRS'] # and we output the response of clouds/storms to these climate conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fz = 12\n",
    "lw = 2\n",
    "siz = 100\n",
    "\n",
    "plt.rc('text', usetex=False)\n",
    "mpl.rcParams['mathtext.fontset'] = 'stix'\n",
    "mpl.rcParams['font.family'] = 'STIXGeneral'\n",
    "plt.rc('font', family='serif', size=fz)\n",
    "mpl.rcParams['lines.linewidth'] = lw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gen_rescaling(input_rescaling,path_norm,path_train,scale_dict):\n",
    "    return DataGeneratorCI(\n",
    "        data_fn = path_train,\n",
    "        input_vars = input_rescaling,\n",
    "        output_vars = out_vars,\n",
    "        norm_fn = path_norm,\n",
    "        input_transform = ('mean', 'maxrs'),\n",
    "        output_transform = scale_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen_RH = train_gen_rescaling(['RH','TBP','PS', 'SOLIN', 'SHFLX', 'LHFLX'],\n",
    "                                   path_norm_RH,path_train_RH,scale_dict_RH)\n",
    "train_gen_BMSE = train_gen_rescaling(['QBP','BMSE','PS', 'SOLIN', 'SHFLX', 'LHFLX'],\n",
    "                                     path_norm_BMSE,path_train_BMSE,scale_dict)\n",
    "train_gen_LHF_nsDELQ = train_gen_rescaling(['QBP','TBP','PS', 'SOLIN', 'SHFLX', 'LHF_nsDELQ'],\n",
    "                                           path_norm_LHF_nsDELQ,path_train_LHF_nsDELQ,scale_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generator_singleDS(path,rescaling=None):\n",
    "    \n",
    "    in_vars = ['QBP','TBP','PS','SOLIN','SHFLX','LHFLX'] # We take the large-scale climate state as inputs\n",
    "    out_vars = ['PHQ','TPHYSTND','QRL','QRS'] # and we output the response of clouds/storms to these climate conditions\n",
    "    path_input_norm = path_data + '2021_01_24_NORM_O3_small.nc'\n",
    "    scale_dict = pickle.load(open(path_data+'009_Wm2_scaling.pkl','rb'))\n",
    "    \n",
    "    if rescaling=='CI':\n",
    "        gen = DataGeneratorCI(\n",
    "        data_fn = path,\n",
    "        input_vars = in_vars,\n",
    "        output_vars = out_vars,\n",
    "        norm_fn = path_input_norm,\n",
    "        batch_size=8192,\n",
    "        input_transform = ('mean', 'maxrs'),\n",
    "        output_transform = scale_dict,\n",
    "        Qscaling = 'RH',\n",
    "        Tscaling = 'BMSE',\n",
    "        LHFscaling = 'LHF_nsDELQ',\n",
    "        hyam=hyam, hybm=hybm, # Arrays to define mid-levels of hybrid vertical coordinate\n",
    "        inp_sub_Qscaling=train_gen_RH.input_transform.sub, # What to subtract from RH inputs\n",
    "        inp_div_Qscaling=train_gen_RH.input_transform.div, # What to divide RH inputs by\n",
    "        inp_sub_Tscaling=train_gen_BMSE.input_transform.sub,\n",
    "        inp_div_Tscaling=train_gen_BMSE.input_transform.div,\n",
    "        inp_sub_LHFscaling=train_gen_LHF_nsDELQ.input_transform.sub,\n",
    "        inp_div_LHFscaling=train_gen_LHF_nsDELQ.input_transform.div\n",
    "        ) \n",
    "    else:\n",
    "        gen = DataGeneratorCI(\n",
    "        data_fn = path,\n",
    "        input_vars = in_vars,\n",
    "        output_vars = out_vars,\n",
    "        norm_fn = path_input_norm,\n",
    "        batch_size=8192,\n",
    "        input_transform = ('mean', 'maxrs'),\n",
    "        output_transform = scale_dict\n",
    "        )\n",
    "\n",
    "    return gen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BFgen = {}\n",
    "CIgen = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Climate =  cold\n",
      "Set =  train\n",
      "Set =  valid\n",
      "Set =  test\n",
      "Climate =  hot\n",
      "Set =  train\n",
      "Set =  valid\n",
      "Set =  test\n",
      "Climate =  both\n",
      "Set =  train\n",
      "Set =  valid\n",
      "Set =  test\n",
      "Climate =  medium\n",
      "Set =  train\n",
      "Set =  valid\n",
      "Set =  test\n"
     ]
    }
   ],
   "source": [
    "for iclimate,clim in enumerate(test_clim_str):\n",
    "    print('Climate = ',clim)\n",
    "    BFgen[clim] = {}\n",
    "    CIgen[clim] = {}\n",
    "    \n",
    "    for iset,st in enumerate(set_str):\n",
    "        print('Set = ',st)\n",
    "        \n",
    "        BFgen[clim][st] = Generator_singleDS(path_array[clim][iset])\n",
    "        CIgen[clim][st] = Generator_singleDS(path_array[clim][iset],rescaling='CI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:    \n",
    "- Train on training set containing both climates    \n",
    "- Evaluate on test set of each climate separately   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(64,)) ## input after rh and tns transformation\n",
    "dense_out = Dense(120, activation='linear')(inp)\n",
    "MLR_BF = tf.keras.models.Model(inp, dense_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp2 = Input(shape=(64,)) ## input after rh and tns transformation\n",
    "dense2 = Dense(120, activation='linear')(inp2)\n",
    "MLR_CI = tf.keras.models.Model(inp2, dense2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 64)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 120)               7800      \n",
      "=================================================================\n",
      "Total params: 7,800\n",
      "Trainable params: 7,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MLR_BF.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLR_BF.compile(tf.keras.optimizers.Adam(), loss=mse)\n",
    "MLR_CI.compile(tf.keras.optimizers.Adam(), loss=mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_HDF5 = '/DFS-L/DATA/pritchard/tbeucler/SPCAM/HDF5_DATA/'\n",
    "save_name = '2022_07_12_MLR_both'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "mcp_save_BF = ModelCheckpoint(path_HDF5+save_name+'_BF.hdf5',save_best_only=True, monitor='val_loss', mode='min')\n",
    "mcp_save_CI = ModelCheckpoint(path_HDF5+save_name+'_CI.hdf5',save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nep = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLR_BF.fit_generator(BFgen['both']['train'], epochs=Nep, validation_data=BFgen['both']['valid'],\n",
    "#                      callbacks=[earlyStopping, mcp_save_BF])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLR_BF.load_weights(path_HDF5+'2022_06_25_MLR_both'+'_BF.hdf5')\n",
    "#MLR_CI.load_weights(path_HDF5+save_name+'_CI.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "11518/11518 [==============================] - 4028s 350ms/step - loss: 522.6601 - val_loss: 500.0511\n",
      "Epoch 2/20\n",
      "11518/11518 [==============================] - 3337s 290ms/step - loss: 493.4946 - val_loss: 490.3513\n",
      "Epoch 3/20\n",
      "11518/11518 [==============================] - 3461s 301ms/step - loss: 487.5516 - val_loss: 486.5635\n",
      "Epoch 4/20\n",
      "11518/11518 [==============================] - 3482s 302ms/step - loss: 484.5118 - val_loss: 484.2162\n",
      "Epoch 5/20\n",
      "11517/11518 [============================>.] - ETA: 0s - loss: 482.5082"
     ]
    }
   ],
   "source": [
    "MLR_CI.fit_generator(CIgen['both']['train'], epochs=Nep, validation_data=CIgen['both']['valid'],\n",
    "                     callbacks=[earlyStopping, mcp_save_CI])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = 'test'\n",
    "BFtest = {}; CItest = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iclimate,clim in enumerate(test_clim_str):\n",
    "    print('Climate = ',clim)\n",
    "    BFg = BFgen[clim][st]; CIg = CIgen[clim][st]\n",
    "    BFtest[clim] = MLR_BF.evaluate_generator(BFg)\n",
    "    print('BF ',print(BFtest[clim]))\n",
    "    CItest[clim] = MLR_CI.evaluate_generator(CIg)\n",
    "    print('CI ',print(CItest[clim]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test = path_data + 'PKL_DATA/2022_07_12_Performance_Four_Climates_MLR_Both'\n",
    "\n",
    "pickle.dump({'BFtest':BFtest,'CItest':CItest},open(path_test,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(BFtest); print(CItest);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tb - 06/26/2022 - The results are negative once again. If allowed to be fully non-local and use data from both climates, climate-invariant mappings are no better than brute-force ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tb - 07/12/2022 - Trying again with improved CI data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
