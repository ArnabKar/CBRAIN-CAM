{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tgb - 3/2/2020 - The goal is to rederive the reduced data for the unstable LRFs using the same norm file that was used for the coupled runs.\n",
    "- Define unstable NN\n",
    "- Input-regularize base profile loaded from reduced data\n",
    "- Calculate the corresponding LRFs\n",
    "- Save the LRF(regularization_amplitude)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/t/Tom.Beucler/miniconda3/envs/cbrain_1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/envs/cbrain_1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/envs/cbrain_1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/envs/cbrain_1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/envs/cbrain_1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/t/Tom.Beucler/miniconda3/envs/cbrain_1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/t/Tom.Beucler/SPCAM/CBRAIN-CAM/notebooks/tbeucler_devlog\n"
     ]
    }
   ],
   "source": [
    "from cbrain.imports import *\n",
    "from cbrain.data_generator import *\n",
    "from cbrain.utils import *\n",
    "from cbrain.normalization import *\n",
    "from cbrain.models import fc_model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import pickle\n",
    "import scipy.integrate as sin\n",
    "from tensorflow.python.ops.parallel_for.gradients import batch_jacobian\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_vars = ['QBP', 'TBP', 'VBP', 'PS', 'SOLIN', 'SHFLX', 'LHFLX']\n",
    "out_vars = ['PHQ', 'TPHYSTND', 'FSNT', 'FSNS', 'FLNT', 'FLNS', 'PRECT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_dict = load_pickle('/home/t/Tom.Beucler/SPCAM/CBRAIN-CAM/nn_config/scale_dicts/002_pnas_scaling.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_transform = InputNormalizer(\n",
    "    xr.open_dataset(f'/project/meteo/w2w/A6/S.Rasp/SP-CAM/preprocessed_data/003_norm.nc'),\n",
    "    in_vars,\n",
    "    'mean', 'maxrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_transform = DictNormalizer(xr.open_dataset(f'/project/meteo/w2w/A6/S.Rasp/SP-CAM/preprocessed_data/003_norm.nc'), \n",
    "                                  out_vars, scale_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import *\n",
    "def fc_model(input_shape, output_shape, hidden_layers, conservation_layer=False,\n",
    "             inp_sub=None, inp_div=None, norm_q=None):\n",
    "    inp = Input(shape=(input_shape,))\n",
    "\n",
    "    # First hidden layer\n",
    "    x = Dense(hidden_layers[0])(inp)\n",
    "    x = LeakyReLU()(x)\n",
    "\n",
    "    # Remaining hidden layers\n",
    "    for h in hidden_layers[1:]:\n",
    "        x = Dense(h)(x)\n",
    "        x = LeakyReLU()(x)\n",
    "\n",
    "    if conservation_layer:\n",
    "        x = SurRadLayer(inp_sub, inp_div, norm_q)([inp, x])\n",
    "        x = MassConsLayer(inp_sub, inp_div, norm_q)([inp, x])\n",
    "        out = EntConsLayer(inp_sub, inp_div, norm_q)([inp, x])\n",
    "\n",
    "    else:\n",
    "        out = Dense(output_shape)(x)\n",
    "\n",
    "    return tf.keras.models.Model(inp, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNSTABNN_path = '/local/Tom.Beucler/SPCAM_PHYS/Noah32col_weights.h5'\n",
    "\n",
    "unstabNN = fc_model(94, 65, [256]*9)\n",
    "unstabNN.load_weights(f'{UNSTABNN_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perturbation experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test reduced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/t/Tom.Beucler/SPCAM/CBRAIN-CAM/notebooks/tbeucler_devlog/PKL_DATA/'\n",
    "hf = open(path+'9_9_LRF.pkl','rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = pickle.load(hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_state = S['base_state'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['qv', 'T', 'v', 'ps', 'S0', 'SHF', 'LHF', 'p', 'p_interface', 'z', 'z_interface', 'rho', 'rho_interface'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_state.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S['base_state'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perturb the data by 0,1,2.5,5,7.5,10,12.5,15,17.5,20,22.5,25% for Figures 10 and 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jacobian(x, model):\n",
    "    sess = tf.keras.backend.get_session()\n",
    "    jac = jacobian(model.output, model.input)\n",
    "    J = sess.run(jac, feed_dict={model.input: x.astype(np.float32)[None]})\n",
    "    return J.squeeze()\n",
    "def get_batch_jacobian(x, model):\n",
    "    sess = tf.keras.backend.get_session()\n",
    "    jac = batch_jacobian(model.output, model.input)\n",
    "    J = sess.run(jac, feed_dict={model.input: x.astype(np.float32)})\n",
    "    return J.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables that we will perturb \n",
    "profiles = {'qv','T','v'}\n",
    "scalars = {'ps','S0','SHF','LHF'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_inp = np.zeros((1,94))\n",
    "for index in range (94):\n",
    "    if index<30: cf_inp[0,index]=L_V;\n",
    "    elif index<60: cf_inp[0,index]=C_P;\n",
    "    else: cf_inp[0,index]=1;\n",
    "        \n",
    "cf_oup = np.zeros((1,65))\n",
    "for index in range (65):\n",
    "    if index<30: cf_oup[0,index]=L_V;\n",
    "    elif index<60: cf_oup[0,index]=C_P;\n",
    "    else: cf_oup[0,index]=1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = 1\n",
    "Name = ['MeanLRF_unstable']\n",
    "Np = np.size(base_state['p']) # Number of vertical levels\n",
    "Npert = 5000 # Number of perturbations\n",
    "pert_array = 0.01*np.array([0,1,2.5,5,7.5,10,12.5,15,17.5,20,22.5,25])\n",
    "pert_state = {}\n",
    "jac = {}\n",
    "pert_state_mean = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipert= 0  perturbation= 0.0           \n",
      "Calculating Jacobian from unstable NN\n",
      "Linear response functions\n",
      "ipert= 1  perturbation= 0.01           \n",
      "Calculating Jacobian from unstable NN\n",
      "Linear response functions\n",
      "ipert= 2  perturbation= 0.025           \n",
      "Calculating Jacobian from unstable NN\n",
      "Linear response functions\n",
      "ipert= 3  perturbation= 0.05           \n",
      "Calculating Jacobian from unstable NN\n",
      "Linear response functions\n",
      "ipert= 4  perturbation= 0.075           \n",
      "Calculating Jacobian from unstable NN\n",
      "Linear response functions\n",
      "ipert= 5  perturbation= 0.1           \n",
      "Calculating Jacobian from unstable NN\n",
      "Linear response functions\n",
      "ipert= 6  perturbation= 0.125           \n",
      "Calculating Jacobian from unstable NN\n",
      "Linear response functions\n",
      "ipert= 7  perturbation= 0.15           \n",
      "Calculating Jacobian from unstable NN\n",
      "Linear response functions\n",
      "ipert= 8  perturbation= 0.17500000000000002           \n",
      "Calculating Jacobian from unstable NN\n",
      "Linear response functions\n",
      "ipert= 9  perturbation= 0.2           \n",
      "Calculating Jacobian from unstable NN\n",
      "Linear response functions\n",
      "ipert= 10  perturbation= 0.225           \n",
      "Calculating Jacobian from unstable NN\n",
      "Linear response functions\n",
      "ipert= 11  perturbation= 0.25           \n",
      "Calculating Jacobian from unstable NN\n",
      "Linear response functions\n",
      "i= 3  scalar= S0            \r"
     ]
    }
   ],
   "source": [
    "for ipert,pert in enumerate(pert_array):\n",
    "    print('ipert=',ipert,' perturbation=',pert,'          ')\n",
    "    # Perturbed profiles\n",
    "    pert_state[ipert] = {};\n",
    "    for i,profile in enumerate(profiles):\n",
    "        print('i=',i,' profile=',profile,'          ',end='\\r')\n",
    "        pert_state[ipert][profile] = np.zeros((Np,Npert))\n",
    "        for j,lev in enumerate(base_state['p']):\n",
    "            pert_state[ipert][profile][j,:] = base_state[profile][j]+\\\n",
    "            np.random.normal(loc=0,scale=pert,size=(Npert,))*\\\n",
    "            np.tile(base_state[profile][j],(Npert,))\n",
    "    # Perturbed scalars\n",
    "    for i,scalar in enumerate(scalars):\n",
    "        print('i=',i,' scalar=',scalar,'          ',end='\\r')\n",
    "        pert_state[ipert][scalar] = base_state[scalar]+\\\n",
    "        np.random.normal(loc=0,scale=pert,size=(Npert,))*\\\n",
    "        np.tile(base_state[scalar],(Npert,))\n",
    "    # Perturbed input batch to feed to NN\n",
    "    in_vec_pert = np.concatenate([pert_state[ipert]['qv'],\n",
    "                                  pert_state[ipert]['T'],\n",
    "                                  pert_state[ipert]['v'],\n",
    "                                  np.tile(pert_state[ipert]['ps'],(1,1)),\n",
    "                                  np.tile(pert_state[ipert]['S0'],(1,1)),\n",
    "                                  np.tile(pert_state[ipert]['SHF'],(1,1)),\n",
    "                                  np.tile(pert_state[ipert]['LHF'],(1,1)),\n",
    "                                 ])[None, :].astype('float32')\n",
    "    in_vec_pert = np.transpose(in_vec_pert[0,:,:]) # Shape = [#batches,input size]\n",
    "    # Unstable Jacobian\n",
    "    print('Calculating Jacobian from unstable NN')\n",
    "    Junstab = get_batch_jacobian(input_transform.transform(in_vec_pert),unstabNN)*\\\n",
    "    np.transpose(cf_oup/output_transform.scale)/\\\n",
    "    (cf_inp*input_transform.div)\n",
    "    # Linear response functions\n",
    "    print('Linear response functions')\n",
    "    LRFunstab = Junstab[:,:(2*Np),:(2*Np)] # Only keep the d(dq/dt,dT/dt)/d(q,T) Jacobian\n",
    "    LRFunstab_mean = np.mean(LRFunstab,axis=0)\n",
    "    # Save LRFs\n",
    "    jac[ipert] = {}\n",
    "    for ijac,name in enumerate(Name):\n",
    "        if ijac==0: tmp = LRFunstab_mean\n",
    "        jac[ipert][name] = {}\n",
    "        jac[ipert][name]['q'] = {}\n",
    "        jac[ipert][name]['T'] = {}\n",
    "        jac[ipert][name]['q']['q'] = tmp[:30,:30]\n",
    "        jac[ipert][name]['q']['T'] = tmp[:30,30:]\n",
    "        jac[ipert][name]['T']['q'] = tmp[30:,:30]\n",
    "        jac[ipert][name]['T']['T'] = tmp[30:,30:]\n",
    "    # Calculate mean of pert_state which should be close to base_state for reference\n",
    "    pert_state_mean[ipert] = {}\n",
    "    for i,profile in enumerate(profiles):\n",
    "        print('i=',i,' profile=',profile,'          ',end='\\r')\n",
    "        pert_state_mean[ipert][profile] = np.mean(pert_state[ipert][profile],axis=1)\n",
    "    for i,scalar in enumerate(scalars):\n",
    "        print('i=',i,' scalar=',scalar,'          ',end='\\r')\n",
    "        pert_state_mean[ipert][scalar] = np.mean(pert_state[ipert][scalar])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = open(path+'2020_03_02_LRF_Unstable.pkl','wb')\n",
    "ForNoah = {\"base_state\" : base_state,\n",
    "           \"mean_pert_state\" : pert_state_mean,\n",
    "           \"linear_response_functions\" : jac}\n",
    "pickle.dump(ForNoah,hf)\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
