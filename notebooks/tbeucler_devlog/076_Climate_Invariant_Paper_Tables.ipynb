{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfspool-0/home/tbeucler/CBRAIN-CAM/notebooks/tbeucler_devlog\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(1,\"/home1/07064/tg863631/anaconda3/envs/CbrainCustomLayer/lib/python3.6/site-packages\") #work around for h5py\n",
    "from cbrain.imports import *\n",
    "from cbrain.cam_constants import *\n",
    "from cbrain.utils import *\n",
    "from cbrain.layers import *\n",
    "from cbrain.data_generator import DataGenerator\n",
    "from cbrain.climate_invariant import *\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from cbrain.model_diagnostics import ModelDiagnostics\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as imag\n",
    "import scipy.integrate as sin\n",
    "# import cartopy.crs as ccrs\n",
    "import matplotlib.ticker as mticker\n",
    "# from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import pickle\n",
    "# from climate_invariant import *\n",
    "from tensorflow.keras import layers\n",
    "import datetime\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load coordinates (just pick any file from the climate model run)\n",
    "\n",
    "# GP path below\n",
    "path_0K = '/DFS-L/DATA/pritchard/tbeucler/SPCAM/fluxbypass_aqua/'\n",
    "coor = xr.open_dataset(path_0K+\"AndKua_aqua_SPCAM3.0_sp_fbp_f4.cam2.h1.0000-09-02-00000.nc\")\n",
    "\n",
    "lat = coor.lat; lon = coor.lon; lev = coor.lev;\n",
    "coor.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_folRG = '/DFS-L/DATA/pritchard/liranp/'\n",
    "path_RG0K = path_folRG + 'SST_0001Kp_Neuralnet_SPCAM_all_216/atm/hist/SST_0001Kp_Neuralnet_SPCAM_all_216.cam.h1.2013-'\n",
    "path_RG0K = path_RG0K + '05-05-*.nc'\n",
    "\n",
    "coor_RG = xr.open_mfdataset(path_RG0K,decode_cf=False)\n",
    "latRG = coor_RG.lat; lonRG = coor_RG.lon; levRG = coor_RG.lev;\n",
    "coor_RG.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GP path below\n",
    "TRAINDIR = '/DFS-L/DATA/pritchard/tbeucler/SPCAM/SPCAM_PHYS/'\n",
    "path = '/export/nfs0home/tbeucler/CBRAIN-CAM/cbrain/'\n",
    "path_nnconfig = '/export/nfs0home/tbeucler/CBRAIN-CAM/nn_config/'\n",
    "\n",
    "# Load hyam and hybm to calculate pressure field in SPCAM\n",
    "path_hyam = 'hyam_hybm.pkl'\n",
    "hf = open(path+path_hyam,'rb')\n",
    "hyam,hybm = pickle.load(hf)\n",
    "\n",
    "# Scale dictionary to convert the loss to W/m2\n",
    "scale_dict = load_pickle(path_nnconfig+'scale_dicts/009_Wm2_scaling.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table 1: Simulation characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'lev' ()>\n",
       "array(142.994039)\n",
       "Coordinates:\n",
       "    lev      float64 143.0\n",
       "Attributes:\n",
       "    long_name:      hybrid level at midpoints (1000*(A+B))\n",
       "    units:          level\n",
       "    positive:       down\n",
       "    standard_name:  atmosphere_hybrid_sigma_pressure_coordinate\n",
       "    formula_terms:  a: hyam b: hybm p0: P0 ps: PS"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coor_RG['lev'][10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table 2: PDF similarity metrics (SJ and Hellinger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired from [https://github.com/tbeucler/CBRAIN-CAM/blob/master/notebooks/tbeucler_devlog/044_Climate_invariant_analysis_output_scaling.ipynb]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hellinger(x,f,g):\n",
    "    return np.sqrt(np.trapz(y=0.5*(np.sqrt(f)-np.sqrt(g))**2,x=x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL(x,f,g,eps=1e-4):\n",
    "    f = np.maximum(eps,f)\n",
    "    g = np.maximum(eps,g)\n",
    "    return np.trapz(y=f*np.log(f/g),x=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def JS(x,f,g,eps=1e-4):\n",
    "    return np.sqrt(0.5*(KL(x,f,g,eps)+KL(x,g,f,eps)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxmin_norm(xf,xg,f,g):\n",
    "    \n",
    "    fg_xmax = np.maximum(np.max(xf),np.max(xg))\n",
    "    fg_xmin = np.minimum(np.min(xf),np.min(xg))\n",
    "    xf_norm = (xf-fg_xmin)/(fg_xmax-fg_xmin)\n",
    "    xg_norm = (xg-fg_xmin)/(fg_xmax-fg_xmin)\n",
    "    \n",
    "    fg_max = np.maximum(np.max(f),np.max(g))\n",
    "    fg_min = np.minimum(np.min(f),np.min(g))\n",
    "    f_norm = (f-fg_min)/(fg_max-fg_min)\n",
    "    g_norm = (g-fg_min)/(fg_max-fg_min)\n",
    "    \n",
    "    return xf_norm,xg_norm,f_norm,g_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://stackoverflow.com/questions/2413522/weighted-standard-deviation-in-np\n",
    "def weighted_avg_and_std(values, weights):\n",
    "    \"\"\"\n",
    "    Return the weighted average and standard deviation.\n",
    "    values, weights -- np ndarrays with the same shape.\n",
    "    \"\"\"\n",
    "    if np.sum(weights)>0:\n",
    "        average = np.average(values, weights=weights)\n",
    "        variance = np.average((values-average)**2, weights=weights)\n",
    "    else: average = np.nan; variance = np.nan\n",
    "    return (average, np.sqrt(variance))\n",
    "\n",
    "# Make function to calculate conditional mean and std\n",
    "# We condition field_y on field_x\n",
    "def conditional_avg_and_std(bin_edges,field_x,field_y):\n",
    "    # Initialization\n",
    "    Nbin = np.size(bin_edges)\n",
    "    Ym = np.zeros((Nbin-1,1))\n",
    "    Ystd = np.copy(Ym)\n",
    "\n",
    "    for ibin,edge in enumerate(bin_edges):\n",
    "        print('ibin=',ibin,'/',Nbin-1,' & edge=',edge,end=\"\\r\")\n",
    "        if ibin>0:\n",
    "            w = (field_x>=edge_left)*(field_x<edge)\n",
    "            Ym[ibin-1],Ystd[ibin-1] = weighted_avg_and_std(field_y,w)\n",
    "\n",
    "        edge_left = edge\n",
    "    \n",
    "    return Ym,Ystd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_verthist(S):\n",
    "    fig, ax = plt.subplots(20,1,figsize=(15,25))\n",
    "\n",
    "    iav = 0\n",
    "    JS_mean = 0\n",
    "    Hel_mean = 0\n",
    "\n",
    "    for icount,ilev in enumerate(np.arange(10,30)):\n",
    "        TITLE = 'Hel/JS='\n",
    "        for idata,data in enumerate(['m4K','ref','p4K']):\n",
    "            ax[icount].plot(edg2bin(S[ilev][data][1]),S[ilev][data][0],color=COL[idata])\n",
    "            ax[icount].set_ylabel(str(ilev))\n",
    "\n",
    "            f_cold = S[ilev]['m4K'][0]; x_cold = edg2bin(S[ilev]['m4K'][1])\n",
    "            f_data = S[ilev][data][0]; x_data = edg2bin(S[ilev][data][1])\n",
    "\n",
    "            xf_norm,xg_norm,f_norm,g_norm = maxmin_norm(x_cold,x_data,f_cold,f_data)\n",
    "            x = np.linspace(0,1,1000)\n",
    "\n",
    "            f = np.interp(x=x,xp=xf_norm,fp=f_norm)\n",
    "            g = np.interp(x=x,xp=xg_norm,fp=g_norm)\n",
    "\n",
    "            H = Hellinger(x,f,g)\n",
    "            JS0 = JS(x,f,g,eps=1e-4)\n",
    "\n",
    "            iav += 1\n",
    "            JS_mean += JS0\n",
    "            Hel_mean += H\n",
    "\n",
    "            TITLE += '('+data+') '+str(H)[:5]+'/'+str(JS0)[:5]+' '\n",
    "        ax[icount].set_title(TITLE)\n",
    "    fig.tight_layout()\n",
    "    print('Mean JS is ',str(100*JS_mean/iav),'% and mean Hellinger is ',str(100*Hel_mean/iav),'%')\n",
    "    \n",
    "    return JS_mean/iav,Hel_mean/iav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edg2bin(bin_edges):\n",
    "    return 0.5*(bin_edges[1:]+bin_edges[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_array = [\n",
    "     '2021_03_18_O3_TRAIN_M4K_shuffle.nc',\n",
    "     '2021_01_24_O3_TRAIN_shuffle.nc',\n",
    "     '2021_03_18_O3_TRAIN_P4K_shuffle.nc',\n",
    "     '2021_04_18_RG_TRAIN_M4K_shuffle.nc',\n",
    "     '2021_06_03_RG_TRAIN_shuffle.nc',\n",
    "     '2021_04_18_RG_TRAIN_P4K_shuffle.nc'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathPKL = '/export/home/tbeucler/CBRAIN-CAM/notebooks/tbeucler_devlog/PKL_DATA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name = '2021_06_07_AQUA_RG_Qhist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = open(pathPKL+'/'+save_name+'.pkl','rb')\n",
    "\n",
    "Q_data = pickle.load(hf)\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name = '2021_06_07_AQUA_RG_Thist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = open(pathPKL+'/'+save_name+'.pkl','rb')\n",
    "\n",
    "T_data = pickle.load(hf)\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load T at 200hPa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name = '2021_08_18_AQUA_RG_Thist_ilev'+str(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = open(pathPKL+'/'+save_name+'.pkl','rb')\n",
    "\n",
    "T200_data = pickle.load(hf)\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load T at 150hPa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name = '2021_08_18_AQUA_RG_Thist_ilev'+str(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = open(pathPKL+'/'+save_name+'.pkl','rb')\n",
    "\n",
    "T150_data = pickle.load(hf)\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '2021_06_21_distributions_BMSE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = open(pathPKL+'/'+path+'.pkl','rb')\n",
    "\n",
    "B_data = pickle.load(hf)\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load LHF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name = '2021_06_07_AQUA_RG_LHFhist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = open(pathPKL+'/'+save_name+'.pkl','rb')\n",
    "\n",
    "LHF_data = pickle.load(hf)\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group all variables into the same structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "hisQ = {}\n",
    "edgQ = {}\n",
    "\n",
    "for ikey,key in enumerate(['QV','RH','QfromQsat']):\n",
    "    hisQ[key] = {}\n",
    "    edgQ[key] = {}\n",
    "    for ipath,path in enumerate(path_array):\n",
    "        hisQ[key][path] = {}\n",
    "        edgQ[key][path] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "hisT = {}\n",
    "edgT = {}\n",
    "\n",
    "for ikey,key in enumerate(['T','BCONS','TfromNS']):\n",
    "    hisT[key] = {}\n",
    "    edgT[key] = {}\n",
    "    for ipath,path in enumerate(path_array):\n",
    "        hisT[key][path] = {}\n",
    "        edgT[key][path] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "hisT150 = {}\n",
    "edgT150 = {}\n",
    "\n",
    "for ikey,key in enumerate(['T','BCONS','TfromNS']):\n",
    "    hisT150[key] = {}\n",
    "    edgT150[key] = {}\n",
    "    for ipath,path in enumerate(path_array):\n",
    "        hisT150[key][path] = {}\n",
    "        edgT150[key][path] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "hisT200 = {}\n",
    "edgT200 = {}\n",
    "\n",
    "for ikey,key in enumerate(['T','BCONS','TfromNS']):\n",
    "    hisT200[key] = {}\n",
    "    edgT200[key] = {}\n",
    "    for ipath,path in enumerate(path_array):\n",
    "        hisT200[key][path] = {}\n",
    "        edgT200[key][path] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "hisLHF = {}\n",
    "edgLHF = {}\n",
    "\n",
    "for ikey,key in enumerate(['LHF','LHF_nsQ','LHF_nsDELQ']):\n",
    "    hisLHF[key] = {}\n",
    "    edgLHF[key] = {}\n",
    "    for ipath,path in enumerate(path_array):\n",
    "        hisLHF[key][path] = {}\n",
    "        edgLHF[key][path] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "hisQ = Q_data['hisQ']\n",
    "edgQ = Q_data['edgQ']\n",
    "# Convert specific humidities to g/kg\n",
    "for ipath,path0 in enumerate(path_array):\n",
    "    for ikey,key in enumerate(['QV','QfromQsat']):\n",
    "        edgQ[key][path0] *= 1e3\n",
    "\n",
    "hisT = T_data['hisT']\n",
    "edgT = T_data['edgT']\n",
    "# Load buoyancy from MSE\n",
    "ilevB = 23\n",
    "for ikey,key in enumerate(['BMSE']):\n",
    "    hisT[key] = {}\n",
    "    edgT[key] = {}\n",
    "    for ipath,path in enumerate(path_array):\n",
    "        hisT[key][path] = B_data['hisT'][ilevB][path]\n",
    "        edgT[key][path] = B_data['edgT'][ilevB][path]\n",
    "\n",
    "hisT200 = T200_data['hisT']\n",
    "edgT200 = T200_data['edgT']\n",
    "# Load buoyancy from MSE\n",
    "ilevB = 12\n",
    "for ikey,key in enumerate(['BMSE']):\n",
    "    hisT200[key] = {}\n",
    "    edgT200[key] = {}\n",
    "    for ipath,path in enumerate(path_array):\n",
    "        hisT200[key][path] = B_data['hisT'][ilevB][path]\n",
    "        edgT200[key][path] = B_data['edgT'][ilevB][path]\n",
    "        \n",
    "hisT150 = T150_data['hisT']\n",
    "edgT150 = T150_data['edgT']\n",
    "# Load buoyancy from MSE\n",
    "ilevB = 10\n",
    "for ikey,key in enumerate(['BMSE']):\n",
    "    hisT150[key] = {}\n",
    "    edgT150[key] = {}\n",
    "    for ipath,path in enumerate(path_array):\n",
    "        hisT150[key][path] = B_data['hisT'][ilevB][path]\n",
    "        edgT150[key][path] = B_data['edgT'][ilevB][path]\n",
    "\n",
    "# Redefine Tarray to replace BCONS with BMSE for now\n",
    "Tarray = ['T','BMSE','TfromNS']\n",
    "\n",
    "hisLHF = LHF_data['hisLHF']\n",
    "edgLHF = LHF_data['edgLHF']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate JS and Hellinger structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "JS0 = {}; Hel = {};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2021_03_18_O3_TRAIN_M4K_shuffle.nc',\n",
       " '2021_01_24_O3_TRAIN_shuffle.nc',\n",
       " '2021_03_18_O3_TRAIN_P4K_shuffle.nc',\n",
       " '2021_04_18_RG_TRAIN_M4K_shuffle.nc',\n",
       " '2021_06_03_RG_TRAIN_shuffle.nc',\n",
       " '2021_04_18_RG_TRAIN_P4K_shuffle.nc']"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var= QV\n",
      "key= QV                    \r",
      "key= RH                    \r",
      "key= QfromQsat                    \r",
      "var= T\n",
      "key= T                    \r",
      "key= BMSE                    \r",
      "key= TfromNS                    \r",
      "var= T200\n",
      "key= T                    \r",
      "key= BMSE                    \r",
      "key= TfromNS                    \r",
      "var= T150\n",
      "key= T                    \r",
      "key= BMSE                    \r",
      "key= TfromNS                    \r",
      "var= LHF\n",
      "key= LHF                    \r",
      "key= LHF_nsQ                    \r",
      "key= LHF_nsDELQ                    \r"
     ]
    }
   ],
   "source": [
    "for ivar,var in enumerate(['QV','T','T200','T150','LHF']):\n",
    "    print('var=',var,end='\\n')\n",
    "    JS0[var] = {}; Hel[var] = {};\n",
    "    if var=='QV': key_array = ['QV','RH','QfromQsat']; edg = edgQ; his = hisQ;\n",
    "    elif var=='T': key_array = ['T','BMSE','TfromNS']; edg = edgT; his = hisT;\n",
    "    elif var=='T200': edg = edgT200; his = hisT200;\n",
    "    elif var=='T150': edg = edgT150; his = hisT150;\n",
    "    elif var=='LHF': key_array = ['LHF','LHF_nsQ','LHF_nsDELQ']; edg = edgLHF; his  = hisLHF;\n",
    "        \n",
    "    for ikey,key in enumerate(key_array):\n",
    "        print('key=',key,'                   ',end='\\r')\n",
    "        JS0[var][key] = {}; Hel[var][key] = {};\n",
    "        \n",
    "        for ipath,path in enumerate(path_array):\n",
    "            \n",
    "            if ipath<3: \n",
    "                f_cold = his[key][path_array[0]]\n",
    "                x_cold = edg2bin(edg[key][path_array[0]])\n",
    "            else:\n",
    "                f_cold = his[key][path_array[3]]\n",
    "                x_cold = edg2bin(edg[key][path_array[3]])\n",
    "            \n",
    "            f_data = his[key][path]; x_data = edg2bin(edg[key][path])\n",
    "\n",
    "            xf_norm,xg_norm,f_norm,g_norm = maxmin_norm(x_cold,x_data,f_cold,f_data)\n",
    "            x = np.linspace(0,1,1000)\n",
    "\n",
    "            f = np.interp(x=x,xp=xf_norm,fp=f_norm)\n",
    "            g = np.interp(x=x,xp=xg_norm,fp=g_norm)\n",
    "\n",
    "            Hel[var][key][path] = Hellinger(x,f,g)\n",
    "            JS0[var][key][path] = JS(x,f,g,eps=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'QV': {'QV': {'2021_03_18_O3_TRAIN_M4K_shuffle.nc': 0.0,\n",
       "   '2021_01_24_O3_TRAIN_shuffle.nc': 0.10053476613861904,\n",
       "   '2021_03_18_O3_TRAIN_P4K_shuffle.nc': 0.14106358627913645,\n",
       "   '2021_04_18_RG_TRAIN_M4K_shuffle.nc': 0.0,\n",
       "   '2021_06_03_RG_TRAIN_shuffle.nc': 0.09196493671015625,\n",
       "   '2021_04_18_RG_TRAIN_P4K_shuffle.nc': 0.1369547935930896},\n",
       "  'RH': {'2021_03_18_O3_TRAIN_M4K_shuffle.nc': 0.0,\n",
       "   '2021_01_24_O3_TRAIN_shuffle.nc': 0.03388749466183367,\n",
       "   '2021_03_18_O3_TRAIN_P4K_shuffle.nc': 0.07724296169031303,\n",
       "   '2021_04_18_RG_TRAIN_M4K_shuffle.nc': 0.0,\n",
       "   '2021_06_03_RG_TRAIN_shuffle.nc': 0.023559521186652166,\n",
       "   '2021_04_18_RG_TRAIN_P4K_shuffle.nc': 0.0398982252395975},\n",
       "  'QfromQsat': {'2021_03_18_O3_TRAIN_M4K_shuffle.nc': 0.0,\n",
       "   '2021_01_24_O3_TRAIN_shuffle.nc': 0.07953828567655585,\n",
       "   '2021_03_18_O3_TRAIN_P4K_shuffle.nc': 0.09075040733608687,\n",
       "   '2021_04_18_RG_TRAIN_M4K_shuffle.nc': 0.0,\n",
       "   '2021_06_03_RG_TRAIN_shuffle.nc': 0.07592071878695544,\n",
       "   '2021_04_18_RG_TRAIN_P4K_shuffle.nc': 0.110061203628692}},\n",
       " 'T': {'T': {'2021_03_18_O3_TRAIN_M4K_shuffle.nc': 0.0,\n",
       "   '2021_01_24_O3_TRAIN_shuffle.nc': 0.5116006624970451,\n",
       "   '2021_03_18_O3_TRAIN_P4K_shuffle.nc': 0.6612253972772998,\n",
       "   '2021_04_18_RG_TRAIN_M4K_shuffle.nc': 0.0,\n",
       "   '2021_06_03_RG_TRAIN_shuffle.nc': 0.22580201068335173,\n",
       "   '2021_04_18_RG_TRAIN_P4K_shuffle.nc': 0.3384291966660739},\n",
       "  'BMSE': {'2021_03_18_O3_TRAIN_M4K_shuffle.nc': 0.0,\n",
       "   '2021_01_24_O3_TRAIN_shuffle.nc': 0.05969464707892919,\n",
       "   '2021_03_18_O3_TRAIN_P4K_shuffle.nc': 0.09732866099446806,\n",
       "   '2021_04_18_RG_TRAIN_M4K_shuffle.nc': 0.0,\n",
       "   '2021_06_03_RG_TRAIN_shuffle.nc': 0.020352076635316702,\n",
       "   '2021_04_18_RG_TRAIN_P4K_shuffle.nc': 0.0430801764016152},\n",
       "  'TfromNS': {'2021_03_18_O3_TRAIN_M4K_shuffle.nc': 0.0,\n",
       "   '2021_01_24_O3_TRAIN_shuffle.nc': 0.029459349469133436,\n",
       "   '2021_03_18_O3_TRAIN_P4K_shuffle.nc': 0.039156991680714084,\n",
       "   '2021_04_18_RG_TRAIN_M4K_shuffle.nc': 0.0,\n",
       "   '2021_06_03_RG_TRAIN_shuffle.nc': 0.021134976503471514,\n",
       "   '2021_04_18_RG_TRAIN_P4K_shuffle.nc': 0.04158481195998869}},\n",
       " 'T200': {'T': {'2021_03_18_O3_TRAIN_M4K_shuffle.nc': 0.0,\n",
       "   '2021_01_24_O3_TRAIN_shuffle.nc': 0.23620131923384313,\n",
       "   '2021_03_18_O3_TRAIN_P4K_shuffle.nc': 0.3669744080128015,\n",
       "   '2021_04_18_RG_TRAIN_M4K_shuffle.nc': 0.0,\n",
       "   '2021_06_03_RG_TRAIN_shuffle.nc': 0.2243112303213154,\n",
       "   '2021_04_18_RG_TRAIN_P4K_shuffle.nc': 0.3270558217459741},\n",
       "  'BMSE': {'2021_03_18_O3_TRAIN_M4K_shuffle.nc': 0.0,\n",
       "   '2021_01_24_O3_TRAIN_shuffle.nc': 0.47599831473567333,\n",
       "   '2021_03_18_O3_TRAIN_P4K_shuffle.nc': 0.5844726813758819,\n",
       "   '2021_04_18_RG_TRAIN_M4K_shuffle.nc': 0.0,\n",
       "   '2021_06_03_RG_TRAIN_shuffle.nc': 0.11916545155336984,\n",
       "   '2021_04_18_RG_TRAIN_P4K_shuffle.nc': 0.24492410553846988},\n",
       "  'TfromNS': {'2021_03_18_O3_TRAIN_M4K_shuffle.nc': 0.0,\n",
       "   '2021_01_24_O3_TRAIN_shuffle.nc': 0.5103562104065742,\n",
       "   '2021_03_18_O3_TRAIN_P4K_shuffle.nc': 0.5545348690392297,\n",
       "   '2021_04_18_RG_TRAIN_M4K_shuffle.nc': 0.0,\n",
       "   '2021_06_03_RG_TRAIN_shuffle.nc': 0.16678529674690343,\n",
       "   '2021_04_18_RG_TRAIN_P4K_shuffle.nc': 0.2584977118703268}},\n",
       " 'LHF': {'LHF': {'2021_03_18_O3_TRAIN_M4K_shuffle.nc': 0.0,\n",
       "   '2021_01_24_O3_TRAIN_shuffle.nc': 0.03597507168739147,\n",
       "   '2021_03_18_O3_TRAIN_P4K_shuffle.nc': 0.055257482686467754,\n",
       "   '2021_04_18_RG_TRAIN_M4K_shuffle.nc': 0.0,\n",
       "   '2021_06_03_RG_TRAIN_shuffle.nc': 0.032282582925585904,\n",
       "   '2021_04_18_RG_TRAIN_P4K_shuffle.nc': 0.041404560951953835},\n",
       "  'LHF_nsQ': {'2021_03_18_O3_TRAIN_M4K_shuffle.nc': 0.0,\n",
       "   '2021_01_24_O3_TRAIN_shuffle.nc': 0.021482208625626626,\n",
       "   '2021_03_18_O3_TRAIN_P4K_shuffle.nc': 0.03806791047313298,\n",
       "   '2021_04_18_RG_TRAIN_M4K_shuffle.nc': 0.0,\n",
       "   '2021_06_03_RG_TRAIN_shuffle.nc': 0.03158312624293773,\n",
       "   '2021_04_18_RG_TRAIN_P4K_shuffle.nc': 0.03373165224326005},\n",
       "  'LHF_nsDELQ': {'2021_03_18_O3_TRAIN_M4K_shuffle.nc': 0.0,\n",
       "   '2021_01_24_O3_TRAIN_shuffle.nc': 0.03385574083318297,\n",
       "   '2021_03_18_O3_TRAIN_P4K_shuffle.nc': 0.04562909892086906,\n",
       "   '2021_04_18_RG_TRAIN_M4K_shuffle.nc': 0.0,\n",
       "   '2021_06_03_RG_TRAIN_shuffle.nc': 0.03267457705217957,\n",
       "   '2021_04_18_RG_TRAIN_P4K_shuffle.nc': 0.04301031543180126}},\n",
       " 'T150': {'T': {'2021_03_18_O3_TRAIN_M4K_shuffle.nc': 0.0,\n",
       "   '2021_01_24_O3_TRAIN_shuffle.nc': 0.26944261481014403,\n",
       "   '2021_03_18_O3_TRAIN_P4K_shuffle.nc': 0.28210548978025785,\n",
       "   '2021_04_18_RG_TRAIN_M4K_shuffle.nc': 0.0,\n",
       "   '2021_06_03_RG_TRAIN_shuffle.nc': 0.2972907882411728,\n",
       "   '2021_04_18_RG_TRAIN_P4K_shuffle.nc': 0.30276321643103804},\n",
       "  'BMSE': {'2021_03_18_O3_TRAIN_M4K_shuffle.nc': 0.0,\n",
       "   '2021_01_24_O3_TRAIN_shuffle.nc': 0.38728352244085656,\n",
       "   '2021_03_18_O3_TRAIN_P4K_shuffle.nc': 0.45827164721796276,\n",
       "   '2021_04_18_RG_TRAIN_M4K_shuffle.nc': 0.0,\n",
       "   '2021_06_03_RG_TRAIN_shuffle.nc': 0.1293552302768001,\n",
       "   '2021_04_18_RG_TRAIN_P4K_shuffle.nc': 0.2687549773286075},\n",
       "  'TfromNS': {'2021_03_18_O3_TRAIN_M4K_shuffle.nc': 0.0,\n",
       "   '2021_01_24_O3_TRAIN_shuffle.nc': 0.507864315792093,\n",
       "   '2021_03_18_O3_TRAIN_P4K_shuffle.nc': 0.736417131761153,\n",
       "   '2021_04_18_RG_TRAIN_M4K_shuffle.nc': 0.0,\n",
       "   '2021_06_03_RG_TRAIN_shuffle.nc': 0.13033575103390824,\n",
       "   '2021_04_18_RG_TRAIN_P4K_shuffle.nc': 0.24707177126070468}}}"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JS0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table code in latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "TABLEname = 'JS'\n",
    "if TABLEname=='JS': Name = 'Jensen-Shannon'\n",
    "elif TABLEname=='Hellinger': Name = 'Hellinger'\n",
    "path_TXT = '/export/home/tbeucler/CBRAIN-CAM/notebooks/tbeucler_devlog/TXT_DATA/'\n",
    "path = path_TXT+TABLEname+\".txt\"\n",
    "VAR = ['QV','T','T150','LHF']\n",
    "topline = \"Input & SPCAM3 & SPCAM5 & SAM\\\\tabularnewline\\n\"\n",
    "caption = Name+\" distance (in $\\\\%$) away from the (-4K) simulation\"+\\\n",
    "\" for the PDFs of $\\\\left(q_{600\\\\mathrm{hPa}},T_{850\\\\mathrm{hPa}},T_{150\\\\mathrm{hPa}},\\\\mathrm{LHF}\\\\right)$\"+\\\n",
    "\" and their rescalings: (+0K) distance in gray and (+4K) distance in red.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TABLEname=='JS': S = JS0\n",
    "elif TABLEname=='Hellinger': S = Hel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table JS printed to /export/home/tbeucler/CBRAIN-CAM/notebooks/tbeucler_devlog/TXT_DATA/JS.txt\n"
     ]
    }
   ],
   "source": [
    "f= open(path,\"w+\")\n",
    "f.write(\"\\\\begin{table}\\n\")\n",
    "f.write(\"\\\\begin{centering}\\n\")\n",
    "f.write(\"\\\\begin{tabular}{c|c|c|c}\\n\")\n",
    "f.write(topline)\n",
    "f.write(\"\\\\hline\\n\")\n",
    "for ivar,var in enumerate(VAR):\n",
    "    f.write(\"\\\\hline\\n\")\n",
    "    if var=='QV': \n",
    "        key_array = ['QV','RH','QfromQsat']; \n",
    "        tex_array = ['$q_{600\\\\mathrm{hPa}}$','$q_{\\\\mathrm{deficit,}600\\\\mathrm{hPa}}$',\n",
    "                     '$\\mathrm{RH}_{600\\\\mathrm{hPa}}$']\n",
    "    elif var=='T': \n",
    "        key_array = ['T','BMSE','TfromNS'];\n",
    "        tex_array = ['$T_{850\\\\mathrm{hPa}}$',\n",
    "                     '$B_{\\\\mathrm{plume},850\\\\mathrm{hPa}}$',\n",
    "                     '$T_{\\\\mathrm{from\\\\ NS},850\\mathrm{hPa}}$']\n",
    "    elif var=='T150':\n",
    "        tex_array = ['$T_{150\\\\mathrm{hPa}}$',\n",
    "                     '$B_{\\\\mathrm{plume},150\\\\mathrm{hPa}}$',\n",
    "                     '$T_{\\\\mathrm{from\\\\ NS},150\\\\mathrm{hPa}}$']\n",
    "    elif var=='LHF': \n",
    "        key_array = ['LHF','LHF_nsQ','LHF_nsDELQ'];\n",
    "        tex_array = ['$\\\\mathrm{LHF}$','$\\\\mathrm{LHF}_{q}$',\n",
    "                     '$\\\\mathrm{LHF}_{\\\\Delta q}$']\n",
    "    for ikey,key in enumerate(key_array):\n",
    "        f.write(tex_array[ikey]+\" & \")\n",
    "        f.write(\"\\\\textcolor{gray}{\")\n",
    "        f.write(\"%2.1f\"%(100*S[var][key][path_array[1]]))\n",
    "        f.write(\"}, \\\\textcolor{red}{\")\n",
    "        f.write(\"%2.1f\"%(100*S[var][key][path_array[2]]))\n",
    "        f.write(\"} & \\\\textcolor{gray}{\")\n",
    "        f.write(\"%2.1f\"%(100*S[var][key][path_array[4]]))\n",
    "        f.write(\"}, \\\\textcolor{red}{\")\n",
    "        f.write(\"%2.1f\"%(100*S[var][key][path_array[5]]))\n",
    "        f.write(\"} & \\\\tabularnewline\")\n",
    "f.write(\"\\\\end{tabular}\\n\")\n",
    "f.write(\"\\\\par\\\\end{centering}{\\\\small \\\\par}\\n\")\n",
    "f.write(\"\\n\")\n",
    "f.write(\"\\\\caption{\")\n",
    "f.write(caption)\n",
    "f.write(\"}\\n\")\n",
    "f.write(\"\\\\label{tab:PDF}\\n\")\n",
    "f.write(\"\\\\end{table}\\n\")\n",
    "f.close()\n",
    "print('Table',TABLEname,'printed to',path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table 3: MSE of different MLRs/NNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired from [https://github.com/tbeucler/CBRAIN-CAM/blob/master/notebooks/tbeucler_devlog/073_CI_Results_Figure.ipynb]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_PKL = '/export/nfs0home/tbeucler/CBRAIN-CAM/notebooks/tbeucler_devlog/PKL_DATA/'\n",
    "epoch = np.arange(1,21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trained on ref climate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_MLR_BF = path_PKL + 'PKL_DATA2021_04_26_MLR_hist.pkl'\n",
    "hf = open(path_MLR_BF,'rb')\n",
    "hist_MLR_BF = pickle.load(hf)\n",
    "hist_MLR_BF = hist_MLR_BF['hist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_NN_BF1 = path_PKL + 'PKL_DATA2021_04_26_NN_hist.pkl'\n",
    "path_NN_BF2 = path_PKL + 'PKL_DATA2021_05_04_NN_hist.pkl'\n",
    "\n",
    "hf = open(path_NN_BF1,'rb')\n",
    "hist_NN_BF1 = pickle.load(hf)\n",
    "hist_NN_BF1 = hist_NN_BF1['hist']\n",
    "\n",
    "hf = open(path_NN_BF2,'rb')\n",
    "hist_NN_BF2 = pickle.load(hf)\n",
    "hist_NN_BF2 = hist_NN_BF2['hist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_NN_BF = {}\n",
    "for ikey,key in enumerate(hist_NN_BF1.keys()):\n",
    "    hist_NN_BF[key] = 0.5*(np.array(hist_NN_BF1[key])+np.array(hist_NN_BF2[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_MLR_BMSE = path_PKL + 'PKL_DATA2021_06_17_MLR_RH_BMSE_LHF_nsDELQ_hist.pkl'\n",
    "hf = open(path_MLR_BMSE,'rb')\n",
    "hist_MLR_BMSE = pickle.load(hf)\n",
    "hist_MLR_BMSE = hist_MLR_BMSE['hist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_MLR_TfromNS = path_PKL + 'PKL_DATA2021_04_26_MLR_RH_TfromNS_LHF_nsDELQ_hist.pkl'\n",
    "hf = open(path_MLR_TfromNS,'rb')\n",
    "hist_MLR_TfromNS = pickle.load(hf)\n",
    "hist_MLR_TfromNS = hist_MLR_TfromNS['hist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_NN_TfromNS = path_PKL + 'PKL_DATA2021_04_26_NN_RH_TfromNS_LHF_nsDELQ_hist.pkl'\n",
    "hf = open(path_NN_TfromNS,'rb')\n",
    "hist_NN_TfromNS = pickle.load(hf)\n",
    "hist_NN_TfromNS = hist_NN_TfromNS['hist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_NN_BMSE = path_PKL + 'PKL_DATA2021_06_17_NN_RH_BMSE_LHF_nsDELQ_hist.pkl'\n",
    "hf = open(path_NN_BMSE,'rb')\n",
    "hist_NN_BMSE = pickle.load(hf)\n",
    "hist_NN_BMSE = hist_NN_BMSE['hist']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warm to cold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_MLR_BF_W2C = path_PKL + 'PKL_DATA2021_04_27_W2C_MLR_hist.pkl'\n",
    "hf = open(path_MLR_BF_W2C,'rb')\n",
    "hist_MLR_BF_W2C = pickle.load(hf)\n",
    "hist_MLR_BF_W2C = hist_MLR_BF_W2C['hist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_NN_BF_W2C = path_PKL + 'PKL_DATA2021_04_27_W2C_NN_hist.pkl'\n",
    "hf = open(path_NN_BF_W2C,'rb')\n",
    "hist_NN_BF_W2C = pickle.load(hf)\n",
    "hist_NN_BF_W2C = hist_NN_BF_W2C['hist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_MLR_BMSE_W2C = path_PKL + 'PKL_DATA2021_04_27_W2C_MLR_RH_BCONS_LHF_nsDELQ_hist.pkl'\n",
    "hf = open(path_MLR_BMSE_W2C,'rb')\n",
    "hist_MLR_BMSE_W2C = pickle.load(hf)\n",
    "hist_MLR_BMSE_W2C = hist_MLR_BMSE_W2C['hist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_NN_BMSE_W2C = path_PKL + 'PKL_DATA2021_04_27_W2C_NN_RH_BCONS_LHF_nsDELQ_hist.pkl'\n",
    "hf = open(path_NN_BMSE_W2C,'rb')\n",
    "hist_NN_BMSE_W2C = pickle.load(hf)\n",
    "hist_NN_BMSE_W2C = hist_NN_BMSE_W2C['hist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_MLR_TfromNS_W2C = path_PKL + 'PKL_DATA2021_04_27_W2C_MLR_RH_TfromNS_LHF_nsDELQ_hist.pkl'\n",
    "hf = open(path_MLR_TfromNS_W2C,'rb')\n",
    "hist_MLR_TfromNS_W2C = pickle.load(hf)\n",
    "hist_MLR_TfromNS_W2C = hist_MLR_TfromNS_W2C['hist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_NN_TfromNS_W2C = path_PKL + 'PKL_DATA2021_04_27_W2C_NN_RH_TfromNS_LHF_nsDELQ_hist.pkl'\n",
    "hf = open(path_NN_TfromNS_W2C,'rb')\n",
    "hist_NN_TfromNS_W2C = pickle.load(hf)\n",
    "hist_NN_TfromNS_W2C = hist_NN_TfromNS_W2C['hist']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RG to aquaplanet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_MLR_BF_RG2AQ = path_PKL + 'PKL_DATA2021_06_03_RG2AQ_MLR_hist.pkl'\n",
    "hf = open(path_MLR_BF_RG2AQ,'rb')\n",
    "hist_MLR_BF_RG2AQ = pickle.load(hf)\n",
    "hist_MLR_BF_RG2AQ = hist_MLR_BF_RG2AQ['hist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_NN_BF_RG2AQ = path_PKL + 'PKL_DATA2021_06_03_RG2AQ_NN_hist.pkl'\n",
    "hf = open(path_NN_BF_RG2AQ,'rb')\n",
    "hist_NN_BF_RG2AQ = pickle.load(hf)\n",
    "hist_NN_BF_RG2AQ = hist_NN_BF_RG2AQ['hist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_MLR_BMSE_RG2AQ = path_PKL + 'PKL_DATA2021_06_17_RG2AQ_MLR_RH_BMSE_LHF_nsDELQ_hist.pkl'\n",
    "hf = open(path_MLR_BMSE_RG2AQ,'rb')\n",
    "hist_MLR_BMSE_RG2AQ = pickle.load(hf)\n",
    "hist_MLR_BMSE_RG2AQ = hist_MLR_BMSE_RG2AQ['hist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_NN_BMSE_RG2AQ = path_PKL + 'PKL_DATA2021_06_17_RG2AQ_NN_RH_BMSE_LHF_nsDELQ_hist.pkl'\n",
    "hf = open(path_NN_BMSE_RG2AQ,'rb')\n",
    "hist_NN_BMSE_RG2AQ = pickle.load(hf)\n",
    "hist_NN_BMSE_RG2AQ = hist_NN_BMSE_RG2AQ['hist']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch normalization & dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Climate-invariant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_CI_DPBN = path_PKL+'PKL_DATA2021_08_03_NN_RH_BMSE_LHF_nsDELQ_Dropout30_BNL1_hist.pkl'\n",
    "hf = open(path_CI_DPBN,'rb')\n",
    "hist_CI_DPBN = pickle.load(hf)\n",
    "hist_CI_DPBN = hist_CI_DPBN['hist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_CI_DPBN_W2C = path_PKL+'PKL_DATA2021_08_05_W2C_NN_RH_BMSE_LHF_nsDELQ_BNL1_Dropout30_hist.pkl'\n",
    "hf = open(path_CI_DPBN_W2C,'rb')\n",
    "hist_CI_DPBN_W2C = pickle.load(hf)\n",
    "hist_CI_DPBN_W2C = hist_CI_DPBN_W2C['hist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_CI_DPBN_RG2AQ = path_PKL+'PKL_DATA2021_08_07_RG2AQ_NN_RH_BMSE_LHF_nsDELQ_BNL1_Dropout30_hist.pkl'\n",
    "hf = open(path_CI_DPBN_RG2AQ,'rb')\n",
    "hist_CI_DPBN_RG2AQ = pickle.load(hf)\n",
    "hist_CI_DPBN_RG2AQ = hist_CI_DPBN_RG2AQ['hist'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brute-force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_BF_DPBN = path_PKL+'PKL_DATA2021_08_08_NN_BNL1_Dropout30_hist.pkl'\n",
    "hf = open(path_BF_DPBN,'rb')\n",
    "hist_BF_DPBN = pickle.load(hf)\n",
    "hist_BF_DPBN = hist_BF_DPBN['hist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_BF_DPBN_W2C = path_PKL+'PKL_DATA2021_08_08_W2C_NN_BNL1_DP30_hist.pkl'\n",
    "hf = open(path_BF_DPBN_W2C,'rb')\n",
    "hist_BF_DPBN_W2C = pickle.load(hf)\n",
    "hist_BF_DPBN_W2C = hist_BF_DPBN_W2C['hist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_BF_DPBN_RG2AQ = path_PKL+'PKL_DATA2021_08_09_RG2AQ_NN_BNL1_DP30_hist.pkl'\n",
    "hf = open(path_BF_DPBN_RG2AQ,'rb')\n",
    "hist_BF_DPBN_RG2AQ = pickle.load(hf)\n",
    "hist_BF_DPBN_RG2AQ = hist_BF_DPBN_RG2AQ['hist'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Table structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_array = np.zeros((3,2,6,4)) # Training sets x Best/5best x Models x Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "for itraining in range(3):\n",
    "    for imodel in range(6):\n",
    "        for itest in range(4):\n",
    "        \n",
    "            if itraining==0:\n",
    "                if imodel==0: h = hist_MLR_BF; k = ['loss', 'val_loss', 'trainP4K_loss', 'trainM4K_RG_loss']\n",
    "                elif imodel==1: h = hist_MLR_BMSE;\n",
    "                elif imodel==2: h = hist_NN_BF;\n",
    "                elif imodel==3: h = hist_BF_DPBN;\n",
    "                elif imodel==4: h = hist_NN_BMSE;\n",
    "                elif imodel==5: h = hist_CI_DPBN;\n",
    "            elif itraining==1:\n",
    "                if imodel==0: h = hist_MLR_BF_W2C; k = ['loss', 'val_loss', 'trainM4K_loss', 'trainP4K_RG_loss']\n",
    "                elif imodel==1: h = hist_MLR_BMSE_W2C;\n",
    "                elif imodel==2: h = hist_NN_BF_W2C;\n",
    "                elif imodel==3: h = hist_BF_DPBN_W2C;\n",
    "                elif imodel==4: h = hist_NN_BMSE_W2C;\n",
    "                elif imodel==5: h = hist_CI_DPBN_W2C;\n",
    "            elif itraining==2:\n",
    "                if imodel==0: h = hist_MLR_BF_RG2AQ; k = ['loss', 'val_loss', 'trainM4K_loss', 'trainP4K_RG_loss']\n",
    "                elif imodel==1: h = hist_MLR_BMSE_RG2AQ;\n",
    "                elif imodel==2: h = hist_NN_BF_RG2AQ;\n",
    "                elif imodel==3: h = hist_BF_DPBN_RG2AQ;\n",
    "                elif imodel==4: h = hist_NN_BMSE_RG2AQ;\n",
    "                elif imodel==5: h = hist_CI_DPBN_RG2AQ;\n",
    "                 \n",
    "            sortI = np.argsort(h[k[itest]])\n",
    "            MSE_array[itraining,0,imodel,itest] = h[k[itest]][sortI[0]]\n",
    "            hav = 0\n",
    "            for iav in range(5):\n",
    "                hav += h[k[itest]][sortI[iav]]/5\n",
    "            MSE_array[itraining,1,imodel,itest] = hav "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 287.11117402,  288.11598898,  758.90221729,  242.08142289],\n",
       "         [ 293.76082433,  295.28024048,  670.7392851 ,  244.70504782],\n",
       "         [ 171.50021224,  172.46501454, 2166.69840228, 1097.74414623],\n",
       "         [ 222.2906224 ,  205.49047099, 3225.41949269,  258.34723369],\n",
       "         [ 168.1828624 ,  168.83162262,  422.45767988,  297.14024651],\n",
       "         [ 214.03646156,  198.08084332,  483.04392227,  223.74575334]],\n",
       "\n",
       "        [[ 287.72552378,  288.70623946,  785.3445987 ,  264.57652311],\n",
       "         [ 294.03108209,  295.49485597,  671.3164503 ,  264.97253692],\n",
       "         [ 172.09604856,  173.02085487, 2242.22209759, 1117.05410698],\n",
       "         [ 222.48878954,  206.02322339, 3509.21137195,  318.13514165],\n",
       "         [ 168.57171761,  169.24722777,  424.73102696,  315.60475745],\n",
       "         [ 214.12770263,  198.47536021,  486.51962509,  226.91668654]]],\n",
       "\n",
       "\n",
       "       [[[ 642.3658514 ,  643.36672895,  327.52253143,  506.71041051],\n",
       "         [ 653.3779052 ,  653.34683373,  315.23279671,  515.36801732],\n",
       "         [ 363.09348276,  362.24255903,  385.9299837 , 1354.26707684],\n",
       "         [ 472.66049315,  434.42300693,  247.72131095,  727.94808782],\n",
       "         [ 361.96314963,  362.06332127,  429.59411191,  590.20144837],\n",
       "         [ 451.19113983,  412.27838163,  210.26086015,  566.53455825]],\n",
       "\n",
       "        [[ 643.80465684,  644.71768159,  329.87668878,  542.58211593],\n",
       "         [ 654.21124605,  654.15038056,  317.10109692,  559.58606543],\n",
       "         [ 364.30474571,  363.98414903,  472.41913393, 1612.44821398],\n",
       "         [ 473.19973409,  436.35863868,  248.2295525 , 1275.08116909],\n",
       "         [ 363.26778882,  364.37844244,  449.13821896,  601.30616218],\n",
       "         [ 451.44146958,  414.21338919,  212.18641822,  659.2112324 ]]],\n",
       "\n",
       "\n",
       "       [[[ 197.29348996,  196.64264546,  508.30307777,  299.30723076],\n",
       "         [ 202.84442127,  202.04059521,  458.77833164,  307.4322875 ],\n",
       "         [ 114.1155039 ,  115.80217243,  709.44854695,  247.35190515],\n",
       "         [ 165.07596537,  151.6602997 ,  512.02141129,  246.90042521],\n",
       "         [ 111.82356473,  113.84373935,  291.5432753 ,  311.61563138],\n",
       "         [ 157.58986503,  143.50718623,  345.96916327,  228.76273491]],\n",
       "\n",
       "        [[ 197.40916537,  196.75108972,  561.77915702,  299.38310925],\n",
       "         [ 202.88754874,  202.08203924,  458.83983986,  307.48282354],\n",
       "         [ 114.4353074 ,  116.43180828,  803.17125268,  251.35529052],\n",
       "         [ 165.17255472,  151.90986615,  574.93194984,  247.18068319],\n",
       "         [ 112.11265907,  114.30249645,  293.73192954,  323.28477066],\n",
       "         [ 157.67008912,  143.71684314,  347.09731433,  233.17548579]]]])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table code in latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "TABLEname = 'CI_Paper_Results'\n",
    "path_TXT = '/export/home/tbeucler/CBRAIN-CAM/notebooks/tbeucler_devlog/TXT_DATA/'\n",
    "path = path_TXT+TABLEname+\".txt\"\n",
    "\n",
    "topline1 = \" & & Training Set & \\\\textbf{Validation Set} & Training Set & Training Set\\\\tabularnewline\\n\"\n",
    "topline2 = \"Trained & Model & Same temperature & Same temperature & \\\\textbf{Different temperature} & Same temperature\\\\tabularnewline\\n\"\n",
    "topline3 = \"on & & Same configuration & Same configuration & Same configuration & \\\\textbf{Different configuration}\\\\tabularnewline\\n\"\n",
    "\n",
    "caption = \"Mean-Squared Error (MSE, in units W$^{2}$ m$^{-4}$) of six models trained in three simulations (first column)\"+\\\n",
    "\" and evaluated over the training or validation set of the same and two other simulations (last four columns).\"+\\\n",
    "\" The models (second column) are brute-force (BF) or climate-invariant (CI), multiple linear regressions (MLR) \"+\\\n",
    "\"or neural nets (NN), and sometimes include dropout layers preceded by a batch normalization layer (DN).\"+\\\n",
    "\" The models are trained for 20 epochs and we give the MSE corresponding to the epoch of minimal validation loss\"+\\\n",
    "\" followed by the MSE averaged over the 5 epochs with lowest validation losses (in parentheses).\"\n",
    "\n",
    "COLOR = ['black','purple','black','teal','purple','teal']\n",
    "MODEL = [[\" & MLR BF\",\n",
    "          \"\\\\textcolor{blue}{Cold} & \\\\textcolor{purple}{MLR CI}\",\n",
    "          \"\\\\textcolor{blue}{Aquaplanet} & NN BF\",\n",
    "          \"\\\\textcolor{blue}{(-4K)} & \\\\textcolor{teal}{NN BF+DN}\",\n",
    "          \"SPCAM3 & \\\\textcolor{purple}{NN CI}\",\n",
    "          \" & \\\\textcolor{teal}{NN CI+DN}\"],\n",
    "         [\" & MLR BF\",\n",
    "          \"\\\\textcolor{red}{Warm} & \\\\textcolor{purple}{MLR CI}\",\n",
    "          \"\\\\textcolor{red}{Aquaplanet} & NN BF\",\n",
    "          \"\\\\textcolor{red}{(+4K)} & \\\\textcolor{teal}{NN BF+DN}\",\n",
    "          \"SPCAM3 & \\\\textcolor{purple}{NN CI}\",\n",
    "          \" & \\\\textcolor{teal}{NN CI+DN}\"],\n",
    "         [\" & MLR BF\",\n",
    "          \"\\\\textcolor{green}{Cold} & \\\\textcolor{purple}{MLR CI}\",\n",
    "          \"\\\\textcolor{green}{Earth-like} & NN BF\",\n",
    "          \"\\\\textcolor{green}{(-4K)} & \\\\textcolor{teal}{NN BF+DN}\",\n",
    "          \"SPCAM5 & \\\\textcolor{purple}{NN CI}\",\n",
    "          \" & \\\\textcolor{teal}{NN CI+DN}\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table CI_Paper_Results printed to /export/home/tbeucler/CBRAIN-CAM/notebooks/tbeucler_devlog/TXT_DATA/CI_Paper_Results.txt\n"
     ]
    }
   ],
   "source": [
    "f= open(path,\"w+\")\n",
    "f.write(\"\\\\begin{table*}\\n\")\n",
    "f.write(\"\\\\begin{centering}\\n\")\n",
    "f.write(\"\\\\begin{tabular}{c|c||c|c|c|c}\\n\")\n",
    "f.write(topline1)\n",
    "f.write(topline2)\n",
    "f.write(topline3)\n",
    "for itrain in range(3):\n",
    "    f.write(\"\\\\hline\\n\")\n",
    "    for imodel in range(6):\n",
    "        f.write(MODEL[itrain][imodel])\n",
    "        for itest in range(4):\n",
    "            f.write(\" & \")\n",
    "            f.write(\"\\\\textcolor{\"+COLOR[imodel]+\"}{\")\n",
    "            f.write(\"%3.0f\"%MSE_array[itrain,0,imodel,itest]+\" \")\n",
    "            f.write(\"(\"+\"%3.0f\"%MSE_array[itrain,1,imodel,itest]+\") \")\n",
    "            f.write(\"}\")\n",
    "        f.write(\"\\\\tabularnewline\\n\")\n",
    "f.write(\"\\\\end{tabular}\\n\")\n",
    "f.write(\"\\\\par\\\\end{centering}\\n\")\n",
    "f.write(\"\\n\")\n",
    "f.write(\"\\\\caption{\")\n",
    "f.write(caption)\n",
    "f.write(\"}\\n\")\n",
    "f.write(\"\\\\label{tab:Results}\\n\")\n",
    "f.write(\"\\\\end{table*}\\n\")\n",
    "f.close()\n",
    "print('Table',TABLEname,'printed to',path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
