{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tgb - 5/3/2021 - Load climate-invariant versions of models with and without output rescaling and see which one performs best in terms of MSE in the different climate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "- Load models with or without output rescaling  \n",
    "- Code np and tf layers to interpolate back and forth from/to quantile space  \n",
    "- Evaluate MSE for pre vs post processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1,\"/home1/07064/tg863631/anaconda3/envs/CbrainCustomLayer/lib/python3.6/site-packages\") #work around for h5py\n",
    "from cbrain.imports import *\n",
    "from cbrain.cam_constants import *\n",
    "from cbrain.utils import *\n",
    "from cbrain.layers import *\n",
    "from cbrain.data_generator import DataGenerator\n",
    "from cbrain.climate_invariant import *\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy import interp\n",
    "\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "tf.config.experimental.set_memory_growth(physical_devices[1], True)\n",
    "tf.config.experimental.set_memory_growth(physical_devices[2], True)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "\n",
    "from tensorflow import math as tfm\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "import tensorflow_probability as tfp\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from cbrain.model_diagnostics import ModelDiagnostics\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as imag\n",
    "import scipy.integrate as sin\n",
    "# import cartopy.crs as ccrs\n",
    "import matplotlib.ticker as mticker\n",
    "# from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import pickle\n",
    "# from climate_invariant import *\n",
    "from tensorflow.keras import layers\n",
    "import datetime\n",
    "from climate_invariant_utils import *\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fz = 15\n",
    "lw = 4\n",
    "siz = 100\n",
    "S0 = 320 # Representative mean solar insolation for normalization purposes\n",
    "S0max = 1410.6442 # Max solar insolation for normalization purposes\n",
    "SN = S0/100 # Representative target = mean insolation / 4\n",
    "XNNA = 1.25 # Abscissa where architecture-constrained network will be placed\n",
    "XTEXT = 0.25 # Text placement\n",
    "YMIN = -1 # Representative value for conserving network\n",
    "YTEXT = 0.3 # Text placement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('text', usetex=False)\n",
    "mpl.rcParams['mathtext.fontset'] = 'stix'\n",
    "mpl.rcParams['font.family'] = 'STIXGeneral'\n",
    "plt.rc('font', family='serif', size=fz)\n",
    "mpl.rcParams['lines.linewidth'] = lw\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathPKL = '/export/home/tbeucler/CBRAIN-CAM/notebooks/tbeucler_devlog/PKL_DATA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_array = np.linspace(0,1,1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_array = [\n",
    "    '2021_03_18_O3_TRAIN_M4K_shuffle.nc',\n",
    "    '2021_03_18_O3_TRAIN_P4K_shuffle.nc',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = {}\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ipath,path in enumerate(path_array):\n",
    "    hf = open(pathPKL+'/'+path+'_PERC.pkl','rb')\n",
    "    pdf[path] = pickle.load(hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2021_03_18_O3_TRAIN_M4K_shuffle.nc': {'quantile_array': array([0.   , 0.001, 0.002, ..., 0.998, 0.999, 1.   ]),\n",
       "  'PERC_array': array([[9.05374009e-07, 8.77815637e-07, 4.98417307e-07, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [9.11630138e-07, 8.91066577e-07, 5.24233712e-07, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [9.13556164e-07, 8.93629931e-07, 5.24234508e-07, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         ...,\n",
       "         [1.81165069e-06, 1.79016258e-06, 1.61611712e-06, ...,\n",
       "          4.71056754e-05, 4.42048546e-05, 8.29813011e-05],\n",
       "         [1.81427470e-06, 1.79245058e-06, 1.62005475e-06, ...,\n",
       "          6.76648574e-05, 7.45083865e-05, 1.28348825e-04],\n",
       "         [1.82074757e-06, 1.80071015e-06, 1.63516086e-06, ...,\n",
       "          5.01840608e-04, 5.79330081e-04, 6.49507623e-04]])},\n",
       " '2021_03_18_O3_TRAIN_P4K_shuffle.nc': {'quantile_array': array([0.   , 0.001, 0.002, ..., 0.998, 0.999, 1.   ]),\n",
       "  'PERC_array': array([[1.37732434e-06, 1.19104163e-06, 4.81186021e-07, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [1.38357811e-06, 1.25212376e-06, 5.24233371e-07, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [1.38551718e-06, 1.26565038e-06, 5.24234849e-07, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         ...,\n",
       "         [1.74623960e-06, 1.71437534e-06, 1.62744289e-06, ...,\n",
       "          4.11302145e-05, 3.78862698e-05, 3.93864722e-05],\n",
       "         [1.74847685e-06, 1.71654372e-06, 1.68633071e-06, ...,\n",
       "          6.17628516e-05, 6.37223272e-05, 1.02323095e-04],\n",
       "         [1.76003380e-06, 1.72247303e-06, 2.10690723e-06, ...,\n",
       "          4.85183118e-04, 5.21734299e-04, 5.82364621e-04]])}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create data generators for all three cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load coordinates (just pick any file from the climate model run)\n",
    "\n",
    "# Comet path below\n",
    "# coor = xr.open_dataset(\"/oasis/scratch/comet/ankitesh/temp_project/data/sp8fbp_minus4k.cam2.h1.0000-01-01-00000.nc\",\\\n",
    "#                     decode_times=False)\n",
    "\n",
    "# GP path below\n",
    "path_0K = '/DFS-L/DATA/pritchard/tbeucler/SPCAM/fluxbypass_aqua/'\n",
    "coor = xr.open_dataset(path_0K+\"AndKua_aqua_SPCAM3.0_sp_fbp_f4.cam2.h1.0000-09-02-00000.nc\")\n",
    "\n",
    "lat = coor.lat; lon = coor.lon; lev = coor.lev;\n",
    "coor.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comet path below\n",
    "# TRAINDIR = '/oasis/scratch/comet/ankitesh/temp_project/PrepData/CRHData/'\n",
    "# path = '/home/ankitesh/CBrain_project/CBRAIN-CAM/cbrain/'\n",
    "\n",
    "# GP path below\n",
    "TRAINDIR = '/DFS-L/DATA/pritchard/tbeucler/SPCAM/SPCAM_PHYS/'\n",
    "path = '/export/nfs0home/tbeucler/CBRAIN-CAM/cbrain/'\n",
    "path_nnconfig = '/export/nfs0home/tbeucler/CBRAIN-CAM/nn_config/'\n",
    "\n",
    "# Load hyam and hybm to calculate pressure field in SPCAM\n",
    "path_hyam = 'hyam_hybm.pkl'\n",
    "hf = open(path+path_hyam,'rb')\n",
    "hyam,hybm = pickle.load(hf)\n",
    "\n",
    "# Scale dictionary to convert the loss to W/m2\n",
    "scale_dict = load_pickle(path_nnconfig+'scale_dicts/009_Wm2_scaling.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Data generator class for the climate-invariant network. Calculates the physical rescalings needed to make the NN climate-invariant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose between aquaplanet and realistic geography here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GP paths below\n",
    "#path_aquaplanet = '/DFS-L/DATA/pritchard/tbeucler/SPCAM/SPCAM_PHYS/'\n",
    "#path_realgeography = ''\n",
    "\n",
    "# GP /fast paths below\n",
    "path_aquaplanet = '/fast/tbeucler/climate_invariant/aquaplanet/'\n",
    "\n",
    "# Comet paths below\n",
    "# path_aquaplanet = '/oasis/scratch/comet/ankitesh/temp_project/PrepData/'\n",
    "# path_realgeography = '/oasis/scratch/comet/ankitesh/temp_project/PrepData/geography/'\n",
    "\n",
    "path = path_aquaplanet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generator using RH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale_dict_RH = load_pickle('/home/ankitesh/CBrain_project/CBRAIN-CAM/nn_config/scale_dicts/009_Wm2_scaling_2.pkl')\n",
    "scale_dict_RH = scale_dict.copy()\n",
    "scale_dict_RH['RH'] = 0.01*L_S/G, # Arbitrary 0.1 factor as specific humidity is generally below 2%\n",
    "\n",
    "in_vars_RH = ['RH','TBP','PS', 'SOLIN', 'SHFLX', 'LHFLX']\n",
    "# if path==path_realgeography: out_vars_RH = ['PTEQ','PTTEND','FSNT','FSNS','FLNT','FLNS']\n",
    "# elif path==path_aquaplanet: out_vars_RH = ['PHQ','TPHYSTND','FSNT', 'FSNS', 'FLNT', 'FLNS']\n",
    "if path==path_aquaplanet: out_vars_RH = ['PHQ','TPHYSTND','QRL','QRS']\n",
    "\n",
    "# New GP path below\n",
    "TRAINFILE_RH = '2021_01_24_O3_small_shuffle.nc'\n",
    "NORMFILE_RH = '2021_02_01_NORM_O3_RH_small.nc'\n",
    "    \n",
    "# Comet/Ankitesh path below\n",
    "# TRAINFILE_RH = 'CI_RH_M4K_NORM_train_shuffle.nc'\n",
    "# NORMFILE_RH = 'CI_RH_M4K_NORM_norm.nc'\n",
    "# VALIDFILE_RH = 'CI_RH_M4K_NORM_valid.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen_RH = DataGenerator(\n",
    "    data_fn = path+TRAINFILE_RH,\n",
    "    input_vars = in_vars_RH,\n",
    "    output_vars = out_vars_RH,\n",
    "    norm_fn = path+NORMFILE_RH,\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dict_RH,\n",
    "    batch_size=1024,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generator using QSATdeficit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only need the norm file for this generator as we are solely using it as an input to determine the right normalization for the combined generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New GP path below\n",
    "TRAINFILE_QSATdeficit = '2021_02_01_O3_QSATdeficit_small_shuffle.nc'\n",
    "NORMFILE_QSATdeficit = '2021_02_01_NORM_O3_QSATdeficit_small.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_vars_QSATdeficit = ['QSATdeficit','TBP','PS', 'SOLIN', 'SHFLX', 'LHFLX']\n",
    "# if path==path_realgeography: out_vars_RH = ['PTEQ','PTTEND','FSNT','FSNS','FLNT','FLNS']\n",
    "# elif path==path_aquaplanet: out_vars_RH = ['PHQ','TPHYSTND','FSNT', 'FSNS', 'FLNT', 'FLNS']\n",
    "if path==path_aquaplanet: out_vars_QSATdeficit = ['PHQ','TPHYSTND','QRL','QRS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen_QSATdeficit = DataGenerator(\n",
    "    data_fn = path+TRAINFILE_QSATdeficit,\n",
    "    input_vars = in_vars_QSATdeficit,\n",
    "    output_vars = out_vars_QSATdeficit,\n",
    "    norm_fn = path+NORMFILE_QSATdeficit,\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dict,\n",
    "    batch_size=1024,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generator using TNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_vars = ['QBP','TfromNS','PS', 'SOLIN', 'SHFLX', 'LHFLX']\n",
    "if path==path_aquaplanet: out_vars = ['PHQ','TPHYSTND','FSNT', 'FSNS', 'FLNT', 'FLNS']\n",
    "elif path==path_realgeography: out_vars = ['PTEQ','PTTEND','FSNT','FSNS','FLNT','FLNS']\n",
    "\n",
    "TRAINFILE_TNS = '2021_02_01_O3_TfromNS_small_shuffle.nc'\n",
    "NORMFILE_TNS = '2021_02_01_NORM_O3_TfromNS_small.nc'\n",
    "VALIDFILE_TNS = 'CI_TNS_M4K_NORM_valid.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen_TNS = DataGenerator(\n",
    "    data_fn = path+TRAINFILE_TNS,\n",
    "    input_vars = in_vars,\n",
    "    output_vars = out_vars,\n",
    "    norm_fn = path+NORMFILE_TNS,\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dict,\n",
    "    batch_size=1024,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generator using BCONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_vars = ['QBP','BCONS','PS', 'SOLIN', 'SHFLX', 'LHFLX']\n",
    "if path==path_aquaplanet: out_vars = ['PHQ','TPHYSTND','FSNT', 'FSNS', 'FLNT', 'FLNS']\n",
    "elif path==path_realgeography: out_vars = ['PTEQ','PTTEND','FSNT','FSNS','FLNT','FLNS']\n",
    "\n",
    "TRAINFILE_BCONS = '2021_02_01_O3_BCONS_small_shuffle.nc'\n",
    "NORMFILE_BCONS = '2021_02_01_NORM_O3_BCONS_small.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen_BCONS = DataGenerator(\n",
    "    data_fn = path+TRAINFILE_BCONS,\n",
    "    input_vars = in_vars,\n",
    "    output_vars = out_vars,\n",
    "    norm_fn = path+NORMFILE_BCONS,\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dict,\n",
    "    batch_size=1024,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generator using NSto220"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_vars = ['QBP','T_NSto220','PS', 'SOLIN', 'SHFLX', 'LHFLX']\n",
    "if path==path_aquaplanet: out_vars = ['PHQ','TPHYSTND','FSNT', 'FSNS', 'FLNT', 'FLNS']\n",
    "elif path==path_realgeography: out_vars = ['PTEQ','PTTEND','FSNT','FSNS','FLNT','FLNS']\n",
    "\n",
    "TRAINFILE_T_NSto220 = '2021_03_31_O3_T_NSto220_small.nc'\n",
    "NORMFILE_T_NSto220 = '2021_03_31_NORM_O3_T_NSto220_small.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen_T_NSto220 = DataGenerator(\n",
    "    data_fn = path+TRAINFILE_T_NSto220,\n",
    "    input_vars = in_vars,\n",
    "    output_vars = out_vars,\n",
    "    norm_fn = path+NORMFILE_T_NSto220,\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dict,\n",
    "    batch_size=8192,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generator using LHF_nsDELQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_vars = ['QBP','TBP','PS', 'SOLIN', 'SHFLX', 'LHF_nsDELQ']\n",
    "if path==path_aquaplanet: out_vars = ['PHQ','TPHYSTND','FSNT', 'FSNS', 'FLNT', 'FLNS']\n",
    "elif path==path_realgeography: out_vars = ['PTEQ','PTTEND','FSNT','FSNS','FLNT','FLNS']\n",
    "\n",
    "TRAINFILE_LHF_nsDELQ = '2021_02_01_O3_LHF_nsDELQ_small_shuffle.nc'\n",
    "NORMFILE_LHF_nsDELQ = '2021_02_01_NORM_O3_LHF_nsDELQ_small.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen_LHF_nsDELQ = DataGenerator(\n",
    "    data_fn = path+TRAINFILE_LHF_nsDELQ,\n",
    "    input_vars = in_vars,\n",
    "    output_vars = out_vars,\n",
    "    norm_fn = path+NORMFILE_LHF_nsDELQ,\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dict,\n",
    "    batch_size=8192,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generator using LHF_nsQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_vars = ['QBP','TBP','PS', 'SOLIN', 'SHFLX', 'LHF_nsQ']\n",
    "if path==path_aquaplanet: out_vars = ['PHQ','TPHYSTND','FSNT', 'FSNS', 'FLNT', 'FLNS']\n",
    "elif path==path_realgeography: out_vars = ['PTEQ','PTTEND','FSNT','FSNS','FLNT','FLNS']\n",
    "\n",
    "TRAINFILE_LHF_nsQ = '2021_02_01_O3_LHF_nsQ_small_shuffle.nc'\n",
    "NORMFILE_LHF_nsQ = '2021_02_01_NORM_O3_LHF_nsQ_small.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen_LHF_nsQ = DataGenerator(\n",
    "    data_fn = path+TRAINFILE_LHF_nsQ,\n",
    "    input_vars = in_vars,\n",
    "    output_vars = out_vars,\n",
    "    norm_fn = path+NORMFILE_LHF_nsQ,\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dict,\n",
    "    batch_size=8192,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generator Combined (latest flexible version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_vars = ['QBP','TBP','PS', 'SOLIN', 'SHFLX', 'LHFLX']\n",
    "#if path==path_aquaplanet: out_vars=['PHQPERC','TPHYSTNDPERC','QRLPERC','QRSPERC']\n",
    "out_vars = ['PHQ','TPHYSTND','QRL','QRS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINFILE = '2021_01_24_O3_TRAIN_shuffle.nc'\n",
    "NORMFILE = '2021_01_24_NORM_O3_small.nc'\n",
    "# VALIDFILE = '2021_01_24_O3_VALID.nc'\n",
    "# GENTESTFILE = 'CI_SP_P4K_valid.nc'\n",
    "\n",
    "# In physical space\n",
    "TRAINFILE = '2021_03_18_O3_TRAIN_M4K_shuffle.nc'\n",
    "VALIDFILE = '2021_03_18_O3_VALID_M4K.nc'\n",
    "TESTFILE_DIFFCLIMATE = '2021_03_18_O3_TRAIN_P4K_shuffle.nc'\n",
    "TESTFILE_DIFFGEOG = '2021_04_18_RG_TRAIN_M4K_shuffle.nc'\n",
    "\n",
    "# In percentile space\n",
    "#TRAINFILE = '2021_04_09_PERC_TRAIN_M4K_shuffle.nc'\n",
    "#TRAINFILE = '2021_01_24_O3_small_shuffle.nc'\n",
    "#VALIDFILE = '2021_04_09_PERC_VALID_M4K.nc'\n",
    "#TESTFILE = '2021_04_09_PERC_TEST_P4K.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ipath,path in enumerate([TRAINFILE,VALIDFILE,TESTFILE_DIFFCLIMATE,TESTFILE_DIFFGEOG]):\n",
    "    hf = open(pathPKL+'/'+path+'_PERC.pkl','rb')\n",
    "    pdf[path] = pickle.load(hf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brute-force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen_BF = DataGeneratorCI(data_fn = path+TRAINFILE,\n",
    "                               input_vars=in_vars,\n",
    "                               output_vars=out_vars,\n",
    "                               norm_fn=path+NORMFILE,\n",
    "                               input_transform=('mean', 'maxrs'),\n",
    "                               output_transform=scale_dict,\n",
    "                               batch_size=8192,\n",
    "                               shuffle=True,\n",
    "                               xarray=False,\n",
    "                               var_cut_off=None, \n",
    "                               Qscaling=None,\n",
    "                               Tscaling=None,\n",
    "                               LHFscaling=None,\n",
    "                               SHFscaling=None,\n",
    "                               output_scaling=False,\n",
    "                               interpolate=False,\n",
    "                               hyam=hyam,hybm=hybm,\n",
    "                               inp_sub_Qscaling=None,\n",
    "                               inp_div_Qscaling=None,\n",
    "                               inp_sub_Tscaling=None,\n",
    "                               inp_div_Tscaling=None,\n",
    "                               inp_sub_LHFscaling=None,\n",
    "                               inp_div_LHFscaling=None,\n",
    "                               inp_sub_SHFscaling=None,\n",
    "                               inp_div_SHFscaling=None,\n",
    "                               lev=None, interm_size=40,\n",
    "                               lower_lim=6,is_continous=True,Tnot=5,\n",
    "                               epsQ=1e-3,epsT=1,mode='train')\n",
    "\n",
    "test_diffclimate_gen_BF = DataGeneratorCI(data_fn = path+TESTFILE_DIFFCLIMATE,\n",
    "                                       input_vars=in_vars,\n",
    "                                       output_vars=out_vars,\n",
    "                                       norm_fn=path+NORMFILE,\n",
    "                                       input_transform=('mean', 'maxrs'),\n",
    "                                       output_transform=scale_dict,\n",
    "                                       batch_size=8192,\n",
    "                                       shuffle=True,\n",
    "                                       xarray=False,\n",
    "                                       var_cut_off=None, \n",
    "                                       Qscaling=None,\n",
    "                                       Tscaling=None,\n",
    "                                       LHFscaling=None,\n",
    "                                       SHFscaling=None,\n",
    "                                       output_scaling=False,\n",
    "                                       interpolate=False,\n",
    "                                       hyam=hyam,hybm=hybm,\n",
    "                                       inp_sub_Qscaling=None,\n",
    "                                       inp_div_Qscaling=None,\n",
    "                                       inp_sub_Tscaling=None,\n",
    "                                       inp_div_Tscaling=None,\n",
    "                                       inp_sub_LHFscaling=None,\n",
    "                                       inp_div_LHFscaling=None,\n",
    "                                       inp_sub_SHFscaling=None,\n",
    "                                       inp_div_SHFscaling=None,\n",
    "                                       lev=None, interm_size=40,\n",
    "                                       lower_lim=6,is_continous=True,Tnot=5,\n",
    "                                       epsQ=1e-3,epsT=1,mode='train')\n",
    "\n",
    "test_diffgeog_gen_BF = DataGeneratorCI(data_fn = path+TESTFILE_DIFFGEOG,\n",
    "                                       input_vars=in_vars,\n",
    "                                       output_vars=out_vars,\n",
    "                                       norm_fn=path+NORMFILE,\n",
    "                                       input_transform=('mean', 'maxrs'),\n",
    "                                       output_transform=scale_dict,\n",
    "                                       batch_size=8192,\n",
    "                                       shuffle=True,\n",
    "                                       xarray=False,\n",
    "                                       var_cut_off=None, \n",
    "                                       Qscaling=None,\n",
    "                                       Tscaling=None,\n",
    "                                       LHFscaling=None,\n",
    "                                       SHFscaling=None,\n",
    "                                       output_scaling=False,\n",
    "                                       interpolate=False,\n",
    "                                       hyam=hyam,hybm=hybm,\n",
    "                                       inp_sub_Qscaling=None,\n",
    "                                       inp_div_Qscaling=None,\n",
    "                                       inp_sub_Tscaling=None,\n",
    "                                       inp_div_Tscaling=None,\n",
    "                                       inp_sub_LHFscaling=None,\n",
    "                                       inp_div_LHFscaling=None,\n",
    "                                       inp_sub_SHFscaling=None,\n",
    "                                       inp_div_SHFscaling=None,\n",
    "                                       lev=None, interm_size=40,\n",
    "                                       lower_lim=6,is_continous=True,Tnot=5,\n",
    "                                       epsQ=1e-3,epsT=1,mode='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input but not output rescaled (T=BCONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tscaling_name = 'BCONS'\n",
    "train_gen_T = train_gen_BCONS\n",
    "\n",
    "train_gen_I = DataGeneratorCI(data_fn = path+TRAINFILE,\n",
    "                               input_vars=in_vars,\n",
    "                               output_vars=out_vars,\n",
    "                               norm_fn=path+NORMFILE,\n",
    "                               input_transform=('mean', 'maxrs'),\n",
    "                               output_transform=scale_dict,\n",
    "                               batch_size=8192,\n",
    "                               shuffle=True,\n",
    "                               xarray=False,\n",
    "                               var_cut_off=None, \n",
    "                               Qscaling='RH',\n",
    "                               Tscaling=Tscaling_name,\n",
    "                               LHFscaling='LHF_nsDELQ',\n",
    "                               SHFscaling=None,\n",
    "                               output_scaling=False,\n",
    "                               interpolate=False,\n",
    "                               hyam=hyam,hybm=hybm,\n",
    "                               inp_sub_Qscaling=train_gen_RH.input_transform.sub,\n",
    "                               inp_div_Qscaling=train_gen_RH.input_transform.div,\n",
    "                               inp_sub_Tscaling=train_gen_T.input_transform.sub,\n",
    "                               inp_div_Tscaling=train_gen_T.input_transform.div,\n",
    "                               inp_sub_LHFscaling=train_gen_LHF_nsDELQ.input_transform.sub,\n",
    "                               inp_div_LHFscaling=train_gen_LHF_nsDELQ.input_transform.div,\n",
    "                               inp_sub_SHFscaling=None,\n",
    "                               inp_div_SHFscaling=None,\n",
    "                               lev=None, interm_size=40,\n",
    "                               lower_lim=6,is_continous=True,Tnot=5,\n",
    "                               epsQ=1e-3,epsT=1,mode='train')\n",
    "\n",
    "valid_gen_I = DataGeneratorCI(data_fn = path+VALIDFILE,\n",
    "                               input_vars=in_vars,\n",
    "                               output_vars=out_vars,\n",
    "                               norm_fn=path+NORMFILE,\n",
    "                               input_transform=('mean', 'maxrs'),\n",
    "                               output_transform=scale_dict,\n",
    "                               batch_size=8192,\n",
    "                               shuffle=True,\n",
    "                               xarray=False,\n",
    "                               var_cut_off=None, \n",
    "                               Qscaling='RH',\n",
    "                               Tscaling=Tscaling_name,\n",
    "                               LHFscaling='LHF_nsDELQ',\n",
    "                               SHFscaling=None,\n",
    "                               output_scaling=False,\n",
    "                               interpolate=False,\n",
    "                               hyam=hyam,hybm=hybm,\n",
    "                               inp_sub_Qscaling=train_gen_RH.input_transform.sub,\n",
    "                               inp_div_Qscaling=train_gen_RH.input_transform.div,\n",
    "                               inp_sub_Tscaling=train_gen_T.input_transform.sub,\n",
    "                               inp_div_Tscaling=train_gen_T.input_transform.div,\n",
    "                               inp_sub_LHFscaling=train_gen_LHF_nsDELQ.input_transform.sub,\n",
    "                               inp_div_LHFscaling=train_gen_LHF_nsDELQ.input_transform.div,\n",
    "                               inp_sub_SHFscaling=None,\n",
    "                               inp_div_SHFscaling=None,\n",
    "                               lev=None, interm_size=40,\n",
    "                               lower_lim=6,is_continous=True,Tnot=5,\n",
    "                               epsQ=1e-3,epsT=1,mode='train')\n",
    "\n",
    "test_diffclimate_gen_I = DataGeneratorCI(data_fn = path+TESTFILE_DIFFCLIMATE,\n",
    "                                       input_vars=in_vars,\n",
    "                                       output_vars=out_vars,\n",
    "                                       norm_fn=path+NORMFILE,\n",
    "                                       input_transform=('mean', 'maxrs'),\n",
    "                                       output_transform=scale_dict,\n",
    "                                       batch_size=8192,\n",
    "                                       shuffle=True,\n",
    "                                       xarray=False,\n",
    "                                       var_cut_off=None, \n",
    "                                       Qscaling='RH',\n",
    "                                       Tscaling=Tscaling_name,\n",
    "                                       LHFscaling='LHF_nsDELQ',\n",
    "                                       SHFscaling=None,\n",
    "                                       output_scaling=False,\n",
    "                                       interpolate=False,\n",
    "                                       hyam=hyam,hybm=hybm,\n",
    "                                       inp_sub_Qscaling=train_gen_RH.input_transform.sub,\n",
    "                                       inp_div_Qscaling=train_gen_RH.input_transform.div,\n",
    "                                       inp_sub_Tscaling=train_gen_T.input_transform.sub,\n",
    "                                       inp_div_Tscaling=train_gen_T.input_transform.div,\n",
    "                                       inp_sub_LHFscaling=train_gen_LHF_nsDELQ.input_transform.sub,\n",
    "                                       inp_div_LHFscaling=train_gen_LHF_nsDELQ.input_transform.div,\n",
    "                                       inp_sub_SHFscaling=None,\n",
    "                                       inp_div_SHFscaling=None,\n",
    "                                       lev=None, interm_size=40,\n",
    "                                       lower_lim=6,is_continous=True,Tnot=5,\n",
    "                                       epsQ=1e-3,epsT=1,mode='train')\n",
    "\n",
    "test_diffgeog_gen_I = DataGeneratorCI(data_fn = path+TESTFILE_DIFFGEOG,\n",
    "                                       input_vars=in_vars,\n",
    "                                       output_vars=out_vars,\n",
    "                                       norm_fn=path+NORMFILE,\n",
    "                                       input_transform=('mean', 'maxrs'),\n",
    "                                       output_transform=scale_dict,\n",
    "                                       batch_size=8192,\n",
    "                                       shuffle=True,\n",
    "                                       xarray=False,\n",
    "                                       var_cut_off=None, \n",
    "                                       Qscaling='RH',\n",
    "                                       Tscaling=Tscaling_name,\n",
    "                                       LHFscaling='LHF_nsDELQ',\n",
    "                                       SHFscaling=None,\n",
    "                                       output_scaling=False,\n",
    "                                       interpolate=False,\n",
    "                                       hyam=hyam,hybm=hybm,\n",
    "                                       inp_sub_Qscaling=train_gen_RH.input_transform.sub,\n",
    "                                       inp_div_Qscaling=train_gen_RH.input_transform.div,\n",
    "                                       inp_sub_Tscaling=train_gen_T.input_transform.sub,\n",
    "                                       inp_div_Tscaling=train_gen_T.input_transform.div,\n",
    "                                       inp_sub_LHFscaling=train_gen_LHF_nsDELQ.input_transform.sub,\n",
    "                                       inp_div_LHFscaling=train_gen_LHF_nsDELQ.input_transform.div,\n",
    "                                       inp_sub_SHFscaling=None,\n",
    "                                       inp_div_SHFscaling=None,\n",
    "                                       lev=None, interm_size=40,\n",
    "                                       lower_lim=6,is_continous=True,Tnot=5,\n",
    "                                       epsQ=1e-3,epsT=1,mode='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input and output rescaled (T=BCONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_vars = ['QBP','TBP','PS', 'SOLIN', 'SHFLX', 'LHFLX']\n",
    "out_vars=['PHQPERC','TPHYSTNDPERC','QRLPERC','QRSPERC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINFILE = '2021_01_24_O3_TRAIN_shuffle.nc'\n",
    "NORMFILE = '2021_01_24_NORM_O3_small.nc'\n",
    "# VALIDFILE = '2021_01_24_O3_VALID.nc'\n",
    "# GENTESTFILE = 'CI_SP_P4K_valid.nc'\n",
    "\n",
    "# In percentile space\n",
    "TRAINFILE = '2021_04_09_PERC_TRAIN_M4K_shuffle.nc'\n",
    "VALIDFILE = '2021_04_09_PERC_VALID_M4K.nc'\n",
    "TESTFILE_DIFFCLIMATE = '2021_04_09_PERC_TRAIN_P4K_shuffle.nc'\n",
    "TESTFILE_DIFFGEOG = '2021_04_24_RG_PERC_TRAIN_M4K_shuffle.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tscaling_name = 'BCONS'\n",
    "train_gen_T = train_gen_BCONS\n",
    "\n",
    "train_gen_IO = DataGeneratorCI(data_fn = path+TRAINFILE,\n",
    "                               input_vars=in_vars,\n",
    "                               output_vars=out_vars,\n",
    "                               norm_fn=path+NORMFILE,\n",
    "                               input_transform=('mean', 'maxrs'),\n",
    "                               output_transform=None,\n",
    "                               batch_size=8192,\n",
    "                               shuffle=True,\n",
    "                               xarray=False,\n",
    "                               var_cut_off=None, \n",
    "                               Qscaling='RH',\n",
    "                               Tscaling=Tscaling_name,\n",
    "                               LHFscaling='LHF_nsDELQ',\n",
    "                               SHFscaling=None,\n",
    "                               output_scaling=False,\n",
    "                               interpolate=False,\n",
    "                               hyam=hyam,hybm=hybm,\n",
    "                               inp_sub_Qscaling=train_gen_RH.input_transform.sub,\n",
    "                               inp_div_Qscaling=train_gen_RH.input_transform.div,\n",
    "                               inp_sub_Tscaling=train_gen_T.input_transform.sub,\n",
    "                               inp_div_Tscaling=train_gen_T.input_transform.div,\n",
    "                               inp_sub_LHFscaling=train_gen_LHF_nsDELQ.input_transform.sub,\n",
    "                               inp_div_LHFscaling=train_gen_LHF_nsDELQ.input_transform.div,\n",
    "                               inp_sub_SHFscaling=None,\n",
    "                               inp_div_SHFscaling=None,\n",
    "                               lev=None, interm_size=40,\n",
    "                               lower_lim=6,is_continous=True,Tnot=5,\n",
    "                               epsQ=1e-3,epsT=1,mode='train')\n",
    "\n",
    "test_diffclimate_gen_IO = DataGeneratorCI(data_fn = path+TESTFILE_DIFFCLIMATE,\n",
    "                                       input_vars=in_vars,\n",
    "                                       output_vars=out_vars,\n",
    "                                       norm_fn=path+NORMFILE,\n",
    "                                       input_transform=('mean', 'maxrs'),\n",
    "                                       output_transform=None,\n",
    "                                       batch_size=8192,\n",
    "                                       shuffle=True,\n",
    "                                       xarray=False,\n",
    "                                       var_cut_off=None, \n",
    "                                       Qscaling='RH',\n",
    "                                       Tscaling=Tscaling_name,\n",
    "                                       LHFscaling='LHF_nsDELQ',\n",
    "                                       SHFscaling=None,\n",
    "                                       output_scaling=False,\n",
    "                                       interpolate=False,\n",
    "                                       hyam=hyam,hybm=hybm,\n",
    "                                       inp_sub_Qscaling=train_gen_RH.input_transform.sub,\n",
    "                                       inp_div_Qscaling=train_gen_RH.input_transform.div,\n",
    "                                       inp_sub_Tscaling=train_gen_T.input_transform.sub,\n",
    "                                       inp_div_Tscaling=train_gen_T.input_transform.div,\n",
    "                                       inp_sub_LHFscaling=train_gen_LHF_nsDELQ.input_transform.sub,\n",
    "                                       inp_div_LHFscaling=train_gen_LHF_nsDELQ.input_transform.div,\n",
    "                                       inp_sub_SHFscaling=None,\n",
    "                                       inp_div_SHFscaling=None,\n",
    "                                       lev=None, interm_size=40,\n",
    "                                       lower_lim=6,is_continous=True,Tnot=5,\n",
    "                                       epsQ=1e-3,epsT=1,mode='train')\n",
    "\n",
    "test_diffgeog_gen_IO = DataGeneratorCI(data_fn = path+TESTFILE_DIFFGEOG,\n",
    "                                       input_vars=in_vars,\n",
    "                                       output_vars=out_vars,\n",
    "                                       norm_fn=path+NORMFILE,\n",
    "                                       input_transform=('mean', 'maxrs'),\n",
    "                                       output_transform=None,\n",
    "                                       batch_size=8192,\n",
    "                                       shuffle=True,\n",
    "                                       xarray=False,\n",
    "                                       var_cut_off=None, \n",
    "                                       Qscaling='RH',\n",
    "                                       Tscaling=Tscaling_name,\n",
    "                                       LHFscaling='LHF_nsDELQ',\n",
    "                                       SHFscaling=None,\n",
    "                                       output_scaling=False,\n",
    "                                       interpolate=False,\n",
    "                                       hyam=hyam,hybm=hybm,\n",
    "                                       inp_sub_Qscaling=train_gen_RH.input_transform.sub,\n",
    "                                       inp_div_Qscaling=train_gen_RH.input_transform.div,\n",
    "                                       inp_sub_Tscaling=train_gen_T.input_transform.sub,\n",
    "                                       inp_div_Tscaling=train_gen_T.input_transform.div,\n",
    "                                       inp_sub_LHFscaling=train_gen_LHF_nsDELQ.input_transform.sub,\n",
    "                                       inp_div_LHFscaling=train_gen_LHF_nsDELQ.input_transform.div,\n",
    "                                       inp_sub_SHFscaling=None,\n",
    "                                       inp_div_SHFscaling=None,\n",
    "                                       lev=None, interm_size=40,\n",
    "                                       lower_lim=6,is_continous=True,Tnot=5,\n",
    "                                       epsQ=1e-3,epsT=1,mode='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load models for all three cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_HDF5 = '/DFS-L/DATA/pritchard/tbeucler/SPCAM/HDF5_DATA/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model's path\n",
    "path_BF = ['2021_04_26_MLR.hdf5','2021_04_26_NN.hdf5']\n",
    "path_I = ['2021_04_26_MLR_RH_BCONS_LHF_nsDELQ.hdf5','2021_04_26_NN_RH_BCONS_LHF_nsDELQ.hdf5']\n",
    "path_IO = ['2021_04_26_LOGI_PERC_RH_BCONS_LHF_nsDELQ.hdf5','2021_04_26_NN_PERC_RH_BCONS_LHF_nsDELQ.hdf5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = load_model(path_HDF5+path_BF[1],compile=False)\n",
    "NN_I = load_model(path_HDF5+path_I[1],compile=False)\n",
    "NN_IO = load_model(path_HDF5+path_IO[1],compile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Develop functions to go between physical and quantile space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2021_03_18_O3_TRAIN_M4K_shuffle.nc': {'quantile_array': array([0.   , 0.001, 0.002, ..., 0.998, 0.999, 1.   ]),\n",
       "  'PERC_array': array([[9.05374009e-07, 8.77815637e-07, 4.98417307e-07, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [9.11630138e-07, 8.91066577e-07, 5.24233712e-07, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [9.13556164e-07, 8.93629931e-07, 5.24234508e-07, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         ...,\n",
       "         [1.81165069e-06, 1.79016258e-06, 1.61611712e-06, ...,\n",
       "          4.71056754e-05, 4.42048546e-05, 8.29813011e-05],\n",
       "         [1.81427470e-06, 1.79245058e-06, 1.62005475e-06, ...,\n",
       "          6.76648574e-05, 7.45083865e-05, 1.28348825e-04],\n",
       "         [1.82074757e-06, 1.80071015e-06, 1.63516086e-06, ...,\n",
       "          5.01840608e-04, 5.79330081e-04, 6.49507623e-04]])},\n",
       " '2021_03_18_O3_TRAIN_P4K_shuffle.nc': {'quantile_array': array([0.   , 0.001, 0.002, ..., 0.998, 0.999, 1.   ]),\n",
       "  'PERC_array': array([[1.37732434e-06, 1.19104163e-06, 4.81186021e-07, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [1.38357811e-06, 1.25212376e-06, 5.24233371e-07, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [1.38551718e-06, 1.26565038e-06, 5.24234849e-07, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         ...,\n",
       "         [1.74623960e-06, 1.71437534e-06, 1.62744289e-06, ...,\n",
       "          4.11302145e-05, 3.78862698e-05, 3.93864722e-05],\n",
       "         [1.74847685e-06, 1.71654372e-06, 1.68633071e-06, ...,\n",
       "          6.17628516e-05, 6.37223272e-05, 1.02323095e-04],\n",
       "         [1.76003380e-06, 1.72247303e-06, 2.10690723e-06, ...,\n",
       "          4.85183118e-04, 5.21734299e-04, 5.82364621e-04]])},\n",
       " '2021_03_18_O3_VALID_M4K.nc': {'quantile_array': array([0.   , 0.001, 0.002, ..., 0.998, 0.999, 1.   ]),\n",
       "  'PERC_array': array([[8.26210623e-07, 8.04561637e-07, 4.81903157e-07, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [8.31319937e-07, 8.15103931e-07, 5.24232917e-07, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [8.33305933e-07, 8.16881993e-07, 5.24233883e-07, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         ...,\n",
       "         [1.76481399e-06, 1.73612364e-06, 1.53431426e-06, ...,\n",
       "          4.85438222e-05, 4.54995752e-05, 7.73097399e-05],\n",
       "         [1.76617682e-06, 1.73883802e-06, 1.53861829e-06, ...,\n",
       "          7.11914718e-05, 7.70977022e-05, 1.22965203e-04],\n",
       "         [1.77085928e-06, 1.74599643e-06, 1.54997974e-06, ...,\n",
       "          4.96026420e-04, 5.62326692e-04, 6.56150107e-04]])},\n",
       " '2021_04_18_RG_TRAIN_M4K_shuffle.nc': {'quantile_array': array([0.   , 0.001, 0.002, ..., 0.998, 0.999, 1.   ]),\n",
       "  'PERC_array': array([[2.29307511e-06, 2.14836632e-06, 3.71099787e-07, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [2.33794958e-06, 2.17511570e-06, 4.54041050e-07, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [2.36237369e-06, 2.18764262e-06, 5.14603588e-07, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         ...,\n",
       "         [3.60132108e-06, 3.63355046e-06, 3.33921980e-06, ...,\n",
       "          9.01951760e-05, 9.56176832e-05, 2.52555235e-04],\n",
       "         [3.75017116e-06, 3.72326219e-06, 3.41413480e-06, ...,\n",
       "          1.26883682e-04, 1.32677649e-04, 3.40629089e-04],\n",
       "         [4.00879617e-06, 3.87324144e-06, 3.62717196e-06, ...,\n",
       "          7.21842807e-04, 8.91044969e-04, 3.82119580e-03]])}}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_m4K = pdf['2021_03_18_O3_TRAIN_M4K_shuffle.nc']\n",
    "pdf_p4K = pdf['2021_03_18_O3_TRAIN_P4K_shuffle.nc']\n",
    "pdf_RG = pdf['2021_04_18_RG_TRAIN_M4K_shuffle.nc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QM as pre-processing: Going back to physical space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN_IO\n",
    "train_gen_m4K = train_gen_IO\n",
    "train_gen_p4K = test_diffclimate_gen_IO\n",
    "\n",
    "model_I = NN_I\n",
    "train_gen_m4K_I = train_gen_I\n",
    "train_gen_p4K_I = test_diffclimate_gen_I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = train_gen_m4K\n",
    "\n",
    "inp = train_gen[ib][0]\n",
    "tru = train_gen[ib][1]\n",
    "prd = model.predict_on_batch(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = train_gen_m4K_I\n",
    "\n",
    "inpI = train_gen[ib][0]\n",
    "truI = train_gen[ib][1]\n",
    "prdI = model_I.predict_on_batch(inpI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valid for aquaplanet only\n",
    "i0 = {}\n",
    "i0['PHQ'] = 94\n",
    "i0['TPHYSTND'] = 124\n",
    "i0['QRL'] = 154\n",
    "i0['QRS'] = 184\n",
    "\n",
    "scale_dict0 = scale_dict['PHQ']\n",
    "scale_dict0 = np.concatenate((scale_dict0,scale_dict['TPHYSTND'],scale_dict['QRL'],scale_dict['QRS']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1001, 214)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_m4K['PERC_array'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1001, 120)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_m4K['PERC_array'][:,i0['PHQ']:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8192, 120)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolating level  0 out of  120\n",
      "Interpolating level  1 out of  120\n",
      "Interpolating level  2 out of  120\n",
      "Interpolating level  3 out of  120\n",
      "Interpolating level  4 out of  120\n",
      "Interpolating level  5 out of  120\n",
      "Interpolating level  6 out of  120\n",
      "Interpolating level  7 out of  120\n",
      "Interpolating level  8 out of  120\n",
      "Interpolating level  9 out of  120\n",
      "Interpolating level  10 out of  120\n",
      "Interpolating level  11 out of  120\n",
      "Interpolating level  12 out of  120\n",
      "Interpolating level  13 out of  120\n",
      "Interpolating level  14 out of  120\n",
      "Interpolating level  15 out of  120\n",
      "Interpolating level  16 out of  120\n",
      "Interpolating level  17 out of  120\n",
      "Interpolating level  18 out of  120\n",
      "Interpolating level  19 out of  120\n",
      "Interpolating level  20 out of  120\n",
      "Interpolating level  21 out of  120\n",
      "Interpolating level  22 out of  120\n",
      "Interpolating level  23 out of  120\n",
      "Interpolating level  24 out of  120\n",
      "Interpolating level  25 out of  120\n",
      "Interpolating level  26 out of  120\n",
      "Interpolating level  27 out of  120\n",
      "Interpolating level  28 out of  120\n",
      "Interpolating level  29 out of  120\n",
      "Interpolating level  30 out of  120\n",
      "Interpolating level  31 out of  120\n",
      "Interpolating level  32 out of  120\n",
      "Interpolating level  33 out of  120\n",
      "Interpolating level  34 out of  120\n",
      "Interpolating level  35 out of  120\n",
      "Interpolating level  36 out of  120\n",
      "Interpolating level  37 out of  120\n",
      "Interpolating level  38 out of  120\n",
      "Interpolating level  39 out of  120\n",
      "Interpolating level  40 out of  120\n",
      "Interpolating level  41 out of  120\n",
      "Interpolating level  42 out of  120\n",
      "Interpolating level  43 out of  120\n",
      "Interpolating level  44 out of  120\n",
      "Interpolating level  45 out of  120\n",
      "Interpolating level  46 out of  120\n",
      "Interpolating level  47 out of  120\n",
      "Interpolating level  48 out of  120\n",
      "Interpolating level  49 out of  120\n",
      "Interpolating level  50 out of  120\n",
      "Interpolating level  51 out of  120\n",
      "Interpolating level  52 out of  120\n",
      "Interpolating level  53 out of  120\n",
      "Interpolating level  54 out of  120\n",
      "Interpolating level  55 out of  120\n",
      "Interpolating level  56 out of  120\n",
      "Interpolating level  57 out of  120\n",
      "Interpolating level  58 out of  120\n",
      "Interpolating level  59 out of  120\n",
      "Interpolating level  60 out of  120\n",
      "Interpolating level  61 out of  120\n",
      "Interpolating level  62 out of  120\n",
      "Interpolating level  63 out of  120\n",
      "Interpolating level  64 out of  120\n",
      "Interpolating level  65 out of  120\n",
      "Interpolating level  66 out of  120\n",
      "Interpolating level  67 out of  120\n",
      "Interpolating level  68 out of  120\n",
      "Interpolating level  69 out of  120\n",
      "Interpolating level  70 out of  120\n",
      "Interpolating level  71 out of  120\n",
      "Interpolating level  72 out of  120\n",
      "Interpolating level  73 out of  120\n",
      "Interpolating level  74 out of  120\n",
      "Interpolating level  75 out of  120\n",
      "Interpolating level  76 out of  120\n",
      "Interpolating level  77 out of  120\n",
      "Interpolating level  78 out of  120\n",
      "Interpolating level  79 out of  120\n",
      "Interpolating level  80 out of  120\n",
      "Interpolating level  81 out of  120\n",
      "Interpolating level  82 out of  120\n",
      "Interpolating level  83 out of  120\n",
      "Interpolating level  84 out of  120\n",
      "Interpolating level  85 out of  120\n",
      "Interpolating level  86 out of  120\n",
      "Interpolating level  87 out of  120\n",
      "Interpolating level  88 out of  120\n",
      "Interpolating level  89 out of  120\n",
      "Interpolating level  90 out of  120\n",
      "Interpolating level  91 out of  120\n",
      "Interpolating level  92 out of  120\n",
      "Interpolating level  93 out of  120\n",
      "Interpolating level  94 out of  120\n",
      "Interpolating level  95 out of  120\n",
      "Interpolating level  96 out of  120\n",
      "Interpolating level  97 out of  120\n",
      "Interpolating level  98 out of  120\n",
      "Interpolating level  99 out of  120\n",
      "Interpolating level  100 out of  120\n",
      "Interpolating level  101 out of  120\n",
      "Interpolating level  102 out of  120\n",
      "Interpolating level  103 out of  120\n",
      "Interpolating level  104 out of  120\n",
      "Interpolating level  105 out of  120\n",
      "Interpolating level  106 out of  120\n",
      "Interpolating level  107 out of  120\n",
      "Interpolating level  108 out of  120\n",
      "Interpolating level  109 out of  120\n",
      "Interpolating level  110 out of  120\n",
      "Interpolating level  111 out of  120\n",
      "Interpolating level  112 out of  120\n",
      "Interpolating level  113 out of  120\n",
      "Interpolating level  114 out of  120\n",
      "Interpolating level  115 out of  120\n",
      "Interpolating level  116 out of  120\n",
      "Interpolating level  117 out of  120\n",
      "Interpolating level  118 out of  120\n",
      "Interpolating level  119 out of  120\n"
     ]
    }
   ],
   "source": [
    "# Project onto 1D percentile space to form the output\n",
    "tru_physical = np.zeros(prd.shape) # Initialization\n",
    "prd_physical = np.zeros(prd.shape)\n",
    "for ilev in range(prd.shape[1]):\n",
    "    print('Interpolating level ',ilev,'out of ',prd.shape[1])\n",
    "    interp_fx = interp1d(x=quantile_array,y=pdf_m4K['PERC_array'][:,i0['PHQ']+ilev],bounds_error=False)\n",
    "    tru_physical[:,ilev] = interp_fx(tru[:,ilev])\n",
    "    prd_physical[:,ilev] = interp_fx(prd[:,ilev])\n",
    "tru_physical *= scale_dict0\n",
    "prd_physical *= scale_dict0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170.12730761628038"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((prdI-truI)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1003.6718589436348"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((prd_physical-tru_physical)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1003.6718589687545"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((prd_physical-truI)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.510537095311309e-08"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((tru_physical-truI)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolating level  119 out of  120        \r"
     ]
    }
   ],
   "source": [
    "tru_physical = quantile_to_physical(tru,pdf_m4K['PERC_array'][:,i0['PHQ']:],quantile_array,scale_dict0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QM as post-processing: Going to percentile space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolating level  0 out of  120\n",
      "Interpolating level  1 out of  120\n",
      "Interpolating level  2 out of  120\n",
      "Interpolating level  3 out of  120\n",
      "Interpolating level  4 out of  120\n",
      "Interpolating level  5 out of  120\n",
      "Interpolating level  6 out of  120\n",
      "Interpolating level  7 out of  120\n",
      "Interpolating level  8 out of  120\n",
      "Interpolating level  9 out of  120\n",
      "Interpolating level  10 out of  120\n",
      "Interpolating level  11 out of  120\n",
      "Interpolating level  12 out of  120\n",
      "Interpolating level  13 out of  120\n",
      "Interpolating level  14 out of  120\n",
      "Interpolating level  15 out of  120\n",
      "Interpolating level  16 out of  120\n",
      "Interpolating level  17 out of  120\n",
      "Interpolating level  18 out of  120\n",
      "Interpolating level  19 out of  120\n",
      "Interpolating level  20 out of  120\n",
      "Interpolating level  21 out of  120\n",
      "Interpolating level  22 out of  120\n",
      "Interpolating level  23 out of  120\n",
      "Interpolating level  24 out of  120\n",
      "Interpolating level  25 out of  120\n",
      "Interpolating level  26 out of  120\n",
      "Interpolating level  27 out of  120\n",
      "Interpolating level  28 out of  120\n",
      "Interpolating level  29 out of  120\n",
      "Interpolating level  30 out of  120\n",
      "Interpolating level  31 out of  120\n",
      "Interpolating level  32 out of  120\n",
      "Interpolating level  33 out of  120\n",
      "Interpolating level  34 out of  120\n",
      "Interpolating level  35 out of  120\n",
      "Interpolating level  36 out of  120\n",
      "Interpolating level  37 out of  120\n",
      "Interpolating level  38 out of  120\n",
      "Interpolating level  39 out of  120\n",
      "Interpolating level  40 out of  120\n",
      "Interpolating level  41 out of  120\n",
      "Interpolating level  42 out of  120\n",
      "Interpolating level  43 out of  120\n",
      "Interpolating level  44 out of  120\n",
      "Interpolating level  45 out of  120\n",
      "Interpolating level  46 out of  120\n",
      "Interpolating level  47 out of  120\n",
      "Interpolating level  48 out of  120\n",
      "Interpolating level  49 out of  120\n",
      "Interpolating level  50 out of  120\n",
      "Interpolating level  51 out of  120\n",
      "Interpolating level  52 out of  120\n",
      "Interpolating level  53 out of  120\n",
      "Interpolating level  54 out of  120\n",
      "Interpolating level  55 out of  120\n",
      "Interpolating level  56 out of  120\n",
      "Interpolating level  57 out of  120\n",
      "Interpolating level  58 out of  120\n",
      "Interpolating level  59 out of  120\n",
      "Interpolating level  60 out of  120\n",
      "Interpolating level  61 out of  120\n",
      "Interpolating level  62 out of  120\n",
      "Interpolating level  63 out of  120\n",
      "Interpolating level  64 out of  120\n",
      "Interpolating level  65 out of  120\n",
      "Interpolating level  66 out of  120\n",
      "Interpolating level  67 out of  120\n",
      "Interpolating level  68 out of  120\n",
      "Interpolating level  69 out of  120\n",
      "Interpolating level  70 out of  120\n",
      "Interpolating level  71 out of  120\n",
      "Interpolating level  72 out of  120\n",
      "Interpolating level  73 out of  120\n",
      "Interpolating level  74 out of  120\n",
      "Interpolating level  75 out of  120\n",
      "Interpolating level  76 out of  120\n",
      "Interpolating level  77 out of  120\n",
      "Interpolating level  78 out of  120\n",
      "Interpolating level  79 out of  120\n",
      "Interpolating level  80 out of  120\n",
      "Interpolating level  81 out of  120\n",
      "Interpolating level  82 out of  120\n",
      "Interpolating level  83 out of  120\n",
      "Interpolating level  84 out of  120\n",
      "Interpolating level  85 out of  120\n",
      "Interpolating level  86 out of  120\n",
      "Interpolating level  87 out of  120\n",
      "Interpolating level  88 out of  120\n",
      "Interpolating level  89 out of  120\n",
      "Interpolating level  90 out of  120\n",
      "Interpolating level  91 out of  120\n",
      "Interpolating level  92 out of  120\n",
      "Interpolating level  93 out of  120\n",
      "Interpolating level  94 out of  120\n",
      "Interpolating level  95 out of  120\n",
      "Interpolating level  96 out of  120\n",
      "Interpolating level  97 out of  120\n",
      "Interpolating level  98 out of  120\n",
      "Interpolating level  99 out of  120\n",
      "Interpolating level  100 out of  120\n",
      "Interpolating level  101 out of  120\n",
      "Interpolating level  102 out of  120\n",
      "Interpolating level  103 out of  120\n",
      "Interpolating level  104 out of  120\n",
      "Interpolating level  105 out of  120\n",
      "Interpolating level  106 out of  120\n",
      "Interpolating level  107 out of  120\n",
      "Interpolating level  108 out of  120\n",
      "Interpolating level  109 out of  120\n",
      "Interpolating level  110 out of  120\n",
      "Interpolating level  111 out of  120\n",
      "Interpolating level  112 out of  120\n",
      "Interpolating level  113 out of  120\n",
      "Interpolating level  114 out of  120\n",
      "Interpolating level  115 out of  120\n",
      "Interpolating level  116 out of  120\n",
      "Interpolating level  117 out of  120\n",
      "Interpolating level  118 out of  120\n",
      "Interpolating level  119 out of  120\n"
     ]
    }
   ],
   "source": [
    "# Project onto 1D percentile space to form the output\n",
    "truI_quantile = np.zeros(prd.shape) # Initialization\n",
    "prdI_quantile = np.zeros(prd.shape)\n",
    "for ilev in range(prd.shape[1]):\n",
    "    print('Interpolating level ',ilev,'out of ',prd.shape[1])\n",
    "    interp_fx = interp1d(x=pdf_m4K['PERC_array'][:,i0['PHQ']+ilev],y=quantile_array,bounds_error=False,fill_value=(0,1))\n",
    "    truI_quantile[:,ilev] = interp_fx(truI[:,ilev]/scale_dict0[ilev])\n",
    "    prdI_quantile[:,ilev] = interp_fx(prdI[:,ilev]/scale_dict0[ilev])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((tru-truI_quantile)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.025491540315767947"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((tru-prd)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0757695836803891"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((truI_quantile-prdI_quantile)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolating level  119 out of  120        \r"
     ]
    }
   ],
   "source": [
    "truI_quantile = physical_to_quantile(truI,pdf_m4K['PERC_array'][:,i0['PHQ']:],quantile_array,scale_dict0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make functions to go back and forth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def physical_to_quantile(output_physical,pdf_output,quantile_array,scaling_output):\n",
    "    output_quantile = np.zeros(output_physical.shape)\n",
    "    for ilev in range(prd.shape[1]):\n",
    "        print('Interpolating level ',ilev,'out of ',output_physical.shape[1],'       ',end='\\r')\n",
    "        interp_fx = interp1d(x=pdf_output[:,ilev],y=quantile_array,bounds_error=False,fill_value=(0,1))\n",
    "        output_quantile[:,ilev] = interp_fx(output_physical[:,ilev]/scaling_output[ilev])\n",
    "    return output_quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_to_physical(output_quantile,pdf_output,quantile_array,scaling_output):\n",
    "    output_physical = np.zeros(output_quantile.shape)\n",
    "    for ilev in range(output_quantile.shape[1]):\n",
    "        print('Interpolating level ',ilev,'out of ',output_physical.shape[1],'       ',end='\\r')\n",
    "        interp_fx = interp1d(x=quantile_array,y=pdf_output[:,ilev],bounds_error=False)\n",
    "        output_physical[:,ilev] = interp_fx(output_quantile[:,ilev])\n",
    "    output_physical *= scaling_output\n",
    "    return output_physical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the pre/post-QM on the generalization set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 5 predictions in physical space and 3 in quantile space:     \n",
    "- 1+1) BF, direct prediction in physical/quantile spaces    \n",
    "- 2) BF with QM-post-processing, prediction in physical space    \n",
    "- 3+2) Inputs rescaling only, direct prediction in physical and quantile spaces   \n",
    "- 4) Input rescalings only with QM post-processing in physical space      \n",
    "- 5+3) Input+Output rescalings, in physical and quantile space   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "ib = 450"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1+1) BF, direct prediction in physical and quantile space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = test_diffclimate_gen_BF[ib][0]\n",
    "tru = test_diffclimate_gen_BF[ib][1]\n",
    "prd = NN.predict_on_batch(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2269.139955947895"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((tru-prd)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolating level  119 out of  120        \r"
     ]
    }
   ],
   "source": [
    "prd_quantile = physical_to_quantile(prd,pdf_p4K['PERC_array'][:,i0['PHQ']:],quantile_array,scale_dict0)\n",
    "tru_quantile = physical_to_quantile(tru,pdf_p4K['PERC_array'][:,i0['PHQ']:],quantile_array,scale_dict0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11345305207715686"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((tru_quantile-prd_quantile)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) BF with QM as post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolating level  0 out of  120        \r",
      "Interpolating level  1 out of  120        \r",
      "Interpolating level  2 out of  120        \r",
      "Interpolating level  3 out of  120        \r",
      "Interpolating level  4 out of  120        \r",
      "Interpolating level  5 out of  120        \r",
      "Interpolating level  6 out of  120        \r",
      "Interpolating level  7 out of  120        \r",
      "Interpolating level  8 out of  120        \r",
      "Interpolating level  9 out of  120        \r",
      "Interpolating level  10 out of  120        \r",
      "Interpolating level  11 out of  120        \r",
      "Interpolating level  12 out of  120        \r",
      "Interpolating level  13 out of  120        \r",
      "Interpolating level  14 out of  120        \r",
      "Interpolating level  15 out of  120        \r",
      "Interpolating level  16 out of  120        \r",
      "Interpolating level  17 out of  120        \r",
      "Interpolating level  18 out of  120        \r",
      "Interpolating level  19 out of  120        \r",
      "Interpolating level  20 out of  120        \r",
      "Interpolating level  21 out of  120        \r",
      "Interpolating level  22 out of  120        \r",
      "Interpolating level  23 out of  120        \r",
      "Interpolating level  24 out of  120        \r",
      "Interpolating level  25 out of  120        \r",
      "Interpolating level  26 out of  120        \r",
      "Interpolating level  27 out of  120        \r",
      "Interpolating level  28 out of  120        \r",
      "Interpolating level  29 out of  120        \r",
      "Interpolating level  30 out of  120        \r",
      "Interpolating level  31 out of  120        \r",
      "Interpolating level  32 out of  120        \r",
      "Interpolating level  33 out of  120        \r",
      "Interpolating level  34 out of  120        \r",
      "Interpolating level  35 out of  120        \r",
      "Interpolating level  36 out of  120        \r",
      "Interpolating level  37 out of  120        \r",
      "Interpolating level  38 out of  120        \r",
      "Interpolating level  39 out of  120        \r",
      "Interpolating level  40 out of  120        \r",
      "Interpolating level  41 out of  120        \r",
      "Interpolating level  42 out of  120        \r",
      "Interpolating level  43 out of  120        \r",
      "Interpolating level  44 out of  120        \r",
      "Interpolating level  45 out of  120        \r",
      "Interpolating level  46 out of  120        \r",
      "Interpolating level  47 out of  120        \r",
      "Interpolating level  48 out of  120        \r",
      "Interpolating level  49 out of  120        \r",
      "Interpolating level  50 out of  120        \r",
      "Interpolating level  51 out of  120        \r",
      "Interpolating level  52 out of  120        \r",
      "Interpolating level  53 out of  120        \r",
      "Interpolating level  54 out of  120        \r",
      "Interpolating level  55 out of  120        \r",
      "Interpolating level  56 out of  120        \r",
      "Interpolating level  57 out of  120        \r",
      "Interpolating level  58 out of  120        \r",
      "Interpolating level  59 out of  120        \r",
      "Interpolating level  60 out of  120        \r",
      "Interpolating level  61 out of  120        \r",
      "Interpolating level  62 out of  120        \r",
      "Interpolating level  63 out of  120        \r",
      "Interpolating level  64 out of  120        \r",
      "Interpolating level  65 out of  120        \r",
      "Interpolating level  66 out of  120        \r",
      "Interpolating level  67 out of  120        \r",
      "Interpolating level  68 out of  120        \r",
      "Interpolating level  69 out of  120        \r",
      "Interpolating level  70 out of  120        \r",
      "Interpolating level  71 out of  120        \r",
      "Interpolating level  72 out of  120        \r",
      "Interpolating level  73 out of  120        \r",
      "Interpolating level  74 out of  120        \r",
      "Interpolating level  75 out of  120        \r",
      "Interpolating level  76 out of  120        \r",
      "Interpolating level  77 out of  120        \r",
      "Interpolating level  78 out of  120        \r",
      "Interpolating level  79 out of  120        \r",
      "Interpolating level  80 out of  120        \r",
      "Interpolating level  81 out of  120        \r",
      "Interpolating level  82 out of  120        \r",
      "Interpolating level  83 out of  120        \r",
      "Interpolating level  84 out of  120        \r",
      "Interpolating level  85 out of  120        \r",
      "Interpolating level  86 out of  120        \r",
      "Interpolating level  87 out of  120        \r",
      "Interpolating level  88 out of  120        \r",
      "Interpolating level  89 out of  120        \r",
      "Interpolating level  90 out of  120        \r",
      "Interpolating level  91 out of  120        \r",
      "Interpolating level  92 out of  120        \r",
      "Interpolating level  93 out of  120        \r",
      "Interpolating level  94 out of  120        \r",
      "Interpolating level  95 out of  120        \r",
      "Interpolating level  96 out of  120        \r",
      "Interpolating level  97 out of  120        \r",
      "Interpolating level  98 out of  120        \r",
      "Interpolating level  99 out of  120        \r",
      "Interpolating level  100 out of  120        \r",
      "Interpolating level  101 out of  120        \r",
      "Interpolating level  102 out of  120        \r",
      "Interpolating level  103 out of  120        \r",
      "Interpolating level  104 out of  120        \r",
      "Interpolating level  105 out of  120        \r",
      "Interpolating level  106 out of  120        \r",
      "Interpolating level  107 out of  120        \r",
      "Interpolating level  108 out of  120        \r",
      "Interpolating level  109 out of  120        \r",
      "Interpolating level  110 out of  120        \r",
      "Interpolating level  111 out of  120        \r",
      "Interpolating level  112 out of  120        \r",
      "Interpolating level  113 out of  120        \r",
      "Interpolating level  114 out of  120        \r",
      "Interpolating level  115 out of  120        \r",
      "Interpolating level  116 out of  120        \r",
      "Interpolating level  117 out of  120        \r",
      "Interpolating level  118 out of  120        \r",
      "Interpolating level  119 out of  120        \r"
     ]
    }
   ],
   "source": [
    "prd_quantile_m4K = physical_to_quantile(prd,pdf_m4K['PERC_array'][:,i0['PHQ']:],quantile_array,scale_dict0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolating level  0 out of  120        \r",
      "Interpolating level  1 out of  120        \r",
      "Interpolating level  2 out of  120        \r",
      "Interpolating level  3 out of  120        \r",
      "Interpolating level  4 out of  120        \r",
      "Interpolating level  5 out of  120        \r",
      "Interpolating level  6 out of  120        \r",
      "Interpolating level  7 out of  120        \r",
      "Interpolating level  8 out of  120        \r",
      "Interpolating level  9 out of  120        \r",
      "Interpolating level  10 out of  120        \r",
      "Interpolating level  11 out of  120        \r",
      "Interpolating level  12 out of  120        \r",
      "Interpolating level  13 out of  120        \r",
      "Interpolating level  14 out of  120        \r",
      "Interpolating level  15 out of  120        \r",
      "Interpolating level  16 out of  120        \r",
      "Interpolating level  17 out of  120        \r",
      "Interpolating level  18 out of  120        \r",
      "Interpolating level  19 out of  120        \r",
      "Interpolating level  20 out of  120        \r",
      "Interpolating level  21 out of  120        \r",
      "Interpolating level  22 out of  120        \r",
      "Interpolating level  23 out of  120        \r",
      "Interpolating level  24 out of  120        \r",
      "Interpolating level  25 out of  120        \r",
      "Interpolating level  26 out of  120        \r",
      "Interpolating level  27 out of  120        \r",
      "Interpolating level  28 out of  120        \r",
      "Interpolating level  29 out of  120        \r",
      "Interpolating level  30 out of  120        \r",
      "Interpolating level  31 out of  120        \r",
      "Interpolating level  32 out of  120        \r",
      "Interpolating level  33 out of  120        \r",
      "Interpolating level  34 out of  120        \r",
      "Interpolating level  35 out of  120        \r",
      "Interpolating level  36 out of  120        \r",
      "Interpolating level  37 out of  120        \r",
      "Interpolating level  38 out of  120        \r",
      "Interpolating level  39 out of  120        \r",
      "Interpolating level  40 out of  120        \r",
      "Interpolating level  41 out of  120        \r",
      "Interpolating level  42 out of  120        \r",
      "Interpolating level  43 out of  120        \r",
      "Interpolating level  44 out of  120        \r",
      "Interpolating level  45 out of  120        \r",
      "Interpolating level  46 out of  120        \r",
      "Interpolating level  47 out of  120        \r",
      "Interpolating level  48 out of  120        \r",
      "Interpolating level  49 out of  120        \r",
      "Interpolating level  50 out of  120        \r",
      "Interpolating level  51 out of  120        \r",
      "Interpolating level  52 out of  120        \r",
      "Interpolating level  53 out of  120        \r",
      "Interpolating level  54 out of  120        \r",
      "Interpolating level  55 out of  120        \r",
      "Interpolating level  56 out of  120        \r",
      "Interpolating level  57 out of  120        \r",
      "Interpolating level  58 out of  120        \r",
      "Interpolating level  59 out of  120        \r",
      "Interpolating level  60 out of  120        \r",
      "Interpolating level  61 out of  120        \r",
      "Interpolating level  62 out of  120        \r",
      "Interpolating level  63 out of  120        \r",
      "Interpolating level  64 out of  120        \r",
      "Interpolating level  65 out of  120        \r",
      "Interpolating level  66 out of  120        \r",
      "Interpolating level  67 out of  120        \r",
      "Interpolating level  68 out of  120        \r",
      "Interpolating level  69 out of  120        \r",
      "Interpolating level  70 out of  120        \r",
      "Interpolating level  71 out of  120        \r",
      "Interpolating level  72 out of  120        \r",
      "Interpolating level  73 out of  120        \r",
      "Interpolating level  74 out of  120        \r",
      "Interpolating level  75 out of  120        \r",
      "Interpolating level  76 out of  120        \r",
      "Interpolating level  77 out of  120        \r",
      "Interpolating level  78 out of  120        \r",
      "Interpolating level  79 out of  120        \r",
      "Interpolating level  80 out of  120        \r",
      "Interpolating level  81 out of  120        \r",
      "Interpolating level  82 out of  120        \r",
      "Interpolating level  83 out of  120        \r",
      "Interpolating level  84 out of  120        \r",
      "Interpolating level  85 out of  120        \r",
      "Interpolating level  86 out of  120        \r",
      "Interpolating level  87 out of  120        \r",
      "Interpolating level  88 out of  120        \r",
      "Interpolating level  89 out of  120        \r",
      "Interpolating level  90 out of  120        \r",
      "Interpolating level  91 out of  120        \r",
      "Interpolating level  92 out of  120        \r",
      "Interpolating level  93 out of  120        \r",
      "Interpolating level  94 out of  120        \r",
      "Interpolating level  95 out of  120        \r",
      "Interpolating level  96 out of  120        \r",
      "Interpolating level  97 out of  120        \r",
      "Interpolating level  98 out of  120        \r",
      "Interpolating level  99 out of  120        \r",
      "Interpolating level  100 out of  120        \r",
      "Interpolating level  101 out of  120        \r",
      "Interpolating level  102 out of  120        \r",
      "Interpolating level  103 out of  120        \r",
      "Interpolating level  104 out of  120        \r",
      "Interpolating level  105 out of  120        \r",
      "Interpolating level  106 out of  120        \r",
      "Interpolating level  107 out of  120        \r",
      "Interpolating level  108 out of  120        \r",
      "Interpolating level  109 out of  120        \r",
      "Interpolating level  110 out of  120        \r",
      "Interpolating level  111 out of  120        \r",
      "Interpolating level  112 out of  120        \r",
      "Interpolating level  113 out of  120        \r",
      "Interpolating level  114 out of  120        \r",
      "Interpolating level  115 out of  120        \r",
      "Interpolating level  116 out of  120        \r",
      "Interpolating level  117 out of  120        \r",
      "Interpolating level  118 out of  120        \r",
      "Interpolating level  119 out of  120        \r"
     ]
    }
   ],
   "source": [
    "prd_QM = quantile_to_physical(prd_quantile_m4K,pdf_p4K['PERC_array'][:,i0['PHQ']:],quantile_array,scale_dict0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6999.374964910534"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((tru-prd_QM)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3+2) Input rescaling, direct prediction in physical and quantile space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpI = test_diffclimate_gen_I[ib][0]\n",
    "truI = test_diffclimate_gen_I[ib][1]\n",
    "prdI = NN_I.predict_on_batch(inpI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "581.3297725177895"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((truI-prdI)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolating level  119 out of  120        out of  120        \r"
     ]
    }
   ],
   "source": [
    "prdI_quantile = physical_to_quantile(prdI,pdf_p4K['PERC_array'][:,i0['PHQ']:],quantile_array,scale_dict0)\n",
    "truI_quantile = physical_to_quantile(truI,pdf_p4K['PERC_array'][:,i0['PHQ']:],quantile_array,scale_dict0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07917119206492841"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((truI_quantile-prdI_quantile)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Input rescaling with QM as post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolating level  119 out of  120        \r"
     ]
    }
   ],
   "source": [
    "prdI_quantile_m4K = physical_to_quantile(prdI,pdf_m4K['PERC_array'][:,i0['PHQ']:],quantile_array,scale_dict0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolating level  119 out of  120        \r"
     ]
    }
   ],
   "source": [
    "prdI_QM = quantile_to_physical(prdI_quantile_m4K,pdf_p4K['PERC_array'][:,i0['PHQ']:],quantile_array,scale_dict0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "546.9603251451517"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((truI-prdI_QM)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5+3) Input + output rescaling in physical and quantile space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpIO = test_diffclimate_gen_IO[ib][0]\n",
    "truIO = test_diffclimate_gen_IO[ib][1]\n",
    "prdIO = NN_IO.predict_on_batch(inpIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04083318682668868"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((truIO-prdIO)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolating level  119 out of  120         out of  120        \r"
     ]
    }
   ],
   "source": [
    "prdIO_physical = quantile_to_physical(prdIO,pdf_p4K['PERC_array'][:,i0['PHQ']:],quantile_array,scale_dict0)\n",
    "truIO_physical = quantile_to_physical(truIO,pdf_p4K['PERC_array'][:,i0['PHQ']:],quantile_array,scale_dict0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1987.2422070075286"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((prdIO_physical-truIO_physical)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directly compare NN with and without output rescaling in cold and warm climate to understand how it influences performance & generalization abilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nbatches = 5\n",
    "b_random = np.random.choice(np.linspace(0,5700,5701),size=((Nbatches,)),replace=False).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE = {}\n",
    "INP = {}\n",
    "VAR = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idataset= 0  & dataset= AQ-4K\n",
      "itype= 0  & modeltype= I\n",
      "itype= 1  & modeltype= IO\n",
      "idataset= 1  & dataset= AQ+4K\n",
      "itype= 0  & modeltype= I\n",
      "itype= 1  & modeltype= IO\n",
      "idataset= 2  & dataset= RG\n",
      "itype= 0  & modeltype= I\n",
      "itype= 1  & modeltype= IO\n",
      "ibatch= 4 / 4  & ib 1056\r"
     ]
    }
   ],
   "source": [
    "for idataset,dataset in enumerate(['AQ-4K','AQ+4K','RG']):\n",
    "    print('idataset=',idataset,' & dataset=',dataset)\n",
    "    MSE[dataset] = {}; INP[dataset] = {}; VAR[dataset] = {};\n",
    "    \n",
    "    for itype,modeltype in enumerate(['I','IO']):\n",
    "        print ('itype=',itype,' & modeltype=',modeltype)\n",
    "            \n",
    "        if modeltype=='I':\n",
    "            model = NN_I\n",
    "            if dataset=='AQ-4K': train_gen = train_gen_I\n",
    "            elif dataset=='AQ+4K': train_gen = test_diffclimate_gen_I\n",
    "            elif dataset=='RG': train_gen = test_diffgeog_gen_I\n",
    "        elif modeltype=='IO':\n",
    "            model = NN_IO\n",
    "            if dataset=='AQ-4K': train_gen = train_gen_IO\n",
    "            elif dataset=='AQ+4K': train_gen = test_diffclimate_gen_IO\n",
    "            elif dataset=='RG': train_gen = test_diffgeog_gen_IO\n",
    "            \n",
    "        for ibatch,ib in enumerate(b_random):\n",
    "            print('ibatch=',ibatch,'/',Nbatches-1,' & ib',ib,end=\"\\r\")\n",
    "\n",
    "            inp = train_gen[ib][0]\n",
    "            tru = train_gen[ib][1]\n",
    "            prd = model.predict_on_batch(inp)\n",
    "\n",
    "            inp_geo = np.reshape(inp,(64,128,inp.shape[1],1))\n",
    "            prd_geo = np.reshape(prd,(64,128,prd.shape[1]))\n",
    "            tru_geo = np.reshape(tru,(64,128,tru.shape[1]))\n",
    "\n",
    "            mse = np.expand_dims(np.mean((tru_geo-prd_geo)**2,axis=2),axis=2)\n",
    "            var = np.expand_dims(np.var(prd_geo,axis=2),axis=2)\n",
    "\n",
    "            if ibatch==0:\n",
    "                MSE[dataset][modeltype] = mse; \n",
    "                VAR[dataset][modeltype] = var; \n",
    "                INP[dataset][modeltype] = inp_geo;\n",
    "            else:\n",
    "                MSE[dataset][modeltype] = np.concatenate((MSE[dataset][modeltype],mse),axis=2)\n",
    "                VAR[dataset][modeltype] = np.concatenate((VAR[dataset][modeltype],var),axis=2)\n",
    "                INP[dataset][modeltype] = np.concatenate((INP[dataset][modeltype],inp_geo),axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Legacy code with geographical reformatting) Directly compare NN with and without output rescaling in cold and warm climate to understand how it influences performance & generalization abilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nbatches = 5\n",
    "b_random = np.random.choice(np.linspace(0,5700,5701),size=((Nbatches,)),replace=False).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE = {}\n",
    "INP = {}\n",
    "VAR = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idataset= 0  & dataset= AQ-4K\n",
      "itype= 0  & modeltype= I\n",
      "itype= 1  & modeltype= IO\n",
      "idataset= 1  & dataset= AQ+4K\n",
      "itype= 0  & modeltype= I\n",
      "itype= 1  & modeltype= IO\n",
      "idataset= 2  & dataset= RG\n",
      "itype= 0  & modeltype= I\n",
      "itype= 1  & modeltype= IO\n",
      "ibatch= 4 / 4  & ib 1056\r"
     ]
    }
   ],
   "source": [
    "for idataset,dataset in enumerate(['AQ-4K','AQ+4K','RG']):\n",
    "    print('idataset=',idataset,' & dataset=',dataset)\n",
    "    MSE[dataset] = {}; INP[dataset] = {}; VAR[dataset] = {};\n",
    "    \n",
    "    for itype,modeltype in enumerate(['I','IO']):\n",
    "        print ('itype=',itype,' & modeltype=',modeltype)\n",
    "            \n",
    "        if modeltype=='I':\n",
    "            model = NN_I\n",
    "            if dataset=='AQ-4K': train_gen = train_gen_I\n",
    "            elif dataset=='AQ+4K': train_gen = test_diffclimate_gen_I\n",
    "            elif dataset=='RG': train_gen = test_diffgeog_gen_I\n",
    "        elif modeltype=='IO':\n",
    "            model = NN_IO\n",
    "            if dataset=='AQ-4K': train_gen = train_gen_IO\n",
    "            elif dataset=='AQ+4K': train_gen = test_diffclimate_gen_IO\n",
    "            elif dataset=='RG': train_gen = test_diffgeog_gen_IO\n",
    "            \n",
    "        for ibatch,ib in enumerate(b_random):\n",
    "            print('ibatch=',ibatch,'/',Nbatches-1,' & ib',ib,end=\"\\r\")\n",
    "\n",
    "            inp = train_gen[ib][0]\n",
    "            tru = train_gen[ib][1]\n",
    "            prd = model.predict_on_batch(inp)\n",
    "\n",
    "            inp_geo = np.reshape(inp,(64,128,inp.shape[1],1))\n",
    "            prd_geo = np.reshape(prd,(64,128,prd.shape[1]))\n",
    "            tru_geo = np.reshape(tru,(64,128,tru.shape[1]))\n",
    "\n",
    "            mse = np.expand_dims(np.mean((tru_geo-prd_geo)**2,axis=2),axis=2)\n",
    "            var = np.expand_dims(np.var(prd_geo,axis=2),axis=2)\n",
    "\n",
    "            if ibatch==0:\n",
    "                MSE[dataset][modeltype] = mse; \n",
    "                VAR[dataset][modeltype] = var; \n",
    "                INP[dataset][modeltype] = inp_geo;\n",
    "            else:\n",
    "                MSE[dataset][modeltype] = np.concatenate((MSE[dataset][modeltype],mse),axis=2)\n",
    "                VAR[dataset][modeltype] = np.concatenate((VAR[dataset][modeltype],var),axis=2)\n",
    "                INP[dataset][modeltype] = np.concatenate((INP[dataset][modeltype],inp_geo),axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idataset= 0  & dataset= AQ-4K\n",
      "itype= 0  & modeltype= I\n",
      "MSE: mean= 170.46862526489673 , std= 559.1165491759274\n",
      "itype= 1  & modeltype= IO\n",
      "MSE: mean= 0.025232193508585344 , std= 0.01627114225383874\n",
      "idataset= 1  & dataset= AQ+4K\n",
      "itype= 0  & modeltype= I\n",
      "MSE: mean= 590.060785432884 , std= 2517.239156670746\n",
      "itype= 1  & modeltype= IO\n",
      "MSE: mean= 0.041000803417202546 , std= 0.02512555606239193\n",
      "idataset= 2  & dataset= RG\n",
      "itype= 0  & modeltype= I\n",
      "MSE: mean= 245.88371 , std= 988.55634\n",
      "itype= 1  & modeltype= IO\n",
      "MSE: mean= 0.07444334 , std= 0.03211816\n"
     ]
    }
   ],
   "source": [
    "for idataset,dataset in enumerate(['AQ-4K','AQ+4K','RG']):\n",
    "    print('idataset=',idataset,' & dataset=',dataset)\n",
    "    \n",
    "    for itype,modeltype in enumerate(['I','IO']):\n",
    "        print ('itype=',itype,' & modeltype=',modeltype)\n",
    "        \n",
    "        print('MSE: mean=',np.mean(MSE[dataset][modeltype],axis=(0,1,2)),\n",
    "              ', std=',np.std(MSE[dataset][modeltype],axis=(0,1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "341.333px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
