{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tgb - 5/3/2021 - Load climate-invariant versions of models with and without output rescaling and see which one performs best in terms of MSE in the different climate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "- Load models with or without output rescaling  \n",
    "- Code np and tf layers to interpolate back and forth from/to quantile space  \n",
    "- Evaluate MSE for pre vs post processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfspool-0/home/tbeucler/CBRAIN-CAM/notebooks/tbeucler_devlog\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(1,\"/home1/07064/tg863631/anaconda3/envs/CbrainCustomLayer/lib/python3.6/site-packages\") #work around for h5py\n",
    "from cbrain.imports import *\n",
    "from cbrain.cam_constants import *\n",
    "from cbrain.utils import *\n",
    "from cbrain.layers import *\n",
    "from cbrain.data_generator import DataGenerator\n",
    "from cbrain.climate_invariant import *\n",
    "\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "tf.config.experimental.set_memory_growth(physical_devices[1], True)\n",
    "tf.config.experimental.set_memory_growth(physical_devices[2], True)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "\n",
    "from tensorflow import math as tfm\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "import tensorflow_probability as tfp\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from cbrain.model_diagnostics import ModelDiagnostics\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as imag\n",
    "import scipy.integrate as sin\n",
    "# import cartopy.crs as ccrs\n",
    "import matplotlib.ticker as mticker\n",
    "# from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import pickle\n",
    "# from climate_invariant import *\n",
    "from tensorflow.keras import layers\n",
    "import datetime\n",
    "from climate_invariant_utils import *\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fz = 15\n",
    "lw = 4\n",
    "siz = 100\n",
    "S0 = 320 # Representative mean solar insolation for normalization purposes\n",
    "S0max = 1410.6442 # Max solar insolation for normalization purposes\n",
    "SN = S0/100 # Representative target = mean insolation / 4\n",
    "XNNA = 1.25 # Abscissa where architecture-constrained network will be placed\n",
    "XTEXT = 0.25 # Text placement\n",
    "YMIN = -1 # Representative value for conserving network\n",
    "YTEXT = 0.3 # Text placement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('text', usetex=False)\n",
    "mpl.rcParams['mathtext.fontset'] = 'stix'\n",
    "mpl.rcParams['font.family'] = 'STIXGeneral'\n",
    "plt.rc('font', family='serif', size=fz)\n",
    "mpl.rcParams['lines.linewidth'] = lw\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathPKL = '/export/home/tbeucler/CBRAIN-CAM/notebooks/tbeucler_devlog/PKL_DATA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_array = np.linspace(0,1,1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_array = [\n",
    "    '2021_03_18_O3_TRAIN_M4K_shuffle.nc',\n",
    "    '2021_03_18_O3_TRAIN_P4K_shuffle.nc',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = {}\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ipath,path in enumerate(path_array):\n",
    "    hf = open(pathPKL+'/'+path+'_PERC.pkl','rb')\n",
    "    pdf[path] = pickle.load(hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2021_03_18_O3_TRAIN_M4K_shuffle.nc': {'quantile_array': array([0.   , 0.001, 0.002, ..., 0.998, 0.999, 1.   ]),\n",
       "  'PERC_array': array([[9.05374009e-07, 8.77815637e-07, 4.98417307e-07, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [9.11630138e-07, 8.91066577e-07, 5.24233712e-07, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [9.13556164e-07, 8.93629931e-07, 5.24234508e-07, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         ...,\n",
       "         [1.81165069e-06, 1.79016258e-06, 1.61611712e-06, ...,\n",
       "          4.71056754e-05, 4.42048546e-05, 8.29813011e-05],\n",
       "         [1.81427470e-06, 1.79245058e-06, 1.62005475e-06, ...,\n",
       "          6.76648574e-05, 7.45083865e-05, 1.28348825e-04],\n",
       "         [1.82074757e-06, 1.80071015e-06, 1.63516086e-06, ...,\n",
       "          5.01840608e-04, 5.79330081e-04, 6.49507623e-04]])},\n",
       " '2021_03_18_O3_TRAIN_P4K_shuffle.nc': {'quantile_array': array([0.   , 0.001, 0.002, ..., 0.998, 0.999, 1.   ]),\n",
       "  'PERC_array': array([[1.37732434e-06, 1.19104163e-06, 4.81186021e-07, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [1.38357811e-06, 1.25212376e-06, 5.24233371e-07, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [1.38551718e-06, 1.26565038e-06, 5.24234849e-07, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         ...,\n",
       "         [1.74623960e-06, 1.71437534e-06, 1.62744289e-06, ...,\n",
       "          4.11302145e-05, 3.78862698e-05, 3.93864722e-05],\n",
       "         [1.74847685e-06, 1.71654372e-06, 1.68633071e-06, ...,\n",
       "          6.17628516e-05, 6.37223272e-05, 1.02323095e-04],\n",
       "         [1.76003380e-06, 1.72247303e-06, 2.10690723e-06, ...,\n",
       "          4.85183118e-04, 5.21734299e-04, 5.82364621e-04]])}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create data generators for all three cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load coordinates (just pick any file from the climate model run)\n",
    "\n",
    "# Comet path below\n",
    "# coor = xr.open_dataset(\"/oasis/scratch/comet/ankitesh/temp_project/data/sp8fbp_minus4k.cam2.h1.0000-01-01-00000.nc\",\\\n",
    "#                     decode_times=False)\n",
    "\n",
    "# GP path below\n",
    "path_0K = '/DFS-L/DATA/pritchard/tbeucler/SPCAM/fluxbypass_aqua/'\n",
    "coor = xr.open_dataset(path_0K+\"AndKua_aqua_SPCAM3.0_sp_fbp_f4.cam2.h1.0000-09-02-00000.nc\")\n",
    "\n",
    "lat = coor.lat; lon = coor.lon; lev = coor.lev;\n",
    "coor.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comet path below\n",
    "# TRAINDIR = '/oasis/scratch/comet/ankitesh/temp_project/PrepData/CRHData/'\n",
    "# path = '/home/ankitesh/CBrain_project/CBRAIN-CAM/cbrain/'\n",
    "\n",
    "# GP path below\n",
    "TRAINDIR = '/DFS-L/DATA/pritchard/tbeucler/SPCAM/SPCAM_PHYS/'\n",
    "path = '/export/nfs0home/tbeucler/CBRAIN-CAM/cbrain/'\n",
    "path_nnconfig = '/export/nfs0home/tbeucler/CBRAIN-CAM/nn_config/'\n",
    "\n",
    "# Load hyam and hybm to calculate pressure field in SPCAM\n",
    "path_hyam = 'hyam_hybm.pkl'\n",
    "hf = open(path+path_hyam,'rb')\n",
    "hyam,hybm = pickle.load(hf)\n",
    "\n",
    "# Scale dictionary to convert the loss to W/m2\n",
    "scale_dict = load_pickle(path_nnconfig+'scale_dicts/009_Wm2_scaling.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Data generator class for the climate-invariant network. Calculates the physical rescalings needed to make the NN climate-invariant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose between aquaplanet and realistic geography here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GP paths below\n",
    "#path_aquaplanet = '/DFS-L/DATA/pritchard/tbeucler/SPCAM/SPCAM_PHYS/'\n",
    "#path_realgeography = ''\n",
    "\n",
    "# GP /fast paths below\n",
    "path_aquaplanet = '/fast/tbeucler/climate_invariant/aquaplanet/'\n",
    "\n",
    "# Comet paths below\n",
    "# path_aquaplanet = '/oasis/scratch/comet/ankitesh/temp_project/PrepData/'\n",
    "# path_realgeography = '/oasis/scratch/comet/ankitesh/temp_project/PrepData/geography/'\n",
    "\n",
    "path = path_aquaplanet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generator using RH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale_dict_RH = load_pickle('/home/ankitesh/CBrain_project/CBRAIN-CAM/nn_config/scale_dicts/009_Wm2_scaling_2.pkl')\n",
    "scale_dict_RH = scale_dict.copy()\n",
    "scale_dict_RH['RH'] = 0.01*L_S/G, # Arbitrary 0.1 factor as specific humidity is generally below 2%\n",
    "\n",
    "in_vars_RH = ['RH','TBP','PS', 'SOLIN', 'SHFLX', 'LHFLX']\n",
    "# if path==path_realgeography: out_vars_RH = ['PTEQ','PTTEND','FSNT','FSNS','FLNT','FLNS']\n",
    "# elif path==path_aquaplanet: out_vars_RH = ['PHQ','TPHYSTND','FSNT', 'FSNS', 'FLNT', 'FLNS']\n",
    "if path==path_aquaplanet: out_vars_RH = ['PHQ','TPHYSTND','QRL','QRS']\n",
    "\n",
    "# New GP path below\n",
    "TRAINFILE_RH = '2021_01_24_O3_small_shuffle.nc'\n",
    "NORMFILE_RH = '2021_02_01_NORM_O3_RH_small.nc'\n",
    "    \n",
    "# Comet/Ankitesh path below\n",
    "# TRAINFILE_RH = 'CI_RH_M4K_NORM_train_shuffle.nc'\n",
    "# NORMFILE_RH = 'CI_RH_M4K_NORM_norm.nc'\n",
    "# VALIDFILE_RH = 'CI_RH_M4K_NORM_valid.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen_RH = DataGenerator(\n",
    "    data_fn = path+TRAINFILE_RH,\n",
    "    input_vars = in_vars_RH,\n",
    "    output_vars = out_vars_RH,\n",
    "    norm_fn = path+NORMFILE_RH,\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dict_RH,\n",
    "    batch_size=1024,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generator using QSATdeficit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only need the norm file for this generator as we are solely using it as an input to determine the right normalization for the combined generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New GP path below\n",
    "TRAINFILE_QSATdeficit = '2021_02_01_O3_QSATdeficit_small_shuffle.nc'\n",
    "NORMFILE_QSATdeficit = '2021_02_01_NORM_O3_QSATdeficit_small.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_vars_QSATdeficit = ['QSATdeficit','TBP','PS', 'SOLIN', 'SHFLX', 'LHFLX']\n",
    "# if path==path_realgeography: out_vars_RH = ['PTEQ','PTTEND','FSNT','FSNS','FLNT','FLNS']\n",
    "# elif path==path_aquaplanet: out_vars_RH = ['PHQ','TPHYSTND','FSNT', 'FSNS', 'FLNT', 'FLNS']\n",
    "if path==path_aquaplanet: out_vars_QSATdeficit = ['PHQ','TPHYSTND','QRL','QRS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen_QSATdeficit = DataGenerator(\n",
    "    data_fn = path+TRAINFILE_QSATdeficit,\n",
    "    input_vars = in_vars_QSATdeficit,\n",
    "    output_vars = out_vars_QSATdeficit,\n",
    "    norm_fn = path+NORMFILE_QSATdeficit,\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dict,\n",
    "    batch_size=1024,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generator using TNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_vars = ['QBP','TfromNS','PS', 'SOLIN', 'SHFLX', 'LHFLX']\n",
    "if path==path_aquaplanet: out_vars = ['PHQ','TPHYSTND','FSNT', 'FSNS', 'FLNT', 'FLNS']\n",
    "elif path==path_realgeography: out_vars = ['PTEQ','PTTEND','FSNT','FSNS','FLNT','FLNS']\n",
    "\n",
    "TRAINFILE_TNS = '2021_02_01_O3_TfromNS_small_shuffle.nc'\n",
    "NORMFILE_TNS = '2021_02_01_NORM_O3_TfromNS_small.nc'\n",
    "VALIDFILE_TNS = 'CI_TNS_M4K_NORM_valid.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen_TNS = DataGenerator(\n",
    "    data_fn = path+TRAINFILE_TNS,\n",
    "    input_vars = in_vars,\n",
    "    output_vars = out_vars,\n",
    "    norm_fn = path+NORMFILE_TNS,\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dict,\n",
    "    batch_size=1024,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generator using BCONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_vars = ['QBP','BCONS','PS', 'SOLIN', 'SHFLX', 'LHFLX']\n",
    "if path==path_aquaplanet: out_vars = ['PHQ','TPHYSTND','FSNT', 'FSNS', 'FLNT', 'FLNS']\n",
    "elif path==path_realgeography: out_vars = ['PTEQ','PTTEND','FSNT','FSNS','FLNT','FLNS']\n",
    "\n",
    "TRAINFILE_BCONS = '2021_02_01_O3_BCONS_small_shuffle.nc'\n",
    "NORMFILE_BCONS = '2021_02_01_NORM_O3_BCONS_small.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen_BCONS = DataGenerator(\n",
    "    data_fn = path+TRAINFILE_BCONS,\n",
    "    input_vars = in_vars,\n",
    "    output_vars = out_vars,\n",
    "    norm_fn = path+NORMFILE_BCONS,\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dict,\n",
    "    batch_size=1024,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generator using NSto220"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_vars = ['QBP','T_NSto220','PS', 'SOLIN', 'SHFLX', 'LHFLX']\n",
    "if path==path_aquaplanet: out_vars = ['PHQ','TPHYSTND','FSNT', 'FSNS', 'FLNT', 'FLNS']\n",
    "elif path==path_realgeography: out_vars = ['PTEQ','PTTEND','FSNT','FSNS','FLNT','FLNS']\n",
    "\n",
    "TRAINFILE_T_NSto220 = '2021_03_31_O3_T_NSto220_small.nc'\n",
    "NORMFILE_T_NSto220 = '2021_03_31_NORM_O3_T_NSto220_small.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen_T_NSto220 = DataGenerator(\n",
    "    data_fn = path+TRAINFILE_T_NSto220,\n",
    "    input_vars = in_vars,\n",
    "    output_vars = out_vars,\n",
    "    norm_fn = path+NORMFILE_T_NSto220,\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dict,\n",
    "    batch_size=8192,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generator using LHF_nsDELQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_vars = ['QBP','TBP','PS', 'SOLIN', 'SHFLX', 'LHF_nsDELQ']\n",
    "if path==path_aquaplanet: out_vars = ['PHQ','TPHYSTND','FSNT', 'FSNS', 'FLNT', 'FLNS']\n",
    "elif path==path_realgeography: out_vars = ['PTEQ','PTTEND','FSNT','FSNS','FLNT','FLNS']\n",
    "\n",
    "TRAINFILE_LHF_nsDELQ = '2021_02_01_O3_LHF_nsDELQ_small_shuffle.nc'\n",
    "NORMFILE_LHF_nsDELQ = '2021_02_01_NORM_O3_LHF_nsDELQ_small.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen_LHF_nsDELQ = DataGenerator(\n",
    "    data_fn = path+TRAINFILE_LHF_nsDELQ,\n",
    "    input_vars = in_vars,\n",
    "    output_vars = out_vars,\n",
    "    norm_fn = path+NORMFILE_LHF_nsDELQ,\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dict,\n",
    "    batch_size=8192,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generator using LHF_nsQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_vars = ['QBP','TBP','PS', 'SOLIN', 'SHFLX', 'LHF_nsQ']\n",
    "if path==path_aquaplanet: out_vars = ['PHQ','TPHYSTND','FSNT', 'FSNS', 'FLNT', 'FLNS']\n",
    "elif path==path_realgeography: out_vars = ['PTEQ','PTTEND','FSNT','FSNS','FLNT','FLNS']\n",
    "\n",
    "TRAINFILE_LHF_nsQ = '2021_02_01_O3_LHF_nsQ_small_shuffle.nc'\n",
    "NORMFILE_LHF_nsQ = '2021_02_01_NORM_O3_LHF_nsQ_small.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen_LHF_nsQ = DataGenerator(\n",
    "    data_fn = path+TRAINFILE_LHF_nsQ,\n",
    "    input_vars = in_vars,\n",
    "    output_vars = out_vars,\n",
    "    norm_fn = path+NORMFILE_LHF_nsQ,\n",
    "    input_transform = ('mean', 'maxrs'),\n",
    "    output_transform = scale_dict,\n",
    "    batch_size=8192,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generator Combined (latest flexible version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_vars = ['QBP','TBP','PS', 'SOLIN', 'SHFLX', 'LHFLX']\n",
    "#if path==path_aquaplanet: out_vars=['PHQPERC','TPHYSTNDPERC','QRLPERC','QRSPERC']\n",
    "out_vars = ['PHQ','TPHYSTND','QRL','QRS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINFILE = '2021_01_24_O3_TRAIN_shuffle.nc'\n",
    "NORMFILE = '2021_01_24_NORM_O3_small.nc'\n",
    "# VALIDFILE = '2021_01_24_O3_VALID.nc'\n",
    "# GENTESTFILE = 'CI_SP_P4K_valid.nc'\n",
    "\n",
    "# In physical space\n",
    "TRAINFILE = '2021_03_18_O3_TRAIN_M4K_shuffle.nc'\n",
    "VALIDFILE = '2021_03_18_O3_VALID_M4K.nc'\n",
    "TESTFILE_DIFFCLIMATE = '2021_03_18_O3_TRAIN_P4K_shuffle.nc'\n",
    "TESTFILE_DIFFGEOG = '2021_04_18_RG_TRAIN_M4K_shuffle.nc'\n",
    "\n",
    "# In percentile space\n",
    "#TRAINFILE = '2021_04_09_PERC_TRAIN_M4K_shuffle.nc'\n",
    "#TRAINFILE = '2021_01_24_O3_small_shuffle.nc'\n",
    "#VALIDFILE = '2021_04_09_PERC_VALID_M4K.nc'\n",
    "#TESTFILE = '2021_04_09_PERC_TEST_P4K.nc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brute-force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen_BF = DataGeneratorCI(data_fn = path+TRAINFILE,\n",
    "                               input_vars=in_vars,\n",
    "                               output_vars=out_vars,\n",
    "                               norm_fn=path+NORMFILE,\n",
    "                               input_transform=('mean', 'maxrs'),\n",
    "                               output_transform=scale_dict,\n",
    "                               batch_size=8192,\n",
    "                               shuffle=True,\n",
    "                               xarray=False,\n",
    "                               var_cut_off=None, \n",
    "                               Qscaling=None,\n",
    "                               Tscaling=None,\n",
    "                               LHFscaling=None,\n",
    "                               SHFscaling=None,\n",
    "                               output_scaling=False,\n",
    "                               interpolate=False,\n",
    "                               hyam=hyam,hybm=hybm,\n",
    "                               inp_sub_Qscaling=None,\n",
    "                               inp_div_Qscaling=None,\n",
    "                               inp_sub_Tscaling=None,\n",
    "                               inp_div_Tscaling=None,\n",
    "                               inp_sub_LHFscaling=None,\n",
    "                               inp_div_LHFscaling=None,\n",
    "                               inp_sub_SHFscaling=None,\n",
    "                               inp_div_SHFscaling=None,\n",
    "                               lev=None, interm_size=40,\n",
    "                               lower_lim=6,is_continous=True,Tnot=5,\n",
    "                               epsQ=1e-3,epsT=1,mode='train')\n",
    "\n",
    "test_diffclimate_gen_BF = DataGeneratorCI(data_fn = path+TESTFILE_DIFFCLIMATE,\n",
    "                                       input_vars=in_vars,\n",
    "                                       output_vars=out_vars,\n",
    "                                       norm_fn=path+NORMFILE,\n",
    "                                       input_transform=('mean', 'maxrs'),\n",
    "                                       output_transform=scale_dict,\n",
    "                                       batch_size=8192,\n",
    "                                       shuffle=True,\n",
    "                                       xarray=False,\n",
    "                                       var_cut_off=None, \n",
    "                                       Qscaling=None,\n",
    "                                       Tscaling=None,\n",
    "                                       LHFscaling=None,\n",
    "                                       SHFscaling=None,\n",
    "                                       output_scaling=False,\n",
    "                                       interpolate=False,\n",
    "                                       hyam=hyam,hybm=hybm,\n",
    "                                       inp_sub_Qscaling=None,\n",
    "                                       inp_div_Qscaling=None,\n",
    "                                       inp_sub_Tscaling=None,\n",
    "                                       inp_div_Tscaling=None,\n",
    "                                       inp_sub_LHFscaling=None,\n",
    "                                       inp_div_LHFscaling=None,\n",
    "                                       inp_sub_SHFscaling=None,\n",
    "                                       inp_div_SHFscaling=None,\n",
    "                                       lev=None, interm_size=40,\n",
    "                                       lower_lim=6,is_continous=True,Tnot=5,\n",
    "                                       epsQ=1e-3,epsT=1,mode='train')\n",
    "\n",
    "test_diffgeog_gen_BF = DataGeneratorCI(data_fn = path+TESTFILE_DIFFGEOG,\n",
    "                                       input_vars=in_vars,\n",
    "                                       output_vars=out_vars,\n",
    "                                       norm_fn=path+NORMFILE,\n",
    "                                       input_transform=('mean', 'maxrs'),\n",
    "                                       output_transform=scale_dict,\n",
    "                                       batch_size=8192,\n",
    "                                       shuffle=True,\n",
    "                                       xarray=False,\n",
    "                                       var_cut_off=None, \n",
    "                                       Qscaling=None,\n",
    "                                       Tscaling=None,\n",
    "                                       LHFscaling=None,\n",
    "                                       SHFscaling=None,\n",
    "                                       output_scaling=False,\n",
    "                                       interpolate=False,\n",
    "                                       hyam=hyam,hybm=hybm,\n",
    "                                       inp_sub_Qscaling=None,\n",
    "                                       inp_div_Qscaling=None,\n",
    "                                       inp_sub_Tscaling=None,\n",
    "                                       inp_div_Tscaling=None,\n",
    "                                       inp_sub_LHFscaling=None,\n",
    "                                       inp_div_LHFscaling=None,\n",
    "                                       inp_sub_SHFscaling=None,\n",
    "                                       inp_div_SHFscaling=None,\n",
    "                                       lev=None, interm_size=40,\n",
    "                                       lower_lim=6,is_continous=True,Tnot=5,\n",
    "                                       epsQ=1e-3,epsT=1,mode='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input but not output rescaled (T=BCONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tscaling_name = 'BCONS'\n",
    "train_gen_T = train_gen_BCONS\n",
    "\n",
    "train_gen_I = DataGeneratorCI(data_fn = path+TRAINFILE,\n",
    "                               input_vars=in_vars,\n",
    "                               output_vars=out_vars,\n",
    "                               norm_fn=path+NORMFILE,\n",
    "                               input_transform=('mean', 'maxrs'),\n",
    "                               output_transform=scale_dict,\n",
    "                               batch_size=8192,\n",
    "                               shuffle=True,\n",
    "                               xarray=False,\n",
    "                               var_cut_off=None, \n",
    "                               Qscaling='RH',\n",
    "                               Tscaling=Tscaling_name,\n",
    "                               LHFscaling='LHF_nsDELQ',\n",
    "                               SHFscaling=None,\n",
    "                               output_scaling=False,\n",
    "                               interpolate=False,\n",
    "                               hyam=hyam,hybm=hybm,\n",
    "                               inp_sub_Qscaling=train_gen_RH.input_transform.sub,\n",
    "                               inp_div_Qscaling=train_gen_RH.input_transform.div,\n",
    "                               inp_sub_Tscaling=train_gen_T.input_transform.sub,\n",
    "                               inp_div_Tscaling=train_gen_T.input_transform.div,\n",
    "                               inp_sub_LHFscaling=train_gen_LHF_nsDELQ.input_transform.sub,\n",
    "                               inp_div_LHFscaling=train_gen_LHF_nsDELQ.input_transform.div,\n",
    "                               inp_sub_SHFscaling=None,\n",
    "                               inp_div_SHFscaling=None,\n",
    "                               lev=None, interm_size=40,\n",
    "                               lower_lim=6,is_continous=True,Tnot=5,\n",
    "                               epsQ=1e-3,epsT=1,mode='train')\n",
    "\n",
    "valid_gen_I = DataGeneratorCI(data_fn = path+VALIDFILE,\n",
    "                               input_vars=in_vars,\n",
    "                               output_vars=out_vars,\n",
    "                               norm_fn=path+NORMFILE,\n",
    "                               input_transform=('mean', 'maxrs'),\n",
    "                               output_transform=scale_dict,\n",
    "                               batch_size=8192,\n",
    "                               shuffle=True,\n",
    "                               xarray=False,\n",
    "                               var_cut_off=None, \n",
    "                               Qscaling='RH',\n",
    "                               Tscaling=Tscaling_name,\n",
    "                               LHFscaling='LHF_nsDELQ',\n",
    "                               SHFscaling=None,\n",
    "                               output_scaling=False,\n",
    "                               interpolate=False,\n",
    "                               hyam=hyam,hybm=hybm,\n",
    "                               inp_sub_Qscaling=train_gen_RH.input_transform.sub,\n",
    "                               inp_div_Qscaling=train_gen_RH.input_transform.div,\n",
    "                               inp_sub_Tscaling=train_gen_T.input_transform.sub,\n",
    "                               inp_div_Tscaling=train_gen_T.input_transform.div,\n",
    "                               inp_sub_LHFscaling=train_gen_LHF_nsDELQ.input_transform.sub,\n",
    "                               inp_div_LHFscaling=train_gen_LHF_nsDELQ.input_transform.div,\n",
    "                               inp_sub_SHFscaling=None,\n",
    "                               inp_div_SHFscaling=None,\n",
    "                               lev=None, interm_size=40,\n",
    "                               lower_lim=6,is_continous=True,Tnot=5,\n",
    "                               epsQ=1e-3,epsT=1,mode='train')\n",
    "\n",
    "test_diffclimate_gen_I = DataGeneratorCI(data_fn = path+TESTFILE_DIFFCLIMATE,\n",
    "                                       input_vars=in_vars,\n",
    "                                       output_vars=out_vars,\n",
    "                                       norm_fn=path+NORMFILE,\n",
    "                                       input_transform=('mean', 'maxrs'),\n",
    "                                       output_transform=scale_dict,\n",
    "                                       batch_size=8192,\n",
    "                                       shuffle=True,\n",
    "                                       xarray=False,\n",
    "                                       var_cut_off=None, \n",
    "                                       Qscaling='RH',\n",
    "                                       Tscaling=Tscaling_name,\n",
    "                                       LHFscaling='LHF_nsDELQ',\n",
    "                                       SHFscaling=None,\n",
    "                                       output_scaling=False,\n",
    "                                       interpolate=False,\n",
    "                                       hyam=hyam,hybm=hybm,\n",
    "                                       inp_sub_Qscaling=train_gen_RH.input_transform.sub,\n",
    "                                       inp_div_Qscaling=train_gen_RH.input_transform.div,\n",
    "                                       inp_sub_Tscaling=train_gen_T.input_transform.sub,\n",
    "                                       inp_div_Tscaling=train_gen_T.input_transform.div,\n",
    "                                       inp_sub_LHFscaling=train_gen_LHF_nsDELQ.input_transform.sub,\n",
    "                                       inp_div_LHFscaling=train_gen_LHF_nsDELQ.input_transform.div,\n",
    "                                       inp_sub_SHFscaling=None,\n",
    "                                       inp_div_SHFscaling=None,\n",
    "                                       lev=None, interm_size=40,\n",
    "                                       lower_lim=6,is_continous=True,Tnot=5,\n",
    "                                       epsQ=1e-3,epsT=1,mode='train')\n",
    "\n",
    "test_diffgeog_gen_CI = DataGeneratorCI(data_fn = path+TESTFILE_DIFFGEOG,\n",
    "                                       input_vars=in_vars,\n",
    "                                       output_vars=out_vars,\n",
    "                                       norm_fn=path+NORMFILE,\n",
    "                                       input_transform=('mean', 'maxrs'),\n",
    "                                       output_transform=scale_dict,\n",
    "                                       batch_size=8192,\n",
    "                                       shuffle=True,\n",
    "                                       xarray=False,\n",
    "                                       var_cut_off=None, \n",
    "                                       Qscaling='RH',\n",
    "                                       Tscaling=Tscaling_name,\n",
    "                                       LHFscaling='LHF_nsDELQ',\n",
    "                                       SHFscaling=None,\n",
    "                                       output_scaling=False,\n",
    "                                       interpolate=False,\n",
    "                                       hyam=hyam,hybm=hybm,\n",
    "                                       inp_sub_Qscaling=train_gen_RH.input_transform.sub,\n",
    "                                       inp_div_Qscaling=train_gen_RH.input_transform.div,\n",
    "                                       inp_sub_Tscaling=train_gen_T.input_transform.sub,\n",
    "                                       inp_div_Tscaling=train_gen_T.input_transform.div,\n",
    "                                       inp_sub_LHFscaling=train_gen_LHF_nsDELQ.input_transform.sub,\n",
    "                                       inp_div_LHFscaling=train_gen_LHF_nsDELQ.input_transform.div,\n",
    "                                       inp_sub_SHFscaling=None,\n",
    "                                       inp_div_SHFscaling=None,\n",
    "                                       lev=None, interm_size=40,\n",
    "                                       lower_lim=6,is_continous=True,Tnot=5,\n",
    "                                       epsQ=1e-3,epsT=1,mode='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input and output rescaled (T=BCONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_vars = ['QBP','TBP','PS', 'SOLIN', 'SHFLX', 'LHFLX']\n",
    "out_vars=['PHQPERC','TPHYSTNDPERC','QRLPERC','QRSPERC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINFILE = '2021_01_24_O3_TRAIN_shuffle.nc'\n",
    "NORMFILE = '2021_01_24_NORM_O3_small.nc'\n",
    "# VALIDFILE = '2021_01_24_O3_VALID.nc'\n",
    "# GENTESTFILE = 'CI_SP_P4K_valid.nc'\n",
    "\n",
    "# In percentile space\n",
    "TRAINFILE = '2021_04_09_PERC_TRAIN_M4K_shuffle.nc'\n",
    "VALIDFILE = '2021_04_09_PERC_VALID_M4K.nc'\n",
    "TESTFILE_DIFFCLIMATE = '2021_04_09_PERC_TRAIN_P4K_shuffle.nc'\n",
    "TESTFILE_DIFFGEOG = '2021_04_24_RG_PERC_TRAIN_M4K_shuffle.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tscaling_name = 'BCONS'\n",
    "train_gen_T = train_gen_BCONS\n",
    "\n",
    "train_gen_IO = DataGeneratorCI(data_fn = path+TRAINFILE,\n",
    "                               input_vars=in_vars,\n",
    "                               output_vars=out_vars,\n",
    "                               norm_fn=path+NORMFILE,\n",
    "                               input_transform=('mean', 'maxrs'),\n",
    "                               output_transform=None,\n",
    "                               batch_size=8192,\n",
    "                               shuffle=True,\n",
    "                               xarray=False,\n",
    "                               var_cut_off=None, \n",
    "                               Qscaling='RH',\n",
    "                               Tscaling=Tscaling_name,\n",
    "                               LHFscaling='LHF_nsDELQ',\n",
    "                               SHFscaling=None,\n",
    "                               output_scaling=False,\n",
    "                               interpolate=False,\n",
    "                               hyam=hyam,hybm=hybm,\n",
    "                               inp_sub_Qscaling=train_gen_RH.input_transform.sub,\n",
    "                               inp_div_Qscaling=train_gen_RH.input_transform.div,\n",
    "                               inp_sub_Tscaling=train_gen_T.input_transform.sub,\n",
    "                               inp_div_Tscaling=train_gen_T.input_transform.div,\n",
    "                               inp_sub_LHFscaling=train_gen_LHF_nsDELQ.input_transform.sub,\n",
    "                               inp_div_LHFscaling=train_gen_LHF_nsDELQ.input_transform.div,\n",
    "                               inp_sub_SHFscaling=None,\n",
    "                               inp_div_SHFscaling=None,\n",
    "                               lev=None, interm_size=40,\n",
    "                               lower_lim=6,is_continous=True,Tnot=5,\n",
    "                               epsQ=1e-3,epsT=1,mode='train')\n",
    "\n",
    "test_diffclimate_gen_IO = DataGeneratorCI(data_fn = path+TESTFILE_DIFFCLIMATE,\n",
    "                                       input_vars=in_vars,\n",
    "                                       output_vars=out_vars,\n",
    "                                       norm_fn=path+NORMFILE,\n",
    "                                       input_transform=('mean', 'maxrs'),\n",
    "                                       output_transform=None,\n",
    "                                       batch_size=8192,\n",
    "                                       shuffle=True,\n",
    "                                       xarray=False,\n",
    "                                       var_cut_off=None, \n",
    "                                       Qscaling='RH',\n",
    "                                       Tscaling=Tscaling_name,\n",
    "                                       LHFscaling='LHF_nsDELQ',\n",
    "                                       SHFscaling=None,\n",
    "                                       output_scaling=False,\n",
    "                                       interpolate=False,\n",
    "                                       hyam=hyam,hybm=hybm,\n",
    "                                       inp_sub_Qscaling=train_gen_RH.input_transform.sub,\n",
    "                                       inp_div_Qscaling=train_gen_RH.input_transform.div,\n",
    "                                       inp_sub_Tscaling=train_gen_T.input_transform.sub,\n",
    "                                       inp_div_Tscaling=train_gen_T.input_transform.div,\n",
    "                                       inp_sub_LHFscaling=train_gen_LHF_nsDELQ.input_transform.sub,\n",
    "                                       inp_div_LHFscaling=train_gen_LHF_nsDELQ.input_transform.div,\n",
    "                                       inp_sub_SHFscaling=None,\n",
    "                                       inp_div_SHFscaling=None,\n",
    "                                       lev=None, interm_size=40,\n",
    "                                       lower_lim=6,is_continous=True,Tnot=5,\n",
    "                                       epsQ=1e-3,epsT=1,mode='train')\n",
    "\n",
    "test_diffgeog_gen_IO = DataGeneratorCI(data_fn = path+TESTFILE_DIFFGEOG,\n",
    "                                       input_vars=in_vars,\n",
    "                                       output_vars=out_vars,\n",
    "                                       norm_fn=path+NORMFILE,\n",
    "                                       input_transform=('mean', 'maxrs'),\n",
    "                                       output_transform=None,\n",
    "                                       batch_size=8192,\n",
    "                                       shuffle=True,\n",
    "                                       xarray=False,\n",
    "                                       var_cut_off=None, \n",
    "                                       Qscaling='RH',\n",
    "                                       Tscaling=Tscaling_name,\n",
    "                                       LHFscaling='LHF_nsDELQ',\n",
    "                                       SHFscaling=None,\n",
    "                                       output_scaling=False,\n",
    "                                       interpolate=False,\n",
    "                                       hyam=hyam,hybm=hybm,\n",
    "                                       inp_sub_Qscaling=train_gen_RH.input_transform.sub,\n",
    "                                       inp_div_Qscaling=train_gen_RH.input_transform.div,\n",
    "                                       inp_sub_Tscaling=train_gen_T.input_transform.sub,\n",
    "                                       inp_div_Tscaling=train_gen_T.input_transform.div,\n",
    "                                       inp_sub_LHFscaling=train_gen_LHF_nsDELQ.input_transform.sub,\n",
    "                                       inp_div_LHFscaling=train_gen_LHF_nsDELQ.input_transform.div,\n",
    "                                       inp_sub_SHFscaling=None,\n",
    "                                       inp_div_SHFscaling=None,\n",
    "                                       lev=None, interm_size=40,\n",
    "                                       lower_lim=6,is_continous=True,Tnot=5,\n",
    "                                       epsQ=1e-3,epsT=1,mode='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load models for all three cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_HDF5 = '/DFS-L/DATA/pritchard/tbeucler/SPCAM/HDF5_DATA/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model's path\n",
    "path_BF = ''\n",
    "path_I = ''\n",
    "path_IO = ''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
