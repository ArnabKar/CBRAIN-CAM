{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tb - 7/18/2022 - Adapting equation learning from data to Earth-like situations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfspool-0/home/tbeucler/CBRAIN-CAM/notebooks/tbeucler_devlog\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from cbrain.cam_constants import *\n",
    "from cbrain.climate_invariant import *\n",
    "from cbrain.equation_discovery import *\n",
    "from cbrain.preprocessing.convert_dataset_20191113 import compute_LHF_nsDELQ\n",
    "from cbrain.climate_invariant_utils import *\n",
    "from scipy.integrate import cumtrapz,trapz\n",
    "from scipy import interpolate,misc\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fz = 12\n",
    "lw = 2\n",
    "siz = 100\n",
    "\n",
    "plt.rc('text', usetex=False)\n",
    "mpl.rcParams['mathtext.fontset'] = 'stix'\n",
    "mpl.rcParams['font.family'] = 'STIXGeneral'\n",
    "plt.rc('font', family='serif', size=fz)\n",
    "mpl.rcParams['lines.linewidth'] = lw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = '/DFS-L/DATA/pritchard/tbeucler/SPCAM/SPCAM_PHYS/'\n",
    "path_array = {}\n",
    "climate_str = ['cold','hot','both']\n",
    "set_str = ['train','valid','test']\n",
    "test_clim_str = ['cold','hot','both','medium']\n",
    "climates = ['cold','medium','hot']\n",
    "path_array['cold'] = [path_data+'2021_04_18_RG_TRAIN_M4K_shuffle.nc',\n",
    "                      path_data+'2021_04_18_RG_VALID_M4K.nc',\n",
    "                      path_data+'2021_04_18_RG_TEST_M4K.nc']\n",
    "path_array['hot'] = [path_data+'2021_04_18_RG_TRAIN_P4K_shuffle.nc',\n",
    "                     path_data+'2021_04_18_RG_VALID_P4K.nc',\n",
    "                     path_data+'2021_04_18_RG_TEST_P4K.nc']\n",
    "path_array['both'] = ['','','']\n",
    "path_array['medium'] = [path_data+'2021_06_03_RG_TRAIN_shuffle.nc',\n",
    "                        path_data+'2021_06_03_RG_VALID.nc',\n",
    "                        path_data+'2021_06_06_RG_TEST.nc']\n",
    "path_input_norm = path_data + '2021_04_18_RG_small.nc'\n",
    "path_train_RH = path_data + '2021_01_24_O3_small_shuffle.nc'\n",
    "path_norm_RH = path_data + '2021_02_01_NORM_O3_RH_small.nc'\n",
    "path_train_BMSE = path_data + '2021_06_16_BMSE_small_shuffle.nc'\n",
    "path_norm_BMSE = path_data + '2021_06_16_NORM_BMSE_small.nc'\n",
    "path_train_LHF_nsDELQ = path_data + '2021_02_01_O3_LHF_nsQ_small_shuffle.nc'\n",
    "path_norm_LHF_nsDELQ = path_data + '2021_02_01_NORM_O3_LHF_nsDELQ_small.nc'\n",
    "in_vars = ['QBP','TBP','PS','SOLIN','SHFLX','LHFLX'] # We take the large-scale climate state as inputs\n",
    "out_vars = ['PHQ','TPHYSTND','QRL','QRS'] # and we output the response of clouds/storms to these climate conditions\n",
    "scale_dict = pickle.load(open(path_data+'009_Wm2_scaling.pkl','rb'))\n",
    "path_append = ['2021_03_18_O3_TEST_M4K.nc','2021_01_24_O3_TEST.nc','2021_03_18_O3_TEST_P4K.nc']\n",
    "path_RH_B_append = ['2022_06_27_B_RH_TEST_m4K.nc','2022_06_27_B_RH_TEST_ref.nc','2022_06_27_B_RH_TEST_p4K.nc']\n",
    "path_LHF_nsDELQ = '2022_06_29_LHF_nsDELQ.nc'\n",
    "path_LHF_nsDELQ_train = '2022_07_08_LHF_nsDELQ_TRAIN_both.nc'\n",
    "scale_dict_RH = scale_dict.copy()\n",
    "scale_dict_RH['RH'] = 0.01*L_S/G, # Arbitrary 0.1 factor as specific humidity is generally below 2%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clim in climates:\n",
    "    train[clim] = xr.open_dataset(path_array[clim][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate input distribution statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-sample all three climates and mix samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYS = {}\n",
    "KEYS['local'] = ['ps', 'S0', 'SHF', 'LHF','LHFns','p', 'q', 'dq_dp_FD',\n",
    "              'd2q_dp2_FD','T', 'dT_dp_FD','d2T_dp2_FD','RH', 'dRH_dp_FD',\n",
    "              'd2RH_dp2_FD','B', 'dB_dp_FD','d2B_dp2_FD']\n",
    "KEYS['localCI'] = ['ps', 'S0', 'SHF','LHFns','p','RH', 'dRH_dp_FD',\n",
    "              'd2RH_dp2_FD','B', 'dB_dp_FD','d2B_dp2_FD']\n",
    "KEYS['localBF'] = ['ps', 'S0', 'SHF', 'LHF', 'p', 'q', 'dq_dp_FD',\n",
    "              'd2q_dp2_FD','T', 'dT_dp_FD','d2T_dp2_FD']\n",
    "KEYS['all'] = np.concatenate((KEYS['local'],['Q_above','Q_below','T_below','T_above',\n",
    "                                             'RH_below','RH_above','B_below','B_above']))\n",
    "KEYS['BF'] = np.concatenate((KEYS['localBF'],['Q_above','Q_below','T_below','T_above']))\n",
    "KEYS['CI'] = np.concatenate((KEYS['localCI'],['RH_below','RH_above','B_below','B_above']))\n",
    "scalar_keys = ['ps','S0','SHF','LHF','LHFns']\n",
    "vector_keys = ['p', 'q', 'dq_dp_FD', 'd2q_dp2_FD', 'Q_above', 'Q_below',\n",
    "               'T', 'dT_dp_FD', 'd2T_dp2_FD', 'T_above', 'T_below',\n",
    "               'RH', 'dRH_dp_FD', 'd2RH_dp2_FD', 'RH_above', 'RH_below',\n",
    "               'B', 'dB_dp_FD', 'd2B_dp2_FD', 'B_above', 'B_below']\n",
    "combin_keys = np.concatenate((scalar_keys,vector_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cold': <xarray.Dataset>\n",
       " Dimensions:    (sample: 143161344, var_names: 184)\n",
       " Coordinates:\n",
       "   * var_names  (var_names) object 'QBP' 'QBP' 'QBP' 'QBP' ... 'QRS' 'QRS' 'QRS'\n",
       " Dimensions without coordinates: sample\n",
       " Data variables:\n",
       "     time       (sample) int64 ...\n",
       "     lat        (sample) float64 ...\n",
       "     lon        (sample) float64 ...\n",
       "     vars       (sample, var_names) float32 ...,\n",
       " 'medium': <xarray.Dataset>\n",
       " Dimensions:    (sample: 143161344, var_names: 184)\n",
       " Coordinates:\n",
       "   * var_names  (var_names) object 'QBP' 'QBP' 'QBP' 'QBP' ... 'QRS' 'QRS' 'QRS'\n",
       " Dimensions without coordinates: sample\n",
       " Data variables:\n",
       "     time       (sample) int64 ...\n",
       "     lat        (sample) float64 ...\n",
       "     lon        (sample) float64 ...\n",
       "     vars       (sample, var_names) float32 ...,\n",
       " 'hot': <xarray.Dataset>\n",
       " Dimensions:    (sample: 143161344, var_names: 184)\n",
       " Coordinates:\n",
       "   * var_names  (var_names) object 'QBP' 'QBP' 'QBP' 'QBP' ... 'QRS' 'QRS' 'QRS'\n",
       " Dimensions without coordinates: sample\n",
       " Data variables:\n",
       "     time       (sample) int64 ...\n",
       "     lat        (sample) float64 ...\n",
       "     lon        (sample) float64 ...\n",
       "     vars       (sample, var_names) float32 ...}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate empirical PDF,CDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nsample = 2500000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_random = np.random.choice(np.linspace(0,xt[clim].shape[0]-1,xt[clim].shape[0]),\n",
    "                                size=((Nsample,)),replace=False).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = subsampler(i_random,x,y,xRH,xB,xLHFns,hyam,hybm,variables=KEYS['all'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "combin_keys = np.concatenate((scalar_keys,vector_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edg2bin(edges):\n",
    "    return (edges[:-1]+edges[1:])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF = {}; EDG = {}; CDF = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p\n",
      "q\n",
      "dq_dp_FD\n",
      "d2q_dp2_FD\n",
      "Q_above\n",
      "Q_below\n",
      "T\n",
      "dT_dp_FD\n",
      "d2T_dp2_FD\n",
      "T_above\n",
      "T_below\n",
      "RH\n",
      "dRH_dp_FD\n",
      "d2RH_dp2_FD\n",
      "RH_above\n",
      "RH_below\n",
      "B\n",
      "dB_dp_FD\n",
      "d2B_dp2_FD\n",
      "B_above\n",
      "B_below\n",
      "ps\n",
      "S0\n",
      "SHF\n",
      "LHF\n",
      "LHFns\n"
     ]
    }
   ],
   "source": [
    "for k in x_train.keys():\n",
    "    print(k)\n",
    "    PDF[k],EDG[k] = np.histogram(x_train[k].flatten(),bins=250,density=True)\n",
    "    db = np.array(np.diff(EDG[k]), float)  \n",
    "    CDF[k] = db*PDF[k].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix A: Convert q,T,LHF to RH,B,LHFns to form the climate-invariant variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_batch = 8192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gen_rescaling(input_rescaling,path_norm,path_train,scale_dict):\n",
    "    return DataGeneratorCI(\n",
    "        data_fn = path_train,\n",
    "        input_vars = input_rescaling,\n",
    "        output_vars = out_vars,\n",
    "        norm_fn = path_norm,\n",
    "        input_transform = ('mean', 'maxrs'),\n",
    "        output_transform = scale_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen_RH = train_gen_rescaling(['RH','TBP','PS', 'SOLIN', 'SHFLX', 'LHFLX'],\n",
    "                                   path_norm_RH,path_train_RH,scale_dict_RH)\n",
    "train_gen_BMSE = train_gen_rescaling(['QBP','BMSE','PS', 'SOLIN', 'SHFLX', 'LHFLX'],\n",
    "                                     path_norm_BMSE,path_train_BMSE,scale_dict)\n",
    "train_gen_LHF_nsDELQ = train_gen_rescaling(['QBP','TBP','PS', 'SOLIN', 'SHFLX', 'LHF_nsDELQ'],\n",
    "                                           path_norm_LHF_nsDELQ,path_train_LHF_nsDELQ,scale_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generator_singleDS(path,rescaling=None):\n",
    "    \n",
    "    in_vars = ['QBP','TBP','PS','SOLIN','SHFLX','LHFLX'] # We take the large-scale climate state as inputs\n",
    "    out_vars = ['PHQ','TPHYSTND','QRL','QRS'] # and we output the response of clouds/storms to these climate conditions\n",
    "    path_input_norm = path_data + '2021_01_24_NORM_O3_small.nc'\n",
    "    scale_dict = pickle.load(open(path_data+'009_Wm2_scaling.pkl','rb'))\n",
    "    \n",
    "    if rescaling=='CI':\n",
    "        gen = DataGeneratorCI(\n",
    "        data_fn = path,\n",
    "        input_vars = in_vars,\n",
    "        output_vars = out_vars,\n",
    "        norm_fn = path_input_norm,\n",
    "        batch_size=N_batch,\n",
    "        input_transform = ('mean', 'maxrs'),\n",
    "        output_transform = scale_dict,\n",
    "        Qscaling = 'RH',\n",
    "        Tscaling = 'BMSE',\n",
    "        LHFscaling = 'LHF_nsDELQ',\n",
    "        hyam=hyam, hybm=hybm, # Arrays to define mid-levels of hybrid vertical coordinate\n",
    "        inp_sub_Qscaling=train_gen_RH.input_transform.sub, # What to subtract from RH inputs\n",
    "        inp_div_Qscaling=train_gen_RH.input_transform.div, # What to divide RH inputs by\n",
    "        inp_sub_Tscaling=train_gen_BMSE.input_transform.sub,\n",
    "        inp_div_Tscaling=train_gen_BMSE.input_transform.div,\n",
    "        inp_sub_LHFscaling=train_gen_LHF_nsDELQ.input_transform.sub,\n",
    "        inp_div_LHFscaling=train_gen_LHF_nsDELQ.input_transform.div\n",
    "        ) \n",
    "    else:\n",
    "        gen = DataGeneratorCI(\n",
    "        data_fn = path,\n",
    "        input_vars = in_vars,\n",
    "        output_vars = out_vars,\n",
    "        norm_fn = path_input_norm,\n",
    "        batch_size=N_batch,\n",
    "        input_transform = ('mean', 'maxrs'),\n",
    "        output_transform = scale_dict\n",
    "        )\n",
    "\n",
    "    return gen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "BFgen = {}\n",
    "CIgen = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Climate =  cold\n",
      "Set =  train\n",
      "Set =  valid\n",
      "Set =  test\n",
      "Climate =  medium\n",
      "Set =  train\n",
      "Set =  valid\n",
      "Set =  test\n",
      "Climate =  hot\n",
      "Set =  train\n",
      "Set =  valid\n",
      "Set =  test\n"
     ]
    }
   ],
   "source": [
    "for iclimate,clim in enumerate(climates):\n",
    "    print('Climate = ',clim)\n",
    "    BFgen[clim] = {}\n",
    "    CIgen[clim] = {}\n",
    "    \n",
    "    for iset,st in enumerate(set_str):\n",
    "        print('Set = ',st)\n",
    "        \n",
    "        BFgen[clim][st] = Generator_singleDS(path_array[clim][iset])\n",
    "        CIgen[clim][st] = Generator_singleDS(path_array[clim][iset],rescaling='CI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create array to hold rescaled variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "clim = 'cold'; set0 = 'train'; iset = 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = CIgen[clim][set0]\n",
    "train_set = xr.open_dataset(path_array[clim][iset])\n",
    "train_CI = train_set.copy()\n",
    "var_names_CI = train_CI['var_names'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(60):\n",
    "    if i<30: var_names_CI[i] = 'RH'\n",
    "    else: var_names_CI[i] = 'BMSE'\n",
    "var_names_CI[63] = 'LHF_nsDELQ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_CI.assign_coords({'var_names':var_names_CI});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "newval_train = np.zeros(train_CI['vars'].shape,dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign new values using climate-invariant generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress= 1.72 %                \r"
     ]
    }
   ],
   "source": [
    "for ibatch in range((gen.n_samples)//N_batch):\n",
    "    if ibatch % 10==0: print('progress=','%2.2f' % \\\n",
    "                             (100*ibatch/((gen.n_samples)//N_batch)),\n",
    "                             '%','               ',end='\\r')\n",
    "    gen_pu = (gen[ibatch][0]*gen.input_transform.div+gen.input_transform.sub)\n",
    "    newval_train[ibatch*N_batch:((1+ibatch)*N_batch),:] = np.concatenate(\n",
    "        (gen_pu[:,:64],train_CI['vars'][ibatch*N_batch:((1+ibatch)*N_batch),64:]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(newval_train[:,:30].flatten(),bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(newval_train[:,30:60].flatten(),bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(newval_train[:,63].flatten(),bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract and save RH, B, and LHF_nsDELQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RH_train = np.float32(newval_train[:,:30])\n",
    "B_train = np.float32(newval_train[:,30:60])\n",
    "LHFnsDELQ_train = np.float32(newval_train[:,63])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict(\n",
    "        RH_train=([\"samples_both\",\"pressure\"],RH_train),\n",
    "        B_train=([\"samples_both\",\"pressure\"],B_train),\n",
    "        LHFnsDELQ_train=([\"samples_both\",\"pressure\"],LHFnsDELQ_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord = dict(\n",
    "        pressure_midlevel=([\"pressure\"],np.mean(pm,axis=0)),\n",
    "        pressure_interfac=([\"pressure_interface\"],np.mean(pi,axis=0)),\n",
    "        samples_mixed=([\"samples_both\"],np.arange(0,RH_train.shape[0]))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = xr.Dataset(\n",
    "    data_vars=data,\n",
    "    coords=coord,\n",
    "    attrs=dict(description=\"RH, B, and LHF_nsDELQ calculated using script [098]\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.to_netcdf(path_data+'2022_07_21_RG_B_RH_LHFns_TRAIN_m4K.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
