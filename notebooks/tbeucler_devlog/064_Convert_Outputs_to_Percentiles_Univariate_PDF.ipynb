{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general goal of this notebook is to develop pre-processing scripts that aim to predict percentiles of the outputs's unconditional PDF rather than physical values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cbrain.imports import *\n",
    "from cbrain.data_generator import *\n",
    "from cbrain.cam_constants import *\n",
    "from cbrain.losses import *\n",
    "from cbrain.utils import limit_mem\n",
    "from cbrain.layers import *\n",
    "from cbrain.data_generator import DataGenerator\n",
    "import tensorflow as tf\n",
    "#import tensorflow.math as tfm\n",
    "from tensorflow import math as tfm\n",
    "#import tensorflow_probability as tfp\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from cbrain.model_diagnostics import ModelDiagnostics\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as imag\n",
    "import scipy.integrate as sin\n",
    "#import cartopy.crs as ccrs\n",
    "import matplotlib.ticker as mticker\n",
    "#from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import pickle\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import stats\n",
    "import scipy.integrate as sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fz = 15\n",
    "lw = 4\n",
    "siz = 100\n",
    "S0 = 320 # Representative mean solar insolation for normalization purposes\n",
    "S0max = 1410.6442 # Max solar insolation for normalization purposes\n",
    "SN = S0/100 # Representative target = mean insolation / 4\n",
    "XNNA = 1.25 # Abscissa where architecture-constrained network will be placed\n",
    "XTEXT = 0.25 # Text placement\n",
    "YMIN = -1 # Representative value for conserving network\n",
    "YTEXT = 0.3 # Text placement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('text', usetex=False)\n",
    "mpl.rcParams['mathtext.fontset'] = 'stix'\n",
    "mpl.rcParams['font.family'] = 'STIXGeneral'\n",
    "plt.rc('font', family='serif', size=fz)\n",
    "mpl.rcParams['lines.linewidth'] = lw\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load training set in memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = '/DFS-L/DATA/pritchard/tbeucler/SPCAM/SPCAM_PHYS/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathPKL = '/export/home/tbeucler/CBRAIN-CAM/notebooks/tbeucler_devlog/PKL_DATA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_TRAIN = path_data + '2021_01_24_O3_TRAIN_shuffle.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = xr.open_dataset(path_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['var_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['vars'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['var_names'][-120:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create histogram bins based on max,min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_max = train_data['vars'].max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_min = train_data['vars'].min(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_max[-121]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_min[-121]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_max.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "214-121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_max[94]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_max[93]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_data_min[-120:])\n",
    "plt.plot(train_data_max[-120:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_bins = np.linspace(start=train_data_min,stop=train_data_max,num=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_bins.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_min[-91]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_max[-91]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate quantile for each output variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['vars'][:,-91].quantile(np.array([0,1])).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_array = np.linspace(0,1,1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERC_array = np.zeros((1001,184))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ivar in range(214):\n",
    "    print('ivar=',ivar,'           ',end='\\r')\n",
    "    PERC_array[:,ivar] = train_data['vars'][:,ivar].quantile(quantile_array).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathPKL = '/export/home/tbeucler/CBRAIN-CAM/notebooks/tbeucler_devlog/PKL_DATA'\n",
    "\n",
    "hf = open(pathPKL+'2021_01_24_O3_TRAIN_shuffle'+'_PERC.pkl','wb')\n",
    "\n",
    "F_data = {'quantile_array':quantile_array,'PERC_array':PERC_array}\n",
    "\n",
    "pickle.dump(F_data,hf)\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_data['PERC_array'][:,-91]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat for every dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathPKL = '/export/home/tbeucler/CBRAIN-CAM/notebooks/tbeucler_devlog/PKL_DATA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_array = np.linspace(0,1,1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_array = [\n",
    "    '2021_06_03_RG_TRAIN_shuffle.nc',\n",
    "    '2021_06_03_RG_VALID.nc',\n",
    "    '2021_06_06_RG_TEST.nc'\n",
    "#    '2021_04_18_RG_TRAIN_M4K_shuffle.nc',\n",
    "#     '2021_04_18_RG_VALID_M4K.nc',\n",
    "#     '2021_04_18_RG_TEST_M4K.nc',\n",
    "#     '2021_04_18_RG_TRAIN_P4K_shuffle.nc',\n",
    "#     '2021_04_18_RG_VALID_P4K.nc',\n",
    "#     '2021_04_18_RG_TEST_P4K.nc'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_array = [\n",
    "#     '2021_03_18_O3_TRAIN_M4K_shuffle.nc',\n",
    "#     '2021_03_18_O3_VALID_M4K.nc',\n",
    "#     '2021_03_18_O3_TEST_P4K.nc',\n",
    "#     '2021_01_24_O3_TRAIN_shuffle.nc',\n",
    "#     '2021_03_18_O3_TEST_M4K.nc',\n",
    "#     '2021_01_24_O3_VALID.nc',\n",
    "#     '2021_01_24_O3_TEST.nc',\n",
    "#     '2021_03_18_O3_TRAIN_P4K_shuffle.nc',\n",
    "#    '2021_03_18_O3_VALID_P4K.nc'\n",
    "#]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ninput = 184"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ninput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ipath,path in enumerate(path_array):\n",
    "    print('ipath=',ipath,'path=',path,'     ',end='\\n')\n",
    "    \n",
    "    path_var = path_data + path \n",
    "    train_data = xr.open_dataset(path_var)\n",
    "    \n",
    "    PERC_array = np.zeros((1001,Ninput))\n",
    "    \n",
    "    for ivar in range(Ninput):\n",
    "        print('ivar=',ivar,'           ',end='\\r')\n",
    "        PERC_array[:,ivar] = train_data['vars'][:,ivar].quantile(quantile_array).values\n",
    "    \n",
    "    hf = open(pathPKL+'/'+path+'_PERC.pkl','wb')\n",
    "\n",
    "    F_data = {'quantile_array':quantile_array,'PERC_array':PERC_array}\n",
    "\n",
    "    pickle.dump(F_data,hf)\n",
    "    hf.close()\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test interpolation onto percentile array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directly test in preprocessing mode to facilitate duplication of training/validation/test in percentile space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing different interpolation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathPKL = '/export/home/tbeucler/CBRAIN-CAM/notebooks/tbeucler_devlog/PKL_DATA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathPKL_train = pathPKL + '/PKL_DATA2021_03_18_O3_TRAIN_M4K_shuffle.nc_PERC.pkl'\n",
    "pathPKL_test = pathPKL + '/PKL_DATA2021_03_18_O3_TEST_P4K.nc_PERC.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = open(pathPKL_train,'rb')\n",
    "tmp = pickle.load(hf)\n",
    "PERC_array = tmp['PERC_array']\n",
    "quantile_array = tmp['quantile_array']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERC_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load small data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dm4K = '/DFS-L/DATA/pritchard/tbeucler/SPCAM/sp8fbp_minus4k/sp8fbp_minus4k.cam2.h2.'\n",
    "ds = xr.open_mfdataset(path_dm4K+'0001-01-05-00000.nc',\\\n",
    "                          decode_times=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var0 = ds['PHQ'][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class scipy.interpolate.interp1d(x, y, kind='linear', axis=- 1, copy=True, bounds_error=None, fill_value=nan, assume_sorted=False)[source]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_interp = interp1d(x=PERC_array[:,-91],y=quantile_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_dict = load_pickle('/export/home/tbeucler/CBRAIN-CAM/nn_config/scale_dicts/009_Wm2_scaling.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_dict['PHQ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(scale_dict['PHQ'][-1]*PERC_array[:,-91],bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var0_afterinterp = var_interp(var0[:,-1,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var0_afterinterp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(var0_afterinterp.flatten(),bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dm4K = '/DFS-L/DATA/pritchard/tbeucler/SPCAM/sp8fbp_minus4k/sp8fbp_minus4k.cam2.h2.'\n",
    "ds = xr.open_mfdataset(path_dm4K+'0001-03-22-00000.nc',\\\n",
    "                          decode_times=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((var_interp(ds['PHQ'][:,-1,:,:])).flatten(),bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_interp = interp1d(x=PERC_array[:,-1],y=quantile_array,fill_value=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_interp._extrapolate='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((var_interp(ds['QRS'][:,-1,:,:])).flatten(),bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_interp = interp1d(x=PERC_array[:,-31],y=quantile_array,fill_value=(0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.hist((var_interp(ds['QRL'][:,-1,:,:])).flatten(),bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check with original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_array = [\n",
    "#    '2021_03_18_O3_TRAIN_M4K_shuffle.nc',\n",
    "#    '2021_03_18_O3_VALID_M4K.nc',\n",
    "    '2021_03_18_O3_TEST_P4K.nc',\n",
    "#    '2021_01_24_O3_TRAIN_shuffle.nc',\n",
    "#    '2021_03_18_O3_TEST_M4K.nc',\n",
    "#    '2021_01_24_O3_VALID.nc',\n",
    "#    '2021_01_24_O3_TEST.nc',\n",
    "#    '2021_03_18_O3_TRAIN_P4K_shuffle.nc',\n",
    "#    '2021_03_18_O3_VALID_P4K.nc'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ipath,path in enumerate(path_array):\n",
    "    print('ipath=',ipath,'path=',path,'     ',end='\\n')\n",
    "    \n",
    "    path_var = path_data + path \n",
    "    train_data = xr.open_dataset(path_var)\n",
    "    \n",
    "    hf = open(pathPKL+'/'+path+'_PERC.pkl','rb')\n",
    "    tmp = pickle.load(hf)\n",
    "    \n",
    "    PERC_array = tmp['PERC_array']\n",
    "    quantile_array = tmp['quantile_array']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_fx = interp1d(x=PERC_array[:,-91],y=quantile_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((interp_fx(train_data['vars'][:,-91])).flatten(),bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Develop preprocessing routine for convert_dataset_20191113"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO = Test\n",
    "def compute_perc(ds, var, PERC_array, quantile_array):\n",
    "    \n",
    "    from scipy.interpolate import interp1d\n",
    "    \n",
    "    # Load variable from dataset\n",
    "    var0 = ds[var[:-4]][1:]\n",
    "    # Manually entering ranges for each variable: \n",
    "    # This should change and PERC_array should be a dictionary with varianble names\n",
    "    i0 = {}\n",
    "    i0['PHQ'] = 94\n",
    "    i0['TPHYSTND'] = 124\n",
    "    i0['QRL'] = 154\n",
    "    i0['QRS'] = 184\n",
    "    \n",
    "    # Project onto 1D percentile space to form the output\n",
    "    output_percentile = 0*var0**0 # Initialization\n",
    "    for ilev in range(var0.shape[1]):\n",
    "        print('Interpolating level ',ilev,'out of ',var0.shape[1])\n",
    "        interp_fx = interp1d(x=PERC_array[:,i0[var[:-4]]+ilev,:,:],y=quantile_array)\n",
    "        output_percentile[:,ilev,:,:] = interp_fx(var0[:,ilev,:,:])\n",
    "        \n",
    "    return output_percentile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_PERC = pathPKL+'/'+'2021_03_18_O3_TRAIN_M4K_shuffle.nc'+'_PERC.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_PERC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "hf = open(path_PERC,'rb')\n",
    "tmp = pickle.load(hf)\n",
    "PERC_array = tmp['PERC_array']\n",
    "quantile_array = tmp['quantile_array']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_m4K_file = '/DFS-L/DATA/pritchard/tbeucler/SPCAM//sp8fbp_minus4k/sp8fbp_minus4k.cam2.h2.00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datam4K = xr.open_mfdataset(path_m4K_file+'01-06-1*-00000.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'QRLPERC'\n",
    "ds = datam4K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var0 = ds[var[:-4]][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i0 = {}\n",
    "i0['PHQ'] = 94\n",
    "i0['TPHYSTND'] = 124\n",
    "i0['QRL'] = 154\n",
    "i0['QRS'] = 184"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_percentile = 0*var0**0 # Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = var0.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilev = 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_fx = interp1d(x=PERC_array[:,i0[var[:-4]]+ilev],y=quantile_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_fx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var0[:,ilev,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var0_interp = interp_fx(var0[:,ilev,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,3,figsize=(15,5))\n",
    "ax[0].hist(var0[:,ilev,:,:].values.flatten(),bins=100);\n",
    "ax[1].hist(PERC_array[:,i0[var[:-4]]+ilev],bins=100);\n",
    "#ax[2].hist(var0_interp.flatten(),bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERC_array[:,i0[var[:-4]]+ilev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project onto 1D percentile space to form the output\n",
    "output_percentile = np.zeros(var0.shape) # Initialization\n",
    "for ilev in range(var0.shape[1]):\n",
    "    print('Interpolating level ',ilev,'out of ',var0.shape[1])\n",
    "    interp_fx = interp1d(x=PERC_array[:,i0[var[:-4]]+ilev],y=quantile_array,bounds_error=False)\n",
    "    output_percentile[:,ilev,:,:] = interp_fx(var0[:,ilev,:,:].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_percentile = output_percentile+0*var0**0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var0[:,ilev,:,:].values.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERC_array[:,i0[var[:-4]]+ilev].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilev = 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,3,figsize=(15,5))\n",
    "ax[0].hist(var0[:,ilev,:,:].values.flatten(),bins=100);\n",
    "ax[1].hist(PERC_array[:,i0[var[:-4]]+ilev],bins=100);\n",
    "ax[2].hist(output_percentile[:,ilev,:,:].values.flatten(),bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Distributions Figure for final postdoc talks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Font size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fz = 40\n",
    "lw = 6\n",
    "siz = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('text', usetex=False)\n",
    "mpl.rcParams['mathtext.fontset'] = 'stix'\n",
    "mpl.rcParams['font.family'] = 'STIXGeneral'\n",
    "plt.rc('font', family='serif', size=fz)\n",
    "mpl.rcParams['lines.linewidth'] = lw\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load coordinates (just pick any file from the climate model run)\n",
    "\n",
    "# Comet path below\n",
    "# coor = xr.open_dataset(\"/oasis/scratch/comet/ankitesh/temp_project/data/sp8fbp_minus4k.cam2.h1.0000-01-01-00000.nc\",\\\n",
    "#                     decode_times=False)\n",
    "\n",
    "# GP path below\n",
    "path_0K = '/DFS-L/DATA/pritchard/tbeucler/SPCAM/fluxbypass_aqua/'\n",
    "coor = xr.open_dataset(path_0K+\"AndKua_aqua_SPCAM3.0_sp_fbp_f4.cam2.h1.0000-09-02-00000.nc\")\n",
    "\n",
    "lat = coor.lat; lon = coor.lon; lev = coor.lev;\n",
    "coor.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comet path below\n",
    "# TRAINDIR = '/oasis/scratch/comet/ankitesh/temp_project/PrepData/CRHData/'\n",
    "# path = '/home/ankitesh/CBrain_project/CBRAIN-CAM/cbrain/'\n",
    "\n",
    "# GP path below\n",
    "TRAINDIR = '/DFS-L/DATA/pritchard/tbeucler/SPCAM/SPCAM_PHYS/'\n",
    "path = '/export/nfs0home/tbeucler/CBRAIN-CAM/cbrain/'\n",
    "path_nnconfig = '/export/nfs0home/tbeucler/CBRAIN-CAM/nn_config/'\n",
    "\n",
    "# Load hyam and hybm to calculate pressure field in SPCAM\n",
    "path_hyam = 'hyam_hybm.pkl'\n",
    "hf = open(path+path_hyam,'rb')\n",
    "hyam,hybm = pickle.load(hf)\n",
    "\n",
    "# Scale dictionary to convert the loss to W/m2\n",
    "scale_dict = load_pickle(path_nnconfig+'scale_dicts/009_Wm2_scaling.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coor.lev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_array = [\n",
    "     '2021_03_18_O3_TRAIN_M4K_shuffle.nc',\n",
    "#    '2021_03_18_O3_VALID_M4K.nc',\n",
    "#    '2021_03_18_O3_TEST_P4K.nc',\n",
    "#    '2021_01_24_O3_TRAIN_shuffle.nc',\n",
    "#    '2021_03_18_O3_TEST_M4K.nc',\n",
    "#    '2021_01_24_O3_VALID.nc',\n",
    "#    '2021_01_24_O3_TEST.nc',\n",
    "     '2021_03_18_O3_TRAIN_P4K_shuffle.nc',\n",
    "#    '2021_03_18_O3_VALID_P4K.nc'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = '/DFS-L/DATA/pritchard/tbeucler/SPCAM/SPCAM_PHYS/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathPKL = '/export/home/tbeucler/CBRAIN-CAM/notebooks/tbeucler_devlog/PKL_DATA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ipath,path in enumerate(path_array):\n",
    "    print('ipath=',ipath,'path=',path,'     ',end='\\n')\n",
    "    \n",
    "    path_var = path_data + path \n",
    "    train_data[path] = xr.open_dataset(path_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "136430485504/1e9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of q vs RH at different levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bp(ds, var):\n",
    "    \"\"\"GCM state at beginning of time step before physics.\n",
    "    ?BP = ?AP - physical tendency * dt\n",
    "\n",
    "    Args:\n",
    "        ds: entire xarray dataset\n",
    "        var: BP variable name\n",
    "\n",
    "    Returns:\n",
    "        bp: xarray dataarray containing just BP variable, with the first time step cut.\n",
    "    \"\"\"\n",
    "    base_var = var[:-2] + 'AP'\n",
    "    return (ds[base_var] - ds[phy_dict[base_var]] * DT)[1:]  # Not the first time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edg2bin(bin_edges):\n",
    "    return 0.5*(bin_edges[1:]+bin_edges[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RH(T,qv,P0,PS,hyam,hybm):\n",
    "    R = 287\n",
    "    Rv = 461\n",
    "    p = (hyam*P0+hybm*PS) # Total pressure (Pa)\n",
    "    return Rv*p*qv/(R*esat(T))\n",
    "def esat(T):\n",
    "    T0 = 273.16\n",
    "    T00 = 253.16\n",
    "    omega = np.maximum(0,np.minimum(1,(T-T00)/(T0-T00)))\n",
    "\n",
    "    return (T>T0)*eliq(T)+(T<T00)*eice(T)+(T<=T0)*(T>=T00)*(omega*eliq(T)+(1-omega)*eice(T))\n",
    "def eliq(T):\n",
    "    a_liq = np.array([-0.976195544e-15,-0.952447341e-13,0.640689451e-10,0.206739458e-7,0.302950461e-5,0.264847430e-3,0.142986287e-1,0.443987641,6.11239921]);\n",
    "    c_liq = -80\n",
    "    T0 = 273.16\n",
    "    return 100*np.polyval(a_liq,np.maximum(c_liq,T-T0))\n",
    "def eice(T):\n",
    "    a_ice = np.array([0.252751365e-14,0.146898966e-11,0.385852041e-9,0.602588177e-7,0.615021634e-5,0.420895665e-3,0.188439774e-1,0.503160820,6.11147274]);\n",
    "    c_ice = np.array([273.15,185,-100,0.00763685,0.000151069,7.48215e-07])\n",
    "    T0 = 273.16\n",
    "    return (T>c_ice[0])*eliq(T)+\\\n",
    "(T<=c_ice[0])*(T>c_ice[1])*100*np.polyval(a_ice,T-T0)+\\\n",
    "(T<=c_ice[1])*100*(c_ice[3]+np.maximum(c_ice[2],T-T0)*(c_ice[4]+np.maximum(c_ice[2],T-T0)*c_ice[5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['2021_03_18_O3_TRAIN_M4K_shuffle.nc']['vars'][:,90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coor.lev[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = train_data['2021_03_18_O3_TRAIN_M4K_shuffle.nc']['vars'][:,19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histQm4K,edgm4K = np.histogram(a, bins=100, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = train_data['2021_03_18_O3_TRAIN_P4K_shuffle.nc']['vars'][:,19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histQp4K,edgp4K = np.histogram(a, bins=100, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aT = train_data['2021_03_18_O3_TRAIN_M4K_shuffle.nc']['vars'][:,49]\n",
    "aq = train_data['2021_03_18_O3_TRAIN_M4K_shuffle.nc']['vars'][:,19]\n",
    "aPS = train_data['2021_03_18_O3_TRAIN_M4K_shuffle.nc']['vars'][:,90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('T')\n",
    "aT = aT.values\n",
    "print('q')\n",
    "aq = aq.values\n",
    "print('PS')\n",
    "aPS = aPS.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = RH(aT,aq,P0,aPS,hyam[19],hybm[19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histRHm4K,edgm4K_RH = np.histogram(a, bins=100, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aT = train_data['2021_03_18_O3_TRAIN_P4K_shuffle.nc']['vars'][:,49]\n",
    "aq = train_data['2021_03_18_O3_TRAIN_P4K_shuffle.nc']['vars'][:,19]\n",
    "aPS = train_data['2021_03_18_O3_TRAIN_P4K_shuffle.nc']['vars'][:,90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('T')\n",
    "aT = aT.values\n",
    "print('q')\n",
    "aq = aq.values\n",
    "print('PS')\n",
    "aPS = aPS.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = RH(aT,aq,P0,aPS,hyam[19],hybm[19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histRHP4K,edgP4K_RH = np.histogram(a, bins=100, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(2,1,figsize=(15,15))\n",
    "\n",
    "plt.subplots_adjust(wspace=None, hspace=-0.025)\n",
    "\n",
    "# Top subplot = Specific humidity\n",
    "ax[0].plot(edg2bin(edgm4K),histQm4K,color='b')\n",
    "ax[0].plot(edg2bin(edgp4K),histQp4K,color='r')\n",
    "ax[0].yaxis.tick_right()\n",
    "#ax[0].set_xlabel('Specific humidity (kg kg$^{-1}$)')\n",
    "ax[0].xaxis.tick_top()\n",
    "ax[0].set_title('Specific humidity (kg kg$^{-1}$)')\n",
    "\n",
    "# Bottom subplot = Relative humidity\n",
    "ax[1].plot(edg2bin(edgm4K_RH),histRHm4K,color='b')\n",
    "ax[1].plot(edg2bin(edgP4K_RH),histRHP4K,color='r')\n",
    "ax[1].yaxis.tick_right()\n",
    "ax[1].set_xlabel('Relative humidity')\n",
    "#ax[1].set_title('PDF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of T vs BCONS at different levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def esat(T):\n",
    "    T0 = 273.16\n",
    "    T00 = 253.16\n",
    "    omega = np.maximum(0,np.minimum(1,(T-T00)/(T0-T00)))\n",
    "\n",
    "    return (T>T0)*eliq(T)+(T<T00)*eice(T)+(T<=T0)*(T>=T00)*(omega*eliq(T)+(1-omega)*eice(T))\n",
    "def eliq(T):\n",
    "    a_liq = np.array([-0.976195544e-15,-0.952447341e-13,0.640689451e-10,0.206739458e-7,0.302950461e-5,0.264847430e-3,0.142986287e-1,0.443987641,6.11239921]);\n",
    "    c_liq = -80\n",
    "    T0 = 273.16\n",
    "    return 100*np.polyval(a_liq,np.maximum(c_liq,T-T0))\n",
    "def eice(T):\n",
    "    a_ice = np.array([0.252751365e-14,0.146898966e-11,0.385852041e-9,0.602588177e-7,0.615021634e-5,0.420895665e-3,0.188439774e-1,0.503160820,6.11147274]);\n",
    "    c_ice = np.array([273.15,185,-100,0.00763685,0.000151069,7.48215e-07])\n",
    "    T0 = 273.16\n",
    "    return (T>c_ice[0])*eliq(T)+\\\n",
    "(T<=c_ice[0])*(T>c_ice[1])*100*np.polyval(a_ice,T-T0)+\\\n",
    "(T<=c_ice[1])*100*(c_ice[3]+np.maximum(c_ice[2],T-T0)*(c_ice[4]+np.maximum(c_ice[2],T-T0)*c_ice[5]))\n",
    "\n",
    "def qv(T,RH,P0,PS,hyam,hybm):\n",
    "    R = 287\n",
    "    Rv = 461\n",
    "    p = (hyam*P0+hybm*PS) # Total pressure (Pa)\n",
    "\n",
    "    return R*esat(T)*RH/(Rv*p)\n",
    "\n",
    "def qsat(T,P0,PS,hyam,hybm):\n",
    "    return qv(T,1,P0,PS,hyam,hybm)\n",
    "\n",
    "def theta_e_calc(T,qv,P0,PS,hyam,hybm):\n",
    "    p = (hyam*P0+hybm*PS) # Total pressure (Pa)\n",
    "\n",
    "    tmelt  = 273.15\n",
    "    CPD = 1005.7\n",
    "    CPV = 1870.0\n",
    "    CPVMCL = 2320.0\n",
    "    RV = 461.5\n",
    "    RD = 287.04\n",
    "    EPS = RD/RV\n",
    "    ALV0 = 2.501E6\n",
    "\n",
    "    r = qv / (1. - qv)\n",
    "    # get ev in hPa \n",
    "    ev_hPa = 100*p*r/(EPS+r)\n",
    "    #get TL\n",
    "    TL = (2840. / ((3.5*np.log(T)) - (np.log(ev_hPa)) - 4.805)) + 55.\n",
    "    #calc chi_e:\n",
    "    chi_e = 0.2854 * (1. - (0.28*r))\n",
    "    P0_norm = (P0/(hyam*P0+hybm*PS))\n",
    "\n",
    "    theta_e = T * P0_norm**chi_e * np.exp(((3.376/TL) - 0.00254) * r * 1000. * (1. + (0.81 * r)))\n",
    "\n",
    "    return theta_e\n",
    "\n",
    "def theta_e_sat_calc(T,qv,P0,PS,hyam,hybm):\n",
    "    return theta_e_calc(T,qsat(T,P0,PS,hyam,hybm),P0,PS,hyam,hybm)\n",
    "\n",
    "# TBP = compute_bp(ds,'TBP')\n",
    "# QBP = compute_bp(ds,'QBP')\n",
    "\n",
    "# return G*(theta_e_calc(TBP,QBP,ds['P0'],ds['PS'][1:,:,:],ds['hyam'],ds['hybm'])[:,-1,:,:]-\\\n",
    "#           theta_e_sat_calc(TBP,QBP,ds['P0'],ds['PS'][1:,:,:],ds['hyam'],ds['hybm']))/\\\n",
    "# theta_e_sat_calc(TBP,QBP,ds['P0'],ds['PS'][1:,:,:],ds['hyam'],ds['hybm'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilev = 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coor.lev[ilev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = train_data['2021_03_18_O3_TRAIN_M4K_shuffle.nc']['vars'][:,30+ilev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histTm4K,edgm4K_T = np.histogram(a, bins=100, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = train_data['2021_03_18_O3_TRAIN_P4K_shuffle.nc']['vars'][:,30+ilev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histTp4K,edgp4K_T = np.histogram(a, bins=100, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aT = train_data['2021_03_18_O3_TRAIN_M4K_shuffle.nc']['vars'][:,30+ilev]\n",
    "aq = train_data['2021_03_18_O3_TRAIN_M4K_shuffle.nc']['vars'][:,ilev]\n",
    "aPS = train_data['2021_03_18_O3_TRAIN_M4K_shuffle.nc']['vars'][:,90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('T')\n",
    "aT = aT.values\n",
    "print('q')\n",
    "aq = aq.values\n",
    "print('PS')\n",
    "aPS = aPS.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aTNS = train_data['2021_03_18_O3_TRAIN_M4K_shuffle.nc']['vars'][:,59]\n",
    "aqNS = train_data['2021_03_18_O3_TRAIN_M4K_shuffle.nc']['vars'][:,29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('T')\n",
    "aTNS = aTNS.values\n",
    "print('q')\n",
    "aqNS = aqNS.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = G*(theta_e_calc(aTNS,aqNS,P0,aPS,hyam[29],hybm[29])-\\\n",
    "   theta_e_sat_calc(aT,aq,P0,aPS,hyam[ilev],hybm[ilev]))/\\\n",
    "theta_e_sat_calc(aT,aq,P0,aPS,hyam[ilev],hybm[ilev])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histBm4K,edgm4K_B = np.histogram(a, bins=100, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aT = train_data['2021_03_18_O3_TRAIN_P4K_shuffle.nc']['vars'][:,30+ilev]\n",
    "aq = train_data['2021_03_18_O3_TRAIN_P4K_shuffle.nc']['vars'][:,ilev]\n",
    "aPS = train_data['2021_03_18_O3_TRAIN_P4K_shuffle.nc']['vars'][:,90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('T')\n",
    "aT = aT.values\n",
    "print('q')\n",
    "aq = aq.values\n",
    "print('PS')\n",
    "aPS = aPS.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aTNS = train_data['2021_03_18_O3_TRAIN_P4K_shuffle.nc']['vars'][:,59]\n",
    "aqNS = train_data['2021_03_18_O3_TRAIN_P4K_shuffle.nc']['vars'][:,29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('T')\n",
    "aTNS = aTNS.values\n",
    "print('q')\n",
    "aqNS = aqNS.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = G*(theta_e_calc(aTNS,aqNS,P0,aPS,hyam[29],hybm[29])-\\\n",
    "   theta_e_sat_calc(aT,aq,P0,aPS,hyam[ilev],hybm[ilev]))/\\\n",
    "theta_e_sat_calc(aT,aq,P0,aPS,hyam[ilev],hybm[ilev])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histBp4K,edgp4K_B = np.histogram(a, bins=100, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(2,1,figsize=(15,15))\n",
    "\n",
    "plt.subplots_adjust(wspace=None, hspace=-0.025)\n",
    "\n",
    "# Top subplot = Specific humidity\n",
    "ax[0].plot(edg2bin(edgm4K_T),histTm4K,color='b')\n",
    "ax[0].plot(edg2bin(edgp4K_T),histTp4K,color='r')\n",
    "ax[0].set_title('Temperature (K)')\n",
    "ax[0].yaxis.tick_right()\n",
    "ax[0].xaxis.tick_top()\n",
    "\n",
    "# Bottom subplot = Relative humidity\n",
    "ax[1].plot(edg2bin(edgm4K_B),histBm4K,color='b')\n",
    "ax[1].plot(edg2bin(edgp4K_B),histBp4K,color='r')\n",
    "ax[1].set_xlabel('Buoyancy (m s$^{-2}$)')\n",
    "ax[1].yaxis.tick_right()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of T vs BMSE at different levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def esat(T):\n",
    "    T0 = 273.16\n",
    "    T00 = 253.16\n",
    "    omega = np.maximum(0,np.minimum(1,(T-T00)/(T0-T00)))\n",
    "\n",
    "    return (T>T0)*eliq(T)+(T<T00)*eice(T)+(T<=T0)*(T>=T00)*(omega*eliq(T)+(1-omega)*eice(T))\n",
    "def eliq(T):\n",
    "    a_liq = np.array([-0.976195544e-15,-0.952447341e-13,0.640689451e-10,0.206739458e-7,0.302950461e-5,0.264847430e-3,0.142986287e-1,0.443987641,6.11239921]);\n",
    "    c_liq = -80\n",
    "    T0 = 273.16\n",
    "    return 100*np.polyval(a_liq,np.maximum(c_liq,T-T0))\n",
    "def eice(T):\n",
    "    a_ice = np.array([0.252751365e-14,0.146898966e-11,0.385852041e-9,0.602588177e-7,0.615021634e-5,0.420895665e-3,0.188439774e-1,0.503160820,6.11147274]);\n",
    "    c_ice = np.array([273.15,185,-100,0.00763685,0.000151069,7.48215e-07])\n",
    "    T0 = 273.16\n",
    "    return (T>c_ice[0])*eliq(T)+\\\n",
    "(T<=c_ice[0])*(T>c_ice[1])*100*np.polyval(a_ice,T-T0)+\\\n",
    "(T<=c_ice[1])*100*(c_ice[3]+np.maximum(c_ice[2],T-T0)*(c_ice[4]+np.maximum(c_ice[2],T-T0)*c_ice[5]))\n",
    "\n",
    "def qv(T,RH,P0,PS,hyam,hybm):\n",
    "    R = 287\n",
    "    Rv = 461\n",
    "#     p = P0 * hyam + PS * hybm\n",
    "#     p = p.astype(np.float32)\n",
    "    S = T.shape;\n",
    "    #print(S)\n",
    "    p = np.moveaxis(np.tile(P0,(30,1)),[0,1],[1,0]) *\\\n",
    "    np.moveaxis(np.tile(hyam,(1,1)),[0,1],[0,1]) + \\\n",
    "    np.moveaxis(np.tile(PS,(30,1)),0,1) * \\\n",
    "    np.moveaxis(np.tile(hybm,(1,1)),[0,1],[0,1])\n",
    "\n",
    "    return R*esat(T)*RH/(Rv*p)\n",
    "\n",
    "def qsat(T,P0,PS,hyam,hybm):\n",
    "    return qv(T,1,P0,PS,hyam,hybm)\n",
    "\n",
    "def bmse_calc(T,qv,P0,PS,hyam,hybm):\n",
    "    eps = 0.622 # Ratio of molecular weight(H2O)/molecular weight(dry air)\n",
    "    R_D = 287 # Specific gas constant of dry air in J/K/kg\n",
    "    Rv = 461\n",
    "    # Calculate kappa\n",
    "    QSAT0 = qsat(T,P0,PS,hyam,hybm)\n",
    "    kappa = (1+(L_V**2)*QSAT0/(Rv*C_P*(T**2))).astype(np.float32)\n",
    "    # Calculate geopotential\n",
    "    r = qv/(qv**0-qv)\n",
    "    Tv = T*(r**0+r/eps)/(r**0+r)\n",
    "#     p = P0 * hyam + PS * hybm\n",
    "#     p = p.astype(np.float32)\n",
    "#     p = (hyam*P0+hybm*PS).values # Total pressure (Pa)\n",
    "    S = Tv.shape;\n",
    "    p = np.moveaxis(np.tile(P0,(30,1)),[0,1],[1,0]) *\\\n",
    "    np.moveaxis(np.tile(hyam,(1,1)),[0,1],[0,1]) + \\\n",
    "    np.moveaxis(np.tile(PS,(30,1)),0,1) * \\\n",
    "    np.moveaxis(np.tile(hybm,(1,1)),[0,1],[0,1])\n",
    "    # Geopotential calculation below\n",
    "    RHO = p/(R_D*Tv)\n",
    "    Z = -sin.cumtrapz(x=p,y=1/(G*RHO),axis=1)\n",
    "    Z = np.concatenate((0*Z[:,0:1]**0,Z),axis=1)\n",
    "    # Assuming near-surface is at 2 meters\n",
    "    Z = (Z-Z[:,[29]])+2 \n",
    "    # Calculate MSEs of plume and environment\n",
    "    Tile_dim = [1,30]\n",
    "    h_plume = (np.tile(np.expand_dims(C_P*T[:,-1]+L_V*qv[:,-1],axis=1),Tile_dim)).astype(np.float32)\n",
    "    h_satenv = (C_P*T+L_V*qv+G*Z).astype(np.float32)\n",
    "    return (G/kappa)*(h_plume-h_satenv)/(C_P*T)\n",
    "\n",
    "# TBP = compute_bp(ds,'TBP')\n",
    "# QBP = compute_bp(ds,'QBP')\n",
    "\n",
    "# return G*(theta_e_calc(TBP,QBP,ds['P0'],ds['PS'][1:,:,:],ds['hyam'],ds['hybm'])[:,-1,:,:]-\\\n",
    "#           theta_e_sat_calc(TBP,QBP,ds['P0'],ds['PS'][1:,:,:],ds['hyam'],ds['hybm']))/\\\n",
    "# theta_e_sat_calc(TBP,QBP,ds['P0'],ds['PS'][1:,:,:],ds['hyam'],ds['hybm'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilev = 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coor.lev[ilev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = train_data['2021_03_18_O3_TRAIN_M4K_shuffle.nc']['vars'][:,30+ilev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histTm4K,edgm4K_T = np.histogram(a, bins=100, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = train_data['2021_03_18_O3_TRAIN_P4K_shuffle.nc']['vars'][:,30+ilev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histTp4K,edgp4K_T = np.histogram(a, bins=100, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aT = train_data['2021_03_18_O3_TRAIN_M4K_shuffle.nc']['vars'][:,30:60]\n",
    "aq = train_data['2021_03_18_O3_TRAIN_M4K_shuffle.nc']['vars'][:,:30]\n",
    "aPS = train_data['2021_03_18_O3_TRAIN_M4K_shuffle.nc']['vars'][:,90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('T')\n",
    "aT = aT.values\n",
    "print('q')\n",
    "aq = aq.values\n",
    "print('PS')\n",
    "aPS = aPS.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dm4K = '/DFS-L/DATA/pritchard/tbeucler/SPCAM/sp8fbp_minus4k/sp8fbp_minus4k.cam2.h2.'\n",
    "ds = xr.open_mfdataset(path_dm4K+'0001-01-05-00000.nc',\\\n",
    "                          decode_times=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['2021_03_18_O3_TRAIN_M4K_shuffle.nc']['vars'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "47177728/(472*1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_mse = np.zeros((47177728, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate bmse in small batches\n",
    "for ibatch in range(471):\n",
    "    print('ibatch=',ibatch,'             ',end='\\r')\n",
    "    aT = train_data['2021_03_18_O3_TRAIN_M4K_shuffle.nc']['vars'][int(ibatch*1e5):int((ibatch+1)*1e5),30:60].values;\n",
    "    aq = train_data['2021_03_18_O3_TRAIN_M4K_shuffle.nc']['vars'][int(ibatch*1e5):int((ibatch+1)*1e5),:30].values;\n",
    "    aPS = train_data['2021_03_18_O3_TRAIN_M4K_shuffle.nc']['vars'][int(ibatch*1e5):int((ibatch+1)*1e5),90].values;\n",
    "    print('Done loading the arrays       ',end='\\r')\n",
    "    a = bmse_calc(aT,aq,P0,aPS,hyam,hybm);\n",
    "    b_mse[int(ibatch*1e5):int((ibatch+1)*1e5),:] = a;\n",
    "print('Final index')\n",
    "aT = train_data['2021_03_18_O3_TRAIN_M4K_shuffle.nc']['vars'][int((ibatch+1)*1e5):,30:60];\n",
    "aq = train_data['2021_03_18_O3_TRAIN_M4K_shuffle.nc']['vars'][int((ibatch+1)*1e5):,:30];\n",
    "aPS = train_data['2021_03_18_O3_TRAIN_M4K_shuffle.nc']['vars'][int((ibatch+1)*1e5):,90];\n",
    "print('Done loading the arrays       ',end='\\r')\n",
    "a = bmse_calc(aT,aq,P0,aPS,hyam,hybm)\n",
    "b_mse[int((ibatch+1)*1e5):,:] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_notload = bmse_calc(train_data['2021_03_18_O3_TRAIN_M4K_shuffle.nc']['vars'][:,30:60],\n",
    "#                       train_data['2021_03_18_O3_TRAIN_M4K_shuffle.nc']['vars'][:,:30],\n",
    "#                       P0,\n",
    "#                       train_data['2021_03_18_O3_TRAIN_M4K_shuffle.nc']['vars'][:,90],\n",
    "#                       coor['hyam'],coor['hybm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = bmse_calc(aT,aq,P0,aPS,hyam,hybm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histBm4K,edgm4K_B = np.histogram(b_mse[:,ilev], bins=100, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_mse = np.zeros((47177728, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['2021_03_18_O3_TRAIN_P4K_shuffle.nc']['vars'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate bmse in small batches\n",
    "for ibatch in range(471):\n",
    "    print('ibatch=',ibatch,'             ',end='\\r')\n",
    "    aT = train_data['2021_03_18_O3_TRAIN_P4K_shuffle.nc']['vars'][int(ibatch*1e5):int((ibatch+1)*1e5),30:60].values;\n",
    "    aq = train_data['2021_03_18_O3_TRAIN_P4K_shuffle.nc']['vars'][int(ibatch*1e5):int((ibatch+1)*1e5),:30].values;\n",
    "    aPS = train_data['2021_03_18_O3_TRAIN_P4K_shuffle.nc']['vars'][int(ibatch*1e5):int((ibatch+1)*1e5),90].values;\n",
    "    print('Done loading the arrays       ',end='\\r')\n",
    "    a = bmse_calc(aT,aq,P0,aPS,hyam,hybm);\n",
    "    b_mse[int(ibatch*1e5):int((ibatch+1)*1e5),:] = a;\n",
    "print('Final index')\n",
    "aT = train_data['2021_03_18_O3_TRAIN_P4K_shuffle.nc']['vars'][int((ibatch+1)*1e5):,30:60];\n",
    "aq = train_data['2021_03_18_O3_TRAIN_P4K_shuffle.nc']['vars'][int((ibatch+1)*1e5):,:30];\n",
    "aPS = train_data['2021_03_18_O3_TRAIN_P4K_shuffle.nc']['vars'][int((ibatch+1)*1e5):,90];\n",
    "print('Done loading the arrays       ',end='\\r')\n",
    "a = bmse_calc(aT,aq,P0,aPS,hyam,hybm)\n",
    "b_mse[int((ibatch+1)*1e5):,:] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmse_calc(aT,aq,P0,aPS,hyam,hybm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_mse[int((ibatch+1)*1e5):,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histBp4K,edgp4K_B = np.histogram(a[ilev], bins=100, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(2,1,figsize=(15,15))\n",
    "\n",
    "plt.subplots_adjust(wspace=None, hspace=-0.025)\n",
    "\n",
    "# Top subplot = Specific humidity\n",
    "# ax[0].plot(edg2bin(edgm4K_T),histTm4K,color='b')\n",
    "# ax[0].plot(edg2bin(edgp4K_T),histTp4K,color='r')\n",
    "# ax[0].set_title('Temperature (K)')\n",
    "# ax[0].yaxis.tick_right()\n",
    "# ax[0].xaxis.tick_top()\n",
    "\n",
    "# Bottom subplot = Relative humidity\n",
    "ax[1].plot(edg2bin(edgm4K_B),histBm4K,color='b')\n",
    "ax[1].plot(edg2bin(edgp4K_B),histBp4K,color='r')\n",
    "ax[1].set_xlabel('Buoyancy (m s$^{-2}$)')\n",
    "ax[1].yaxis.tick_right()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_data = {'edgm4K_B':edgm4K_B,'histBm4K':histBm4K,'edgp4K_B':edgp4K_B,'histBp4K':histBp4K}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '2021_06_17_distributions_BMSE'\n",
    "\n",
    "hf = open(pathPKL+'/'+path+'.pkl','rb')\n",
    "\n",
    "test = pickle.load(hf)\n",
    "hf.close()\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of LHF vs LHF/nsDELQ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['2021_03_18_O3_TRAIN_M4K_shuffle.nc']['vars'][:,93]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aLHF = train_data['2021_03_18_O3_TRAIN_M4K_shuffle.nc']['vars'][:,93]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aLHF = aLHF.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histLHFm4K,edgm4K_LHF = np.histogram(aLHF, bins=100, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aLHF = train_data['2021_03_18_O3_TRAIN_P4K_shuffle.nc']['vars'][:,93]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aLHF = aLHF.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histLHFp4K,edgp4K_LHF = np.histogram(aLHF, bins=100, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def esat(T):\n",
    "    T0 = 273.16\n",
    "    T00 = 253.16\n",
    "    omega = np.maximum(0,np.minimum(1,(T-T00)/(T0-T00)))\n",
    "\n",
    "    return (T>T0)*eliq(T)+(T<T00)*eice(T)+(T<=T0)*(T>=T00)*(omega*eliq(T)+(1-omega)*eice(T))\n",
    "\n",
    "def eliq(T):\n",
    "    a_liq = np.array([-0.976195544e-15,-0.952447341e-13,0.640689451e-10,0.206739458e-7,0.302950461e-5,0.264847430e-3,0.142986287e-1,0.443987641,6.11239921]);\n",
    "    c_liq = -80\n",
    "    T0 = 273.16\n",
    "    return 100*np.polyval(a_liq,np.maximum(c_liq,T-T0))\n",
    "\n",
    "def eice(T):\n",
    "    a_ice = np.array([0.252751365e-14,0.146898966e-11,0.385852041e-9,0.602588177e-7,0.615021634e-5,0.420895665e-3,0.188439774e-1,0.503160820,6.11147274]);\n",
    "    c_ice = np.array([273.15,185,-100,0.00763685,0.000151069,7.48215e-07])\n",
    "    T0 = 273.16\n",
    "    return (T>c_ice[0])*eliq(T)+\\\n",
    "(T<=c_ice[0])*(T>c_ice[1])*100*np.polyval(a_ice,T-T0)+\\\n",
    "(T<=c_ice[1])*100*(c_ice[3]+np.maximum(c_ice[2],T-T0)*(c_ice[4]+np.maximum(c_ice[2],T-T0)*c_ice[5]))\n",
    "\n",
    "def qv(T,RH,P0,PS,hyam,hybm):\n",
    "    R = 287\n",
    "    Rv = 461\n",
    "    p = (hyam*P0+hybm*PS) # Total pressure (Pa)\n",
    "\n",
    "    return R*esat(T)*RH/(Rv*p)\n",
    "\n",
    "def qsat(T,P0,PS,hyam,hybm):\n",
    "    return qv(T,1,P0,PS,hyam,hybm)\n",
    "\n",
    "# QBP = compute_bp(ds,'QBP')\n",
    "# Qden = qsat(ds['TS'][1:,:,:],ds['P0'],ds['PS'][1:,:,:],ds['hyam'][:,-1],ds['hybm'][:,-1])-QBP[:,-1,:,:].values\n",
    "# return ds['LHFLX'][:-1]/(L_V*np.maximum(eps,Qden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aTNS = train_data['2021_03_18_O3_TRAIN_M4K_shuffle.nc']['vars'][:,59]\n",
    "aqNS = train_data['2021_03_18_O3_TRAIN_M4K_shuffle.nc']['vars'][:,29]\n",
    "aPS = train_data['2021_03_18_O3_TRAIN_M4K_shuffle.nc']['vars'][:,90]\n",
    "aLHF = train_data['2021_03_18_O3_TRAIN_M4K_shuffle.nc']['vars'][:,93]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('T')\n",
    "aTNS = aTNS.values\n",
    "print('q')\n",
    "aqNS = aqNS.values\n",
    "print('PS')\n",
    "aPS = aPS.values\n",
    "print('LHF')\n",
    "aLHF = aLHF.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = aLHF/(L_V*np.maximum(1e-3,(qsat(aTNS,P0,aPS,hyam[-1],hybm[-1])-aqNS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histLHFnm4K,edgm4K_LHFn = np.histogram(a, bins=100, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aTNS = train_data['2021_03_18_O3_TRAIN_P4K_shuffle.nc']['vars'][:,59]\n",
    "aqNS = train_data['2021_03_18_O3_TRAIN_P4K_shuffle.nc']['vars'][:,29]\n",
    "aPS = train_data['2021_03_18_O3_TRAIN_P4K_shuffle.nc']['vars'][:,90]\n",
    "aLHF = train_data['2021_03_18_O3_TRAIN_P4K_shuffle.nc']['vars'][:,93]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('T')\n",
    "aTNS = aTNS.values\n",
    "print('q')\n",
    "aqNS = aqNS.values\n",
    "print('PS')\n",
    "aPS = aPS.values\n",
    "print('LHF')\n",
    "aLHF = aLHF.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = aLHF/(L_V*np.maximum(1e-3,(qsat(aTNS,P0,aPS,hyam[-1],hybm[-1])-aqNS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histLHFnp4K,edgp4K_LHFn = np.histogram(a, bins=100, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(2,1,figsize=(15,15))\n",
    "\n",
    "plt.subplots_adjust(wspace=None, hspace=-0.025)\n",
    "\n",
    "# Top subplot = Specific humidity\n",
    "ax[0].plot(edg2bin(edgm4K_LHF),np.log10(histLHFm4K),color='b')\n",
    "ax[0].plot(edg2bin(edgp4K_LHF),np.log10(histLHFp4K),color='r')\n",
    "ax[0].set_title('Latent Heat Flux (W m$^{-2}$)')\n",
    "ax[0].yaxis.tick_right()\n",
    "ax[0].xaxis.tick_top()\n",
    "#ax[0].set_title('PDF')\n",
    "\n",
    "#Bottom subplot = Relative humidity\n",
    "ax[1].plot(edg2bin(test['edgm4K_LHFn']),np.log10(test['histLHFnm4K']),color='b')\n",
    "ax[1].plot(edg2bin(test['edgp4K_LHFn']),np.log10(test['histLHFnp4K']),color='r')\n",
    "ax[1].set_xlabel('Normalized LHF (kg m$^{-2}$ s$^{-1}$)')\n",
    "ax[1].yaxis.tick_right()\n",
    "ax[1].set_title('PDF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save all histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_data = {'edgm4K':edgm4K,'histQm4K':histQm4K,'edgp4K':edgp4K,'histQp4K':histQp4K,'edgm4K_RH':edgm4K_RH,\n",
    "          'histRHm4K':histRHm4K,'edgP4K_RH':edgP4K_RH,'histRHP4K':histRHP4K,'edgm4K_T':edgm4K_T,\n",
    "          'histTm4K':histTm4K,'edgp4K_T':edgp4K_T,'histTp4K':histTp4K,'edgm4K_B':edgm4K_B,\n",
    "          'histBm4K':histBm4K,'edgp4K_B':edgp4K_B,'histBp4K':histBp4K,'edgm4K_LHF':edgm4K_LHF,\n",
    "          'histTm4K':histTm4K,'edgp4K_LHF':edgp4K_LHF,'histTp4K':histTp4K,'edgm4K_LHFn':edgm4K_LHFn,\n",
    "          'histLHFnm4K':histLHFnm4K,'edgp4K_LHFn':edgp4K_LHFn,'histLHFnp4K':histLHFnp4K}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '2021_06_17_distributions_RH_BMSE_LHFn'\n",
    "\n",
    "hf = open(pathPKL+'/'+path+'.pkl','rb')\n",
    "\n",
    "test = pickle.load(hf)\n",
    "hf.close()\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make loss vs time figure for final postdoc talks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_PKL = '/export/nfs0home/tbeucler/CBRAIN-CAM/notebooks/tbeucler_devlog/PKL_DATA/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_MLR_BF = path_PKL + 'PKL_DATA2021_04_26_MLR_hist.pkl'\n",
    "hf = open(path_MLR_BF,'rb')\n",
    "hist_MLR_BF = pickle.load(hf)\n",
    "hist_MLR_BF = hist_MLR_BF['hist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_NN_BF1 = path_PKL + 'PKL_DATA2021_04_26_NN_hist.pkl'\n",
    "path_NN_BF2 = path_PKL + 'PKL_DATA2021_05_04_NN_hist.pkl'\n",
    "\n",
    "hf = open(path_NN_BF1,'rb')\n",
    "hist_NN_BF1 = pickle.load(hf)\n",
    "hist_NN_BF1 = hist_NN_BF1['hist']\n",
    "\n",
    "hf = open(path_NN_BF2,'rb')\n",
    "hist_NN_BF2 = pickle.load(hf)\n",
    "hist_NN_BF2 = hist_NN_BF2['hist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_MLR_CI = path_PKL + 'PKL_DATA2021_04_26_MLR_RH_BCONS_LHF_nsDELQ_hist.pkl'\n",
    "hf = open(path_MLR_CI,'rb')\n",
    "hist_MLR_CI = pickle.load(hf)\n",
    "hist_MLR_CI = hist_MLR_CI['hist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_MLR_TfromNS = path_PKL + 'PKL_DATA2021_04_26_MLR_RH_TfromNS_LHF_nsDELQ_hist.pkl'\n",
    "hf = open(path_MLR_TfromNS,'rb')\n",
    "hist_MLR_TfromNS = pickle.load(hf)\n",
    "hist_MLR_TfromNS = hist_MLR_TfromNS['hist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_NN_TfromNS = path_PKL + 'PKL_DATA2021_04_26_NN_RH_TfromNS_LHF_nsDELQ_hist.pkl'\n",
    "hf = open(path_NN_TfromNS,'rb')\n",
    "hist_NN_TfromNS = pickle.load(hf)\n",
    "hist_NN_TfromNS = hist_NN_TfromNS['hist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_NN_BCONS1 = path_PKL + 'PKL_DATA2021_05_05_NN_RH_BCONS_LHF_nsDELQ_hist10.pkl'\n",
    "hf = open(path_NN_BCONS1,'rb')\n",
    "hist_NN_BCONS1 = pickle.load(hf)\n",
    "hist_NN_BCONS1 = hist_NN_BCONS1['hist']\n",
    "\n",
    "path_NN_BCONS2 = path_PKL + 'PKL_DATA2021_05_05_NN_RH_BCONS_LHF_nsDELQ_hist20.pkl'\n",
    "hf = open(path_NN_BCONS2,'rb')\n",
    "hist_NN_BCONS2 = pickle.load(hf)\n",
    "hist_NN_BCONS2 = hist_NN_BCONS2['hist']\n",
    "\n",
    "hist_NN_BCONS0 = {}\n",
    "for key in hist_NN_BCONS1.keys():\n",
    "    hist_NN_BCONS0[key] = np.append(hist_NN_BCONS1[key],hist_NN_BCONS2[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fz = 15\n",
    "lw = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('text', usetex=False)\n",
    "mpl.rcParams['mathtext.fontset'] = 'stix'\n",
    "mpl.rcParams['font.family'] = 'STIXGeneral'\n",
    "plt.rc('font', family='serif', size=fz)\n",
    "mpl.rcParams['lines.linewidth'] = lw\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(2,3,figsize=(15,10))\n",
    "\n",
    "for iax in range(6):\n",
    "    \n",
    "    iax_ar = iax//3\n",
    "    subp = ax[iax_ar][iax-3*iax_ar]\n",
    "    \n",
    "    if iax==0: h = hist_MLR_BF; tit = 'MLR BF'\n",
    "    elif iax==1: h = hist_NN_BF1; tit = 'NN BF 04 26'\n",
    "    elif iax==2: h = hist_MLR_TfromNS; tit = 'MLR TfromNS'\n",
    "    elif iax==3: h = hist_MLR_CI; tit = 'MLR CI'\n",
    "    elif iax==4: h = hist_NN_TfromNS; tit = 'NN TfromNS'\n",
    "    elif iax==5: h = hist_NN_BCONS0; tit = 'NN BCONS'\n",
    "    \n",
    "    for key in h.keys():\n",
    "        subp.plot(h[key],label=key)\n",
    "    subp.legend()\n",
    "    subp.set_title(tit+' '+str(h['val_loss'][-1])[:4])\n",
    "    subp.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_LOGI_TfromNS = path_PKL + 'PKL_DATA2021_04_26_LOGI_PERC_RH_TfromNS_LHF_nsDELQ_hist.pkl'\n",
    "hf = open(path_LOGI_TfromNS,'rb')\n",
    "hist_LOGI_TfromNS = pickle.load(hf)\n",
    "hist_LOGI_TfromNS = hist_LOGI_TfromNS['hist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_LOGI_BCONS = path_PKL + 'PKL_DATA2021_04_26_LOGI_PERC_RH_BCONS_LHF_nsDELQ_hist.pkl'\n",
    "hf = open(path_LOGI_BCONS,'rb')\n",
    "hist_LOGI_BCONS = pickle.load(hf)\n",
    "hist_LOGI_BCONS = hist_LOGI_BCONS['hist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(2,1,figsize=(15,10))\n",
    "\n",
    "for iax in range(2):\n",
    "    \n",
    "    iax_ar = iax//1\n",
    "    subp = ax[iax]\n",
    "    \n",
    "    if iax==0: h = hist_LOGI_TfromNS; tit = 'LOGI TfromNS'\n",
    "    elif iax==1: h = hist_LOGI_BCONS; tit = 'LOGI BCONS'\n",
    "    \n",
    "    for key in h.keys():\n",
    "        subp.plot(h[key],label=key)\n",
    "    subp.legend()\n",
    "    subp.set_title(tit+' '+str(h['val_loss'][-1])[:6])\n",
    "    subp.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fz = 40\n",
    "lw = 6\n",
    "siz = 250\n",
    "\n",
    "plt.rc('text', usetex=False)\n",
    "mpl.rcParams['mathtext.fontset'] = 'stix'\n",
    "mpl.rcParams['font.family'] = 'STIXGeneral'\n",
    "plt.rc('font', family='serif', size=fz)\n",
    "mpl.rcParams['lines.linewidth'] = lw\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = np.arange(1,21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.scatter(epoch,hist_NN_BF1['val_loss'],s=siz,color='b')\n",
    "plt.plot(epoch,hist_NN_BF1['val_loss'],color='b')\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Loss (W$^{2}$ m${-4})$')\n",
    "plt.xlim((0,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.scatter(epoch,hist_NN_BF1['val_loss'],s=siz,color='b')\n",
    "plt.plot(epoch,hist_NN_BF1['val_loss'],color='b')\n",
    "plt.scatter(epoch,hist_NN_BF1['trainM4K_RG_loss'],s=siz,color='g')\n",
    "plt.plot(epoch,hist_NN_BF1['trainM4K_RG_loss'],color='g')\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Loss (W$^{2}$ m${-4})$')\n",
    "plt.xlim((0,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.scatter(epoch,hist_NN_BF1['val_loss'],s=siz,color='b')\n",
    "plt.plot(epoch,hist_NN_BF1['val_loss'],color='b')\n",
    "\n",
    "plt.scatter(epoch,hist_MLR_BF['val_loss'],s=siz,color='b',marker='s')\n",
    "plt.plot(epoch,hist_MLR_BF['val_loss'],color='b')\n",
    "\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Loss (W$^{2}$ m${-4})$')\n",
    "plt.xlim((0,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.scatter(epoch,hist_NN_BF1['val_loss'],s=siz,color='b')\n",
    "plt.plot(epoch,hist_NN_BF1['val_loss'],color='b')\n",
    "\n",
    "plt.scatter(epoch,hist_MLR_BF['val_loss'],s=siz,color='b',marker='s')\n",
    "plt.plot(epoch,hist_MLR_BF['val_loss'],color='b')\n",
    "\n",
    "plt.scatter(epoch,hist_MLR_BF['trainM4K_RG_loss'],s=siz,color='g',marker='s')\n",
    "plt.plot(epoch,hist_MLR_BF['trainM4K_RG_loss'],color='g',marker='s')\n",
    "\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Loss (W$^{2}$ m${-4})$')\n",
    "plt.xlim((0,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.scatter(epoch,hist_NN_BF1['val_loss'],s=siz,color='b')\n",
    "plt.plot(epoch,hist_NN_BF1['val_loss'],color='b')\n",
    "\n",
    "# plt.scatter(epoch,hist_MLR_BF['val_loss'],s=siz,color='b',marker='s')\n",
    "# plt.plot(epoch,hist_MLR_BF['val_loss'],color='b')\n",
    "\n",
    "plt.scatter(epoch,hist_MLR_BF['trainM4K_RG_loss'],s=siz,color='g',marker='s')\n",
    "plt.plot(epoch,hist_MLR_BF['trainM4K_RG_loss'],color='g',marker='s')\n",
    "\n",
    "plt.scatter(epoch,hist_MLR_CI['val_loss'],color='b',marker='*',s=2*siz)\n",
    "plt.plot(epoch,hist_MLR_CI['val_loss'],color='b',marker='*')\n",
    "\n",
    "plt.scatter(epoch,hist_MLR_CI['trainM4K_RG_loss'],color='g',marker='*',s=2*siz)\n",
    "plt.plot(epoch,hist_MLR_CI['trainM4K_RG_loss'],color='g',marker='*')\n",
    "\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Loss (W$^{2}$ m${-4})$')\n",
    "plt.xlim((0,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "# plt.scatter(epoch,hist_NN_BF1['trainP4K_loss'],s=siz,color='r')\n",
    "# plt.plot(epoch,hist_NN_BF1['trainP4K_loss'],color='r')\n",
    "\n",
    "# plt.scatter(epoch,hist_MLR_BF['val_loss'],s=siz,color='b',marker='s')\n",
    "# plt.plot(epoch,hist_MLR_BF['val_loss'],color='b')\n",
    "\n",
    "plt.scatter(epoch,hist_MLR_BF['trainP4K_loss'],s=siz,color='r',marker='s')\n",
    "plt.plot(epoch,hist_MLR_BF['trainP4K_loss'],color='r',marker='s')\n",
    "\n",
    "plt.scatter(epoch,hist_MLR_CI['trainP4K_loss'],color='r',marker='*',s=2*siz)\n",
    "plt.plot(epoch,hist_MLR_CI['trainP4K_loss'],color='r',marker='*')\n",
    "\n",
    "# plt.scatter(epoch,hist_MLR_CI['trainM4K_RG_loss'],color='g',marker='*',s=2*siz)\n",
    "# plt.plot(epoch,hist_MLR_CI['trainM4K_RG_loss'],color='g',marker='*')\n",
    "\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Loss (W$^{2}$ m${-4})$')\n",
    "plt.xlim((0,20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "409.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
